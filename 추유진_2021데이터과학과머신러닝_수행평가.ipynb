{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "추유진 - 2021데이터과학과머신러닝_수행평가.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yujinchu04/test_repository/blob/main/%EC%B6%94%EC%9C%A0%EC%A7%84_2021%EB%8D%B0%EC%9D%B4%ED%84%B0%EA%B3%BC%ED%95%99%EA%B3%BC%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D_%EC%88%98%ED%96%89%ED%8F%89%EA%B0%80.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkpPmbzo3Bz7"
      },
      "source": [
        "# 2021 데이터과학과 머신러닝 수행평가\n",
        "* Direction : wineClass 데이터는 레드와인과 화이트와인, 그리고 와인질을 평가하는 데이터 셋이다.\n",
        "* 파일명은 wineClass.csv이다. \n",
        "* 다음을 딥러닝 모델로 학습시켜 가장 높은 정확도를 산출하시오.\n",
        "* 각 열의 이름은 다음과 같다.\n",
        "* 결합산,휘발산,구연산,잔여설탕,염화물,자유아황산가스,총황화합물,밀도,산성도,황화합물,알콜,와인질,와인종류\n",
        "* 이미 완성된 코드의 경우 수정하지 않고, 결과를 도출한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "re3-aW6YU5oN"
      },
      "source": [
        "# 데이터 파일 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNK7h2Q9TZg6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b48b15d-31a0-4633-9ee8-a3b0279631c8"
      },
      "source": [
        "import os\n",
        "import random\n",
        "from matplotlib import pyplot as plt\n",
        " \n",
        "# URL로 다운받은 파일 사용하기\n",
        "from urllib.request import urlretrieve\n",
        "urlretrieve(\"https://drive.google.com/uc?export=download&id=1rCT8Q3nHXpxA13qaSkGvnklG5gJmXxzM\", \"wineClass.csv\")\n",
        "###"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('wineClass.csv', <http.client.HTTPMessage at 0x7ff07f9649d0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uplHMDgxnLnb"
      },
      "source": [
        "#라이브러리 가져오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3M51x0OEnN-z"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9ZfrsVmnTHB"
      },
      "source": [
        "# 데이터 셋 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "II0mn_G_nPZJ"
      },
      "source": [
        "df=pd.read_csv('wineClass.csv',encoding='cp949')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SaX2macnbZo"
      },
      "source": [
        "# 데이터 보기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZyal_3SnbHC"
      },
      "source": [
        "# 처음 5줄을 봅니다.\n",
        "print(df.head(50))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTlf474nnlZL"
      },
      "source": [
        "# 데이터의 전반적인 정보를 확인해 봅니다.\n",
        "print(df.info())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNbTf9k3nncB"
      },
      "source": [
        "# 각 정보별 특징을 좀더 자세히 출력합니다.\n",
        "print(df.describe())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8uXfgz2ofCn"
      },
      "source": [
        "#모델 설계"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEzK0fcIojnM"
      },
      "source": [
        "## 라이브러리 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oYkT4rgonjL"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import numpy\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WqVzSheoxY4"
      },
      "source": [
        "## 데이터 로드"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71LbAnCz-3tU"
      },
      "source": [
        "여러 번 로드하면서 모델 정확도 검증 가능(아마두)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMjJ0ERHAZDz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "442cff30-d204-4b9b-a285-18db429d1e73"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import np_utils # for one hot encoding\n",
        " \n",
        "dataset=df.values\n",
        "X = dataset[:,0:12] #사용 X\n",
        "Y = dataset[:,12] #와인 종류 분류용\n",
        " \n",
        "X0=X[:,0:11] #와인질 전까지만\n",
        "#print(X0)\n",
        "Yx=dataset[:,11] #와인질 분류\n",
        "Y0=pd.get_dummies(Yx) # one hot encoding, \n",
        "  #데이터 파일에 품질 1, 2가 없어서 제대로 된 인코딩이라고 할 수는 없음.\n",
        "Y0=Y0.values\n",
        "#print(Y0)\n",
        "''' \n",
        "Y_all=dataset[:,11:] #통합된 정확도 측정을 위해서임.\n",
        "x_a_train,x_a_test,y_a_train,y_a_test=train_test_split(X0,Y_all,test_size=0.3)\n",
        " \n",
        "yall=pd.get_dummies(y_a_train[:,0]) # 12번 콜럼에 대해서는 원 핫 인코딩 need\n",
        "y_a_train_r=yall.values \n",
        "print(y_a_train_r) #찐 훈련용\n",
        "yall0=pd.get_dummies(y_a_test[:,0])\n",
        "y_a_test_r=yall0.values \n",
        "print(y_a_test_r) #찐 검증용\n",
        " '''\n",
        " \n",
        " \n",
        "x_train,x_test,y_train,y_test=train_test_split(X0,Y,test_size=0.2) #와인 분류용\n",
        "x0_train,x0_test,y0_train,y0_test=train_test_split(X0,Y0,test_size=0.2) #와인질 분류용\n",
        "#print(x_test)\n",
        "#print(y0_test)\n",
        "\n",
        "print(x_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 6.8   0.22  0.35 ...  3.24  0.42  9.  ]\n",
            " [ 6.8   0.73  0.2  ...  3.12  0.28 11.1 ]\n",
            " [ 7.5   0.61  0.26 ...  3.3   0.53  9.8 ]\n",
            " ...\n",
            " [ 6.7   0.42  0.39 ...  3.31  0.58  9.7 ]\n",
            " [ 6.8   0.44  0.37 ...  3.08  0.65 10.5 ]\n",
            " [ 6.8   0.56  0.03 ...  3.44  0.63 10.  ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7gj0aNDo5js"
      },
      "source": [
        "## 모델 설정"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSlqpWD3Em7u"
      },
      "source": [
        "####와인 분류 모델"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMbNXsE3ItpQ"
      },
      "source": [
        "MODEL_PATH='./model/'\n",
        "if not os.path.exists(MODEL_PATH):\n",
        "  os.mkdir(MODEL_PATH)\n",
        "model_path=MODEL_PATH+'{val_loss:.4f}-{val_accuracy:.4f}-{epoch:02d}.hdf5' ####최고 성능 모델 저장"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1KueTJfIuhW"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "checkpointer=ModelCheckpoint(filepath=model_path, monitor='val_loss', verbose=2,save_best_only=True) ###222"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBRJ-4thoq-F"
      },
      "source": [
        "model = Sequential() # 4층에, 노드 복잡하지 않게. 이진분류임\n",
        "model.add(Dense(20, input_dim=11, activation='relu')) \n",
        "model.add(Dense(12, activation='relu'))\n",
        "model.add(Dense(4, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LiROnknXEo3P"
      },
      "source": [
        "####와인 질 모델"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSCMh71uIwk8"
      },
      "source": [
        "MODEL_PATH0='./model0/'\n",
        "if not os.path.exists(MODEL_PATH0):\n",
        "  os.mkdir(MODEL_PATH0)\n",
        "model_path0=MODEL_PATH0+'{val_loss:.4f}-{val_accuracy:.4f}-{epoch:02d}.hdf5' ####최고 성능 모델 저장"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1rgA1kbI502"
      },
      "source": [
        "#from keras.callbacks import ModelCheckpoint\n",
        "checkpointer0=ModelCheckpoint(filepath=model_path0, monitor='val_loss', verbose=2,save_best_only=True) ###222"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjxhArO0FACV"
      },
      "source": [
        "from keras.metrics import categorical_accuracy\n",
        "from keras.layers import Flatten"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3kyZZVWGrbL"
      },
      "source": [
        "model0 = Sequential() #4층 60 30 20 10 정도로 돌릴 때 가장 좋았음. (최고 모델이, 아마도)\n",
        "model0.add(Dense(30, input_dim=11, activation='relu')) \n",
        "model0.add(Flatten()) #아래 링크 참고함.\n",
        "#http://5.9.10.113/65240824/keras-valueerror-shapes-none-1-and-none-48-48-96-are-incompatible\n",
        "model0.add(Dense(20, activation='relu')) \n",
        "model0.add(Dense(10, activation='relu')) \n",
        "model0.add(Dense(10, activation='relu'))\n",
        "model0.add(Dense(7, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EswS6IrpBey"
      },
      "source": [
        "## 모델 컴파일"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-C0jhkHBHeSh"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', #와인 분류\n",
        "             optimizer=\"adam\", \n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZqol0tFHgVO"
      },
      "source": [
        "model0.compile(optimizer='adam', #와인질 분류\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5D0hK4mpHg5"
      },
      "source": [
        "## 모델 학습시키기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5m6psFIpG9D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99d15d3c-ad1c-480c-ad8b-954082d6583f"
      },
      "source": [
        "'''model.fit(x_train, y_train, epochs=10, batch_size=200, #와인 종류\n",
        "          validation_split=0.2, verbose=0, callbacks=[checkpointer])'''\n",
        "\n",
        "wineseries = model.fit(x_train, y_train, epochs=1000, batch_size=100, #와인 종류\n",
        "          validation_split=0.3, verbose=1, callbacks=[checkpointer])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "37/37 [==============================] - 1s 10ms/step - loss: 0.4739 - accuracy: 0.7573 - val_loss: 0.3585 - val_accuracy: 0.7551\n",
            "\n",
            "Epoch 00001: val_loss improved from 0.55666 to 0.35849, saving model to ./model/0.3585-0.7551-01.hdf5\n",
            "Epoch 2/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.3545 - accuracy: 0.7775 - val_loss: 0.3126 - val_accuracy: 0.8551\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.35849 to 0.31258, saving model to ./model/0.3126-0.8551-02.hdf5\n",
            "Epoch 3/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.2942 - accuracy: 0.8782 - val_loss: 0.2006 - val_accuracy: 0.9308\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.31258 to 0.20063, saving model to ./model/0.2006-0.9308-03.hdf5\n",
            "Epoch 4/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.2047 - accuracy: 0.9335 - val_loss: 0.1972 - val_accuracy: 0.9295\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.20063 to 0.19716, saving model to ./model/0.1972-0.9295-04.hdf5\n",
            "Epoch 5/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1949 - accuracy: 0.9356 - val_loss: 0.1823 - val_accuracy: 0.9397\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.19716 to 0.18234, saving model to ./model/0.1823-0.9397-05.hdf5\n",
            "Epoch 6/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1885 - accuracy: 0.9391 - val_loss: 0.1731 - val_accuracy: 0.9397\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.18234 to 0.17313, saving model to ./model/0.1731-0.9397-06.hdf5\n",
            "Epoch 7/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1890 - accuracy: 0.9380 - val_loss: 0.1616 - val_accuracy: 0.9423\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.17313 to 0.16165, saving model to ./model/0.1616-0.9423-07.hdf5\n",
            "Epoch 8/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1770 - accuracy: 0.9439 - val_loss: 0.1508 - val_accuracy: 0.9474\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.16165 to 0.15077, saving model to ./model/0.1508-0.9474-08.hdf5\n",
            "Epoch 9/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1565 - accuracy: 0.9461 - val_loss: 0.1440 - val_accuracy: 0.9494\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.15077 to 0.14405, saving model to ./model/0.1440-0.9494-09.hdf5\n",
            "Epoch 10/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1420 - accuracy: 0.9563 - val_loss: 0.1403 - val_accuracy: 0.9500\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.14405 to 0.14031, saving model to ./model/0.1403-0.9500-10.hdf5\n",
            "Epoch 11/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1589 - accuracy: 0.9476 - val_loss: 0.1295 - val_accuracy: 0.9519\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.14031 to 0.12946, saving model to ./model/0.1295-0.9519-11.hdf5\n",
            "Epoch 12/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1420 - accuracy: 0.9561 - val_loss: 0.1260 - val_accuracy: 0.9590\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.12946 to 0.12596, saving model to ./model/0.1260-0.9590-12.hdf5\n",
            "Epoch 13/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1344 - accuracy: 0.9567 - val_loss: 0.1206 - val_accuracy: 0.9558\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.12596 to 0.12062, saving model to ./model/0.1206-0.9558-13.hdf5\n",
            "Epoch 14/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1352 - accuracy: 0.9562 - val_loss: 0.1115 - val_accuracy: 0.9628\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.12062 to 0.11151, saving model to ./model/0.1115-0.9628-14.hdf5\n",
            "Epoch 15/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1330 - accuracy: 0.9540 - val_loss: 0.1156 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.11151\n",
            "Epoch 16/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1174 - accuracy: 0.9600 - val_loss: 0.1245 - val_accuracy: 0.9686\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.11151\n",
            "Epoch 17/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1322 - accuracy: 0.9543 - val_loss: 0.1017 - val_accuracy: 0.9647\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.11151 to 0.10168, saving model to ./model/0.1017-0.9647-17.hdf5\n",
            "Epoch 18/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1197 - accuracy: 0.9611 - val_loss: 0.1172 - val_accuracy: 0.9712\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.10168\n",
            "Epoch 19/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1177 - accuracy: 0.9654 - val_loss: 0.0969 - val_accuracy: 0.9686\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.10168 to 0.09694, saving model to ./model/0.0969-0.9686-19.hdf5\n",
            "Epoch 20/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1128 - accuracy: 0.9638 - val_loss: 0.0981 - val_accuracy: 0.9744\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.09694\n",
            "Epoch 21/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0968 - accuracy: 0.9712 - val_loss: 0.0953 - val_accuracy: 0.9635\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.09694 to 0.09531, saving model to ./model/0.0953-0.9635-21.hdf5\n",
            "Epoch 22/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0987 - accuracy: 0.9675 - val_loss: 0.0955 - val_accuracy: 0.9776\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.09531\n",
            "Epoch 23/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0958 - accuracy: 0.9718 - val_loss: 0.0887 - val_accuracy: 0.9731\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.09531 to 0.08875, saving model to ./model/0.0887-0.9731-23.hdf5\n",
            "Epoch 24/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0958 - accuracy: 0.9705 - val_loss: 0.0936 - val_accuracy: 0.9782\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.08875\n",
            "Epoch 25/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0983 - accuracy: 0.9677 - val_loss: 0.0861 - val_accuracy: 0.9750\n",
            "\n",
            "Epoch 00025: val_loss improved from 0.08875 to 0.08613, saving model to ./model/0.0861-0.9750-25.hdf5\n",
            "Epoch 26/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0990 - accuracy: 0.9715 - val_loss: 0.0840 - val_accuracy: 0.9679\n",
            "\n",
            "Epoch 00026: val_loss improved from 0.08613 to 0.08398, saving model to ./model/0.0840-0.9679-26.hdf5\n",
            "Epoch 27/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0796 - accuracy: 0.9774 - val_loss: 0.0821 - val_accuracy: 0.9724\n",
            "\n",
            "Epoch 00027: val_loss improved from 0.08398 to 0.08212, saving model to ./model/0.0821-0.9724-27.hdf5\n",
            "Epoch 28/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0848 - accuracy: 0.9765 - val_loss: 0.0832 - val_accuracy: 0.9699\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.08212\n",
            "Epoch 29/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0962 - accuracy: 0.9723 - val_loss: 0.0948 - val_accuracy: 0.9763\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.08212\n",
            "Epoch 30/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0887 - accuracy: 0.9773 - val_loss: 0.0801 - val_accuracy: 0.9756\n",
            "\n",
            "Epoch 00030: val_loss improved from 0.08212 to 0.08009, saving model to ./model/0.0801-0.9756-30.hdf5\n",
            "Epoch 31/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0886 - accuracy: 0.9726 - val_loss: 0.0868 - val_accuracy: 0.9782\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.08009\n",
            "Epoch 32/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0987 - accuracy: 0.9714 - val_loss: 0.0790 - val_accuracy: 0.9756\n",
            "\n",
            "Epoch 00032: val_loss improved from 0.08009 to 0.07900, saving model to ./model/0.0790-0.9756-32.hdf5\n",
            "Epoch 33/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0794 - accuracy: 0.9809 - val_loss: 0.0762 - val_accuracy: 0.9769\n",
            "\n",
            "Epoch 00033: val_loss improved from 0.07900 to 0.07619, saving model to ./model/0.0762-0.9769-33.hdf5\n",
            "Epoch 34/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0794 - accuracy: 0.9796 - val_loss: 0.0737 - val_accuracy: 0.9782\n",
            "\n",
            "Epoch 00034: val_loss improved from 0.07619 to 0.07365, saving model to ./model/0.0737-0.9782-34.hdf5\n",
            "Epoch 35/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0791 - accuracy: 0.9771 - val_loss: 0.0771 - val_accuracy: 0.9788\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.07365\n",
            "Epoch 36/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0821 - accuracy: 0.9744 - val_loss: 0.0716 - val_accuracy: 0.9782\n",
            "\n",
            "Epoch 00036: val_loss improved from 0.07365 to 0.07155, saving model to ./model/0.0716-0.9782-36.hdf5\n",
            "Epoch 37/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0915 - accuracy: 0.9761 - val_loss: 0.0705 - val_accuracy: 0.9795\n",
            "\n",
            "Epoch 00037: val_loss improved from 0.07155 to 0.07048, saving model to ./model/0.0705-0.9795-37.hdf5\n",
            "Epoch 38/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0905 - accuracy: 0.9725 - val_loss: 0.0722 - val_accuracy: 0.9776\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.07048\n",
            "Epoch 39/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0910 - accuracy: 0.9742 - val_loss: 0.0716 - val_accuracy: 0.9795\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.07048\n",
            "Epoch 40/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0727 - accuracy: 0.9753 - val_loss: 0.0679 - val_accuracy: 0.9788\n",
            "\n",
            "Epoch 00040: val_loss improved from 0.07048 to 0.06795, saving model to ./model/0.0679-0.9788-40.hdf5\n",
            "Epoch 41/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0812 - accuracy: 0.9761 - val_loss: 0.0684 - val_accuracy: 0.9814\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.06795\n",
            "Epoch 42/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0750 - accuracy: 0.9788 - val_loss: 0.0673 - val_accuracy: 0.9782\n",
            "\n",
            "Epoch 00042: val_loss improved from 0.06795 to 0.06730, saving model to ./model/0.0673-0.9782-42.hdf5\n",
            "Epoch 43/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0872 - accuracy: 0.9726 - val_loss: 0.0752 - val_accuracy: 0.9744\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.06730\n",
            "Epoch 44/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0765 - accuracy: 0.9758 - val_loss: 0.0690 - val_accuracy: 0.9801\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.06730\n",
            "Epoch 45/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0767 - accuracy: 0.9804 - val_loss: 0.0657 - val_accuracy: 0.9808\n",
            "\n",
            "Epoch 00045: val_loss improved from 0.06730 to 0.06568, saving model to ./model/0.0657-0.9808-45.hdf5\n",
            "Epoch 46/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0624 - accuracy: 0.9841 - val_loss: 0.0690 - val_accuracy: 0.9788\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.06568\n",
            "Epoch 47/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0743 - accuracy: 0.9789 - val_loss: 0.0670 - val_accuracy: 0.9808\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.06568\n",
            "Epoch 48/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0833 - accuracy: 0.9752 - val_loss: 0.0634 - val_accuracy: 0.9814\n",
            "\n",
            "Epoch 00048: val_loss improved from 0.06568 to 0.06341, saving model to ./model/0.0634-0.9814-48.hdf5\n",
            "Epoch 49/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0661 - accuracy: 0.9809 - val_loss: 0.0636 - val_accuracy: 0.9808\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.06341\n",
            "Epoch 50/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0688 - accuracy: 0.9794 - val_loss: 0.0636 - val_accuracy: 0.9808\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.06341\n",
            "Epoch 51/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0718 - accuracy: 0.9810 - val_loss: 0.0703 - val_accuracy: 0.9795\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.06341\n",
            "Epoch 52/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0748 - accuracy: 0.9756 - val_loss: 0.0751 - val_accuracy: 0.9769\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.06341\n",
            "Epoch 53/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0772 - accuracy: 0.9802 - val_loss: 0.0710 - val_accuracy: 0.9769\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.06341\n",
            "Epoch 54/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0747 - accuracy: 0.9797 - val_loss: 0.0733 - val_accuracy: 0.9756\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 0.06341\n",
            "Epoch 55/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0731 - accuracy: 0.9817 - val_loss: 0.0613 - val_accuracy: 0.9808\n",
            "\n",
            "Epoch 00055: val_loss improved from 0.06341 to 0.06128, saving model to ./model/0.0613-0.9808-55.hdf5\n",
            "Epoch 56/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0820 - accuracy: 0.9762 - val_loss: 0.0604 - val_accuracy: 0.9814\n",
            "\n",
            "Epoch 00056: val_loss improved from 0.06128 to 0.06041, saving model to ./model/0.0604-0.9814-56.hdf5\n",
            "Epoch 57/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0701 - accuracy: 0.9787 - val_loss: 0.0735 - val_accuracy: 0.9763\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.06041\n",
            "Epoch 58/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0798 - accuracy: 0.9752 - val_loss: 0.0629 - val_accuracy: 0.9814\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.06041\n",
            "Epoch 59/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0628 - accuracy: 0.9803 - val_loss: 0.0608 - val_accuracy: 0.9808\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 0.06041\n",
            "Epoch 60/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0774 - accuracy: 0.9773 - val_loss: 0.0849 - val_accuracy: 0.9699\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.06041\n",
            "Epoch 61/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1018 - accuracy: 0.9682 - val_loss: 0.0616 - val_accuracy: 0.9808\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.06041\n",
            "Epoch 62/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0695 - accuracy: 0.9803 - val_loss: 0.0590 - val_accuracy: 0.9821\n",
            "\n",
            "Epoch 00062: val_loss improved from 0.06041 to 0.05901, saving model to ./model/0.0590-0.9821-62.hdf5\n",
            "Epoch 63/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0631 - accuracy: 0.9807 - val_loss: 0.0610 - val_accuracy: 0.9814\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.05901\n",
            "Epoch 64/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0658 - accuracy: 0.9776 - val_loss: 0.0578 - val_accuracy: 0.9821\n",
            "\n",
            "Epoch 00064: val_loss improved from 0.05901 to 0.05777, saving model to ./model/0.0578-0.9821-64.hdf5\n",
            "Epoch 65/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0697 - accuracy: 0.9785 - val_loss: 0.0772 - val_accuracy: 0.9737\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 0.05777\n",
            "Epoch 66/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0836 - accuracy: 0.9747 - val_loss: 0.0569 - val_accuracy: 0.9840\n",
            "\n",
            "Epoch 00066: val_loss improved from 0.05777 to 0.05693, saving model to ./model/0.0569-0.9840-66.hdf5\n",
            "Epoch 67/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0687 - accuracy: 0.9791 - val_loss: 0.0622 - val_accuracy: 0.9821\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 0.05693\n",
            "Epoch 68/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0679 - accuracy: 0.9806 - val_loss: 0.0588 - val_accuracy: 0.9827\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 0.05693\n",
            "Epoch 69/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0759 - accuracy: 0.9767 - val_loss: 0.0578 - val_accuracy: 0.9833\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 0.05693\n",
            "Epoch 70/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0662 - accuracy: 0.9802 - val_loss: 0.0611 - val_accuracy: 0.9827\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 0.05693\n",
            "Epoch 71/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0753 - accuracy: 0.9792 - val_loss: 0.0603 - val_accuracy: 0.9814\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 0.05693\n",
            "Epoch 72/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0802 - accuracy: 0.9772 - val_loss: 0.0667 - val_accuracy: 0.9808\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 0.05693\n",
            "Epoch 73/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0613 - accuracy: 0.9857 - val_loss: 0.0546 - val_accuracy: 0.9840\n",
            "\n",
            "Epoch 00073: val_loss improved from 0.05693 to 0.05463, saving model to ./model/0.0546-0.9840-73.hdf5\n",
            "Epoch 74/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0595 - accuracy: 0.9828 - val_loss: 0.0579 - val_accuracy: 0.9821\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 0.05463\n",
            "Epoch 75/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0622 - accuracy: 0.9840 - val_loss: 0.0588 - val_accuracy: 0.9821\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.05463\n",
            "Epoch 76/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0616 - accuracy: 0.9844 - val_loss: 0.0551 - val_accuracy: 0.9827\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 0.05463\n",
            "Epoch 77/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0632 - accuracy: 0.9816 - val_loss: 0.0545 - val_accuracy: 0.9833\n",
            "\n",
            "Epoch 00077: val_loss improved from 0.05463 to 0.05450, saving model to ./model/0.0545-0.9833-77.hdf5\n",
            "Epoch 78/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0733 - accuracy: 0.9822 - val_loss: 0.0578 - val_accuracy: 0.9821\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 0.05450\n",
            "Epoch 79/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0776 - accuracy: 0.9759 - val_loss: 0.0550 - val_accuracy: 0.9840\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 0.05450\n",
            "Epoch 80/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0770 - accuracy: 0.9767 - val_loss: 0.0556 - val_accuracy: 0.9821\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.05450\n",
            "Epoch 81/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0712 - accuracy: 0.9797 - val_loss: 0.0560 - val_accuracy: 0.9846\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 0.05450\n",
            "Epoch 82/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0594 - accuracy: 0.9827 - val_loss: 0.0582 - val_accuracy: 0.9833\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 0.05450\n",
            "Epoch 83/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0620 - accuracy: 0.9805 - val_loss: 0.0542 - val_accuracy: 0.9840\n",
            "\n",
            "Epoch 00083: val_loss improved from 0.05450 to 0.05419, saving model to ./model/0.0542-0.9840-83.hdf5\n",
            "Epoch 84/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0577 - accuracy: 0.9844 - val_loss: 0.0653 - val_accuracy: 0.9821\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.05419\n",
            "Epoch 85/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0729 - accuracy: 0.9822 - val_loss: 0.0535 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00085: val_loss improved from 0.05419 to 0.05348, saving model to ./model/0.0535-0.9853-85.hdf5\n",
            "Epoch 86/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0626 - accuracy: 0.9830 - val_loss: 0.0552 - val_accuracy: 0.9833\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 0.05348\n",
            "Epoch 87/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0729 - accuracy: 0.9799 - val_loss: 0.0562 - val_accuracy: 0.9840\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 0.05348\n",
            "Epoch 88/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0630 - accuracy: 0.9827 - val_loss: 0.0531 - val_accuracy: 0.9846\n",
            "\n",
            "Epoch 00088: val_loss improved from 0.05348 to 0.05313, saving model to ./model/0.0531-0.9846-88.hdf5\n",
            "Epoch 89/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0527 - accuracy: 0.9863 - val_loss: 0.0719 - val_accuracy: 0.9769\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 0.05313\n",
            "Epoch 90/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0661 - accuracy: 0.9824 - val_loss: 0.0589 - val_accuracy: 0.9808\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 0.05313\n",
            "Epoch 91/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0661 - accuracy: 0.9800 - val_loss: 0.0596 - val_accuracy: 0.9821\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.05313\n",
            "Epoch 92/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0569 - accuracy: 0.9830 - val_loss: 0.0507 - val_accuracy: 0.9840\n",
            "\n",
            "Epoch 00092: val_loss improved from 0.05313 to 0.05072, saving model to ./model/0.0507-0.9840-92.hdf5\n",
            "Epoch 93/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0641 - accuracy: 0.9823 - val_loss: 0.0518 - val_accuracy: 0.9840\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 0.05072\n",
            "Epoch 94/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0532 - accuracy: 0.9867 - val_loss: 0.0521 - val_accuracy: 0.9840\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 0.05072\n",
            "Epoch 95/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0646 - accuracy: 0.9820 - val_loss: 0.0505 - val_accuracy: 0.9846\n",
            "\n",
            "Epoch 00095: val_loss improved from 0.05072 to 0.05054, saving model to ./model/0.0505-0.9846-95.hdf5\n",
            "Epoch 96/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0559 - accuracy: 0.9841 - val_loss: 0.0596 - val_accuracy: 0.9827\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 0.05054\n",
            "Epoch 97/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0636 - accuracy: 0.9812 - val_loss: 0.0591 - val_accuracy: 0.9814\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 0.05054\n",
            "Epoch 98/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0594 - accuracy: 0.9860 - val_loss: 0.0511 - val_accuracy: 0.9846\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 0.05054\n",
            "Epoch 99/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0623 - accuracy: 0.9847 - val_loss: 0.0526 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 0.05054\n",
            "Epoch 100/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.0487 - accuracy: 0.9874 - val_loss: 0.0606 - val_accuracy: 0.9808\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 0.05054\n",
            "Epoch 101/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0657 - accuracy: 0.9852 - val_loss: 0.0533 - val_accuracy: 0.9846\n",
            "\n",
            "Epoch 00101: val_loss did not improve from 0.05054\n",
            "Epoch 102/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0619 - accuracy: 0.9783 - val_loss: 0.0505 - val_accuracy: 0.9840\n",
            "\n",
            "Epoch 00102: val_loss improved from 0.05054 to 0.05051, saving model to ./model/0.0505-0.9840-102.hdf5\n",
            "Epoch 103/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0667 - accuracy: 0.9840 - val_loss: 0.0519 - val_accuracy: 0.9833\n",
            "\n",
            "Epoch 00103: val_loss did not improve from 0.05051\n",
            "Epoch 104/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0524 - accuracy: 0.9833 - val_loss: 0.0529 - val_accuracy: 0.9846\n",
            "\n",
            "Epoch 00104: val_loss did not improve from 0.05051\n",
            "Epoch 105/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0708 - accuracy: 0.9835 - val_loss: 0.0500 - val_accuracy: 0.9840\n",
            "\n",
            "Epoch 00105: val_loss improved from 0.05051 to 0.04998, saving model to ./model/0.0500-0.9840-105.hdf5\n",
            "Epoch 106/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0702 - accuracy: 0.9806 - val_loss: 0.0518 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00106: val_loss did not improve from 0.04998\n",
            "Epoch 107/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0552 - accuracy: 0.9831 - val_loss: 0.0504 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00107: val_loss did not improve from 0.04998\n",
            "Epoch 108/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0633 - accuracy: 0.9824 - val_loss: 0.0560 - val_accuracy: 0.9833\n",
            "\n",
            "Epoch 00108: val_loss did not improve from 0.04998\n",
            "Epoch 109/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0688 - accuracy: 0.9794 - val_loss: 0.0490 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00109: val_loss improved from 0.04998 to 0.04903, saving model to ./model/0.0490-0.9865-109.hdf5\n",
            "Epoch 110/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0569 - accuracy: 0.9858 - val_loss: 0.0541 - val_accuracy: 0.9821\n",
            "\n",
            "Epoch 00110: val_loss did not improve from 0.04903\n",
            "Epoch 111/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0577 - accuracy: 0.9812 - val_loss: 0.0488 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00111: val_loss improved from 0.04903 to 0.04881, saving model to ./model/0.0488-0.9853-111.hdf5\n",
            "Epoch 112/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0744 - accuracy: 0.9801 - val_loss: 0.0505 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00112: val_loss did not improve from 0.04881\n",
            "Epoch 113/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0712 - accuracy: 0.9803 - val_loss: 0.0741 - val_accuracy: 0.9756\n",
            "\n",
            "Epoch 00113: val_loss did not improve from 0.04881\n",
            "Epoch 114/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0745 - accuracy: 0.9780 - val_loss: 0.0493 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00114: val_loss did not improve from 0.04881\n",
            "Epoch 115/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0549 - accuracy: 0.9854 - val_loss: 0.0491 - val_accuracy: 0.9846\n",
            "\n",
            "Epoch 00115: val_loss did not improve from 0.04881\n",
            "Epoch 116/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0706 - accuracy: 0.9824 - val_loss: 0.0504 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00116: val_loss did not improve from 0.04881\n",
            "Epoch 117/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0662 - accuracy: 0.9795 - val_loss: 0.0498 - val_accuracy: 0.9833\n",
            "\n",
            "Epoch 00117: val_loss did not improve from 0.04881\n",
            "Epoch 118/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0642 - accuracy: 0.9812 - val_loss: 0.0492 - val_accuracy: 0.9827\n",
            "\n",
            "Epoch 00118: val_loss did not improve from 0.04881\n",
            "Epoch 119/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0566 - accuracy: 0.9824 - val_loss: 0.0537 - val_accuracy: 0.9827\n",
            "\n",
            "Epoch 00119: val_loss did not improve from 0.04881\n",
            "Epoch 120/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0569 - accuracy: 0.9843 - val_loss: 0.0609 - val_accuracy: 0.9808\n",
            "\n",
            "Epoch 00120: val_loss did not improve from 0.04881\n",
            "Epoch 121/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0677 - accuracy: 0.9814 - val_loss: 0.0600 - val_accuracy: 0.9833\n",
            "\n",
            "Epoch 00121: val_loss did not improve from 0.04881\n",
            "Epoch 122/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0654 - accuracy: 0.9808 - val_loss: 0.0483 - val_accuracy: 0.9846\n",
            "\n",
            "Epoch 00122: val_loss improved from 0.04881 to 0.04830, saving model to ./model/0.0483-0.9846-122.hdf5\n",
            "Epoch 123/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0628 - accuracy: 0.9838 - val_loss: 0.0766 - val_accuracy: 0.9782\n",
            "\n",
            "Epoch 00123: val_loss did not improve from 0.04830\n",
            "Epoch 124/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0583 - accuracy: 0.9861 - val_loss: 0.0535 - val_accuracy: 0.9840\n",
            "\n",
            "Epoch 00124: val_loss did not improve from 0.04830\n",
            "Epoch 125/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0566 - accuracy: 0.9833 - val_loss: 0.0464 - val_accuracy: 0.9846\n",
            "\n",
            "Epoch 00125: val_loss improved from 0.04830 to 0.04637, saving model to ./model/0.0464-0.9846-125.hdf5\n",
            "Epoch 126/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0629 - accuracy: 0.9853 - val_loss: 0.0475 - val_accuracy: 0.9840\n",
            "\n",
            "Epoch 00126: val_loss did not improve from 0.04637\n",
            "Epoch 127/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0518 - accuracy: 0.9857 - val_loss: 0.0657 - val_accuracy: 0.9788\n",
            "\n",
            "Epoch 00127: val_loss did not improve from 0.04637\n",
            "Epoch 128/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0626 - accuracy: 0.9812 - val_loss: 0.0462 - val_accuracy: 0.9846\n",
            "\n",
            "Epoch 00128: val_loss improved from 0.04637 to 0.04616, saving model to ./model/0.0462-0.9846-128.hdf5\n",
            "Epoch 129/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0541 - accuracy: 0.9828 - val_loss: 0.0484 - val_accuracy: 0.9840\n",
            "\n",
            "Epoch 00129: val_loss did not improve from 0.04616\n",
            "Epoch 130/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0491 - accuracy: 0.9854 - val_loss: 0.0456 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00130: val_loss improved from 0.04616 to 0.04558, saving model to ./model/0.0456-0.9859-130.hdf5\n",
            "Epoch 131/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0579 - accuracy: 0.9861 - val_loss: 0.0543 - val_accuracy: 0.9821\n",
            "\n",
            "Epoch 00131: val_loss did not improve from 0.04558\n",
            "Epoch 132/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0604 - accuracy: 0.9854 - val_loss: 0.0469 - val_accuracy: 0.9833\n",
            "\n",
            "Epoch 00132: val_loss did not improve from 0.04558\n",
            "Epoch 133/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0455 - accuracy: 0.9864 - val_loss: 0.0465 - val_accuracy: 0.9840\n",
            "\n",
            "Epoch 00133: val_loss did not improve from 0.04558\n",
            "Epoch 134/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0478 - accuracy: 0.9862 - val_loss: 0.0520 - val_accuracy: 0.9827\n",
            "\n",
            "Epoch 00134: val_loss did not improve from 0.04558\n",
            "Epoch 135/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0459 - accuracy: 0.9875 - val_loss: 0.0489 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00135: val_loss did not improve from 0.04558\n",
            "Epoch 136/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0659 - accuracy: 0.9835 - val_loss: 0.0492 - val_accuracy: 0.9846\n",
            "\n",
            "Epoch 00136: val_loss did not improve from 0.04558\n",
            "Epoch 137/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0602 - accuracy: 0.9816 - val_loss: 0.0574 - val_accuracy: 0.9821\n",
            "\n",
            "Epoch 00137: val_loss did not improve from 0.04558\n",
            "Epoch 138/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0596 - accuracy: 0.9851 - val_loss: 0.0457 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00138: val_loss did not improve from 0.04558\n",
            "Epoch 139/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0508 - accuracy: 0.9843 - val_loss: 0.0482 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00139: val_loss did not improve from 0.04558\n",
            "Epoch 140/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0572 - accuracy: 0.9833 - val_loss: 0.0492 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00140: val_loss did not improve from 0.04558\n",
            "Epoch 141/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0797 - accuracy: 0.9784 - val_loss: 0.0518 - val_accuracy: 0.9827\n",
            "\n",
            "Epoch 00141: val_loss did not improve from 0.04558\n",
            "Epoch 142/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0727 - accuracy: 0.9821 - val_loss: 0.0518 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00142: val_loss did not improve from 0.04558\n",
            "Epoch 143/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0543 - accuracy: 0.9861 - val_loss: 0.0553 - val_accuracy: 0.9827\n",
            "\n",
            "Epoch 00143: val_loss did not improve from 0.04558\n",
            "Epoch 144/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0582 - accuracy: 0.9831 - val_loss: 0.0460 - val_accuracy: 0.9846\n",
            "\n",
            "Epoch 00144: val_loss did not improve from 0.04558\n",
            "Epoch 145/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0719 - accuracy: 0.9818 - val_loss: 0.0602 - val_accuracy: 0.9801\n",
            "\n",
            "Epoch 00145: val_loss did not improve from 0.04558\n",
            "Epoch 146/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0655 - accuracy: 0.9820 - val_loss: 0.0615 - val_accuracy: 0.9833\n",
            "\n",
            "Epoch 00146: val_loss did not improve from 0.04558\n",
            "Epoch 147/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0529 - accuracy: 0.9840 - val_loss: 0.0489 - val_accuracy: 0.9840\n",
            "\n",
            "Epoch 00147: val_loss did not improve from 0.04558\n",
            "Epoch 148/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.0664 - accuracy: 0.9834 - val_loss: 0.0437 - val_accuracy: 0.9846\n",
            "\n",
            "Epoch 00148: val_loss improved from 0.04558 to 0.04374, saving model to ./model/0.0437-0.9846-148.hdf5\n",
            "Epoch 149/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 0.0490 - accuracy: 0.9871 - val_loss: 0.0482 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00149: val_loss did not improve from 0.04374\n",
            "Epoch 150/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0495 - accuracy: 0.9876 - val_loss: 0.0467 - val_accuracy: 0.9833\n",
            "\n",
            "Epoch 00150: val_loss did not improve from 0.04374\n",
            "Epoch 151/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0533 - accuracy: 0.9877 - val_loss: 0.0550 - val_accuracy: 0.9840\n",
            "\n",
            "Epoch 00151: val_loss did not improve from 0.04374\n",
            "Epoch 152/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0669 - accuracy: 0.9839 - val_loss: 0.0450 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00152: val_loss did not improve from 0.04374\n",
            "Epoch 153/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0544 - accuracy: 0.9852 - val_loss: 0.0461 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00153: val_loss did not improve from 0.04374\n",
            "Epoch 154/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0506 - accuracy: 0.9849 - val_loss: 0.0463 - val_accuracy: 0.9833\n",
            "\n",
            "Epoch 00154: val_loss did not improve from 0.04374\n",
            "Epoch 155/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0643 - accuracy: 0.9823 - val_loss: 0.0435 - val_accuracy: 0.9846\n",
            "\n",
            "Epoch 00155: val_loss improved from 0.04374 to 0.04355, saving model to ./model/0.0435-0.9846-155.hdf5\n",
            "Epoch 156/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0571 - accuracy: 0.9836 - val_loss: 0.0439 - val_accuracy: 0.9846\n",
            "\n",
            "Epoch 00156: val_loss did not improve from 0.04355\n",
            "Epoch 157/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0593 - accuracy: 0.9840 - val_loss: 0.0451 - val_accuracy: 0.9840\n",
            "\n",
            "Epoch 00157: val_loss did not improve from 0.04355\n",
            "Epoch 158/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0527 - accuracy: 0.9857 - val_loss: 0.0458 - val_accuracy: 0.9846\n",
            "\n",
            "Epoch 00158: val_loss did not improve from 0.04355\n",
            "Epoch 159/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0533 - accuracy: 0.9853 - val_loss: 0.0444 - val_accuracy: 0.9840\n",
            "\n",
            "Epoch 00159: val_loss did not improve from 0.04355\n",
            "Epoch 160/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0564 - accuracy: 0.9850 - val_loss: 0.0428 - val_accuracy: 0.9840\n",
            "\n",
            "Epoch 00160: val_loss improved from 0.04355 to 0.04284, saving model to ./model/0.0428-0.9840-160.hdf5\n",
            "Epoch 161/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0489 - accuracy: 0.9863 - val_loss: 0.0462 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00161: val_loss did not improve from 0.04284\n",
            "Epoch 162/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0554 - accuracy: 0.9860 - val_loss: 0.0491 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00162: val_loss did not improve from 0.04284\n",
            "Epoch 163/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0568 - accuracy: 0.9859 - val_loss: 0.0470 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00163: val_loss did not improve from 0.04284\n",
            "Epoch 164/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0574 - accuracy: 0.9828 - val_loss: 0.0443 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00164: val_loss did not improve from 0.04284\n",
            "Epoch 165/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0564 - accuracy: 0.9870 - val_loss: 0.0454 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00165: val_loss did not improve from 0.04284\n",
            "Epoch 166/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0507 - accuracy: 0.9853 - val_loss: 0.0434 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00166: val_loss did not improve from 0.04284\n",
            "Epoch 167/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0501 - accuracy: 0.9852 - val_loss: 0.0460 - val_accuracy: 0.9846\n",
            "\n",
            "Epoch 00167: val_loss did not improve from 0.04284\n",
            "Epoch 168/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0508 - accuracy: 0.9859 - val_loss: 0.0438 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00168: val_loss did not improve from 0.04284\n",
            "Epoch 169/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0503 - accuracy: 0.9856 - val_loss: 0.0485 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00169: val_loss did not improve from 0.04284\n",
            "Epoch 170/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0553 - accuracy: 0.9848 - val_loss: 0.0467 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00170: val_loss did not improve from 0.04284\n",
            "Epoch 171/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0594 - accuracy: 0.9848 - val_loss: 0.0498 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00171: val_loss did not improve from 0.04284\n",
            "Epoch 172/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0572 - accuracy: 0.9852 - val_loss: 0.0423 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00172: val_loss improved from 0.04284 to 0.04227, saving model to ./model/0.0423-0.9853-172.hdf5\n",
            "Epoch 173/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0538 - accuracy: 0.9851 - val_loss: 0.0471 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00173: val_loss did not improve from 0.04227\n",
            "Epoch 174/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0562 - accuracy: 0.9867 - val_loss: 0.0421 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00174: val_loss improved from 0.04227 to 0.04207, saving model to ./model/0.0421-0.9859-174.hdf5\n",
            "Epoch 175/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0460 - accuracy: 0.9864 - val_loss: 0.0421 - val_accuracy: 0.9846\n",
            "\n",
            "Epoch 00175: val_loss did not improve from 0.04207\n",
            "Epoch 176/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0471 - accuracy: 0.9851 - val_loss: 0.0499 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00176: val_loss did not improve from 0.04207\n",
            "Epoch 177/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0589 - accuracy: 0.9842 - val_loss: 0.0713 - val_accuracy: 0.9756\n",
            "\n",
            "Epoch 00177: val_loss did not improve from 0.04207\n",
            "Epoch 178/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0683 - accuracy: 0.9776 - val_loss: 0.0471 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00178: val_loss did not improve from 0.04207\n",
            "Epoch 179/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0438 - accuracy: 0.9866 - val_loss: 0.0444 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00179: val_loss did not improve from 0.04207\n",
            "Epoch 180/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0664 - accuracy: 0.9819 - val_loss: 0.0486 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00180: val_loss did not improve from 0.04207\n",
            "Epoch 181/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0532 - accuracy: 0.9849 - val_loss: 0.0446 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00181: val_loss did not improve from 0.04207\n",
            "Epoch 182/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0560 - accuracy: 0.9832 - val_loss: 0.0415 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00182: val_loss improved from 0.04207 to 0.04146, saving model to ./model/0.0415-0.9853-182.hdf5\n",
            "Epoch 183/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0544 - accuracy: 0.9849 - val_loss: 0.0579 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00183: val_loss did not improve from 0.04146\n",
            "Epoch 184/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0505 - accuracy: 0.9848 - val_loss: 0.0440 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00184: val_loss did not improve from 0.04146\n",
            "Epoch 185/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0536 - accuracy: 0.9841 - val_loss: 0.0417 - val_accuracy: 0.9846\n",
            "\n",
            "Epoch 00185: val_loss did not improve from 0.04146\n",
            "Epoch 186/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0570 - accuracy: 0.9821 - val_loss: 0.0431 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00186: val_loss did not improve from 0.04146\n",
            "Epoch 187/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0532 - accuracy: 0.9876 - val_loss: 0.0432 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00187: val_loss did not improve from 0.04146\n",
            "Epoch 188/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0644 - accuracy: 0.9809 - val_loss: 0.0429 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00188: val_loss did not improve from 0.04146\n",
            "Epoch 189/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0569 - accuracy: 0.9854 - val_loss: 0.0414 - val_accuracy: 0.9846\n",
            "\n",
            "Epoch 00189: val_loss improved from 0.04146 to 0.04135, saving model to ./model/0.0414-0.9846-189.hdf5\n",
            "Epoch 190/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0567 - accuracy: 0.9843 - val_loss: 0.0420 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00190: val_loss did not improve from 0.04135\n",
            "Epoch 191/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0574 - accuracy: 0.9847 - val_loss: 0.0409 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00191: val_loss improved from 0.04135 to 0.04093, saving model to ./model/0.0409-0.9865-191.hdf5\n",
            "Epoch 192/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0628 - accuracy: 0.9838 - val_loss: 0.0489 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00192: val_loss did not improve from 0.04093\n",
            "Epoch 193/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0466 - accuracy: 0.9857 - val_loss: 0.0412 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00193: val_loss did not improve from 0.04093\n",
            "Epoch 194/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0514 - accuracy: 0.9868 - val_loss: 0.0416 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00194: val_loss did not improve from 0.04093\n",
            "Epoch 195/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0441 - accuracy: 0.9876 - val_loss: 0.0719 - val_accuracy: 0.9750\n",
            "\n",
            "Epoch 00195: val_loss did not improve from 0.04093\n",
            "Epoch 196/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0667 - accuracy: 0.9791 - val_loss: 0.0456 - val_accuracy: 0.9833\n",
            "\n",
            "Epoch 00196: val_loss did not improve from 0.04093\n",
            "Epoch 197/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0620 - accuracy: 0.9853 - val_loss: 0.0444 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00197: val_loss did not improve from 0.04093\n",
            "Epoch 198/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0534 - accuracy: 0.9854 - val_loss: 0.0494 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00198: val_loss did not improve from 0.04093\n",
            "Epoch 199/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0556 - accuracy: 0.9860 - val_loss: 0.0633 - val_accuracy: 0.9814\n",
            "\n",
            "Epoch 00199: val_loss did not improve from 0.04093\n",
            "Epoch 200/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0791 - accuracy: 0.9774 - val_loss: 0.0771 - val_accuracy: 0.9756\n",
            "\n",
            "Epoch 00200: val_loss did not improve from 0.04093\n",
            "Epoch 201/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0671 - accuracy: 0.9800 - val_loss: 0.0559 - val_accuracy: 0.9833\n",
            "\n",
            "Epoch 00201: val_loss did not improve from 0.04093\n",
            "Epoch 202/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0528 - accuracy: 0.9863 - val_loss: 0.0404 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00202: val_loss improved from 0.04093 to 0.04035, saving model to ./model/0.0404-0.9865-202.hdf5\n",
            "Epoch 203/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0463 - accuracy: 0.9890 - val_loss: 0.0726 - val_accuracy: 0.9737\n",
            "\n",
            "Epoch 00203: val_loss did not improve from 0.04035\n",
            "Epoch 204/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0951 - accuracy: 0.9697 - val_loss: 0.0552 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00204: val_loss did not improve from 0.04035\n",
            "Epoch 205/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0412 - accuracy: 0.9861 - val_loss: 0.0661 - val_accuracy: 0.9782\n",
            "\n",
            "Epoch 00205: val_loss did not improve from 0.04035\n",
            "Epoch 206/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0576 - accuracy: 0.9844 - val_loss: 0.0419 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00206: val_loss did not improve from 0.04035\n",
            "Epoch 207/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0529 - accuracy: 0.9843 - val_loss: 0.0408 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00207: val_loss did not improve from 0.04035\n",
            "Epoch 208/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0455 - accuracy: 0.9854 - val_loss: 0.0418 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00208: val_loss did not improve from 0.04035\n",
            "Epoch 209/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0346 - accuracy: 0.9903 - val_loss: 0.0500 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00209: val_loss did not improve from 0.04035\n",
            "Epoch 210/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0438 - accuracy: 0.9867 - val_loss: 0.0408 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00210: val_loss did not improve from 0.04035\n",
            "Epoch 211/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0555 - accuracy: 0.9839 - val_loss: 0.0424 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00211: val_loss did not improve from 0.04035\n",
            "Epoch 212/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0432 - accuracy: 0.9861 - val_loss: 0.0536 - val_accuracy: 0.9827\n",
            "\n",
            "Epoch 00212: val_loss did not improve from 0.04035\n",
            "Epoch 213/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0516 - accuracy: 0.9837 - val_loss: 0.0440 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00213: val_loss did not improve from 0.04035\n",
            "Epoch 214/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0607 - accuracy: 0.9793 - val_loss: 0.0439 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00214: val_loss did not improve from 0.04035\n",
            "Epoch 215/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0532 - accuracy: 0.9842 - val_loss: 0.0412 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00215: val_loss did not improve from 0.04035\n",
            "Epoch 216/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0521 - accuracy: 0.9869 - val_loss: 0.0442 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00216: val_loss did not improve from 0.04035\n",
            "Epoch 217/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0604 - accuracy: 0.9823 - val_loss: 0.0484 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00217: val_loss did not improve from 0.04035\n",
            "Epoch 218/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0535 - accuracy: 0.9849 - val_loss: 0.0421 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00218: val_loss did not improve from 0.04035\n",
            "Epoch 219/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0499 - accuracy: 0.9895 - val_loss: 0.0422 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00219: val_loss did not improve from 0.04035\n",
            "Epoch 220/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0512 - accuracy: 0.9874 - val_loss: 0.0412 - val_accuracy: 0.9846\n",
            "\n",
            "Epoch 00220: val_loss did not improve from 0.04035\n",
            "Epoch 221/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0490 - accuracy: 0.9879 - val_loss: 0.0626 - val_accuracy: 0.9808\n",
            "\n",
            "Epoch 00221: val_loss did not improve from 0.04035\n",
            "Epoch 222/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0544 - accuracy: 0.9854 - val_loss: 0.0436 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00222: val_loss did not improve from 0.04035\n",
            "Epoch 223/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0561 - accuracy: 0.9841 - val_loss: 0.0455 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00223: val_loss did not improve from 0.04035\n",
            "Epoch 224/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0420 - accuracy: 0.9895 - val_loss: 0.0399 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00224: val_loss improved from 0.04035 to 0.03991, saving model to ./model/0.0399-0.9853-224.hdf5\n",
            "Epoch 225/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0417 - accuracy: 0.9868 - val_loss: 0.0441 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00225: val_loss did not improve from 0.03991\n",
            "Epoch 226/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0432 - accuracy: 0.9895 - val_loss: 0.0504 - val_accuracy: 0.9846\n",
            "\n",
            "Epoch 00226: val_loss did not improve from 0.03991\n",
            "Epoch 227/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0576 - accuracy: 0.9844 - val_loss: 0.0423 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00227: val_loss did not improve from 0.03991\n",
            "Epoch 228/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0436 - accuracy: 0.9872 - val_loss: 0.0421 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00228: val_loss did not improve from 0.03991\n",
            "Epoch 229/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0470 - accuracy: 0.9860 - val_loss: 0.0430 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00229: val_loss did not improve from 0.03991\n",
            "Epoch 230/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0468 - accuracy: 0.9865 - val_loss: 0.0443 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00230: val_loss did not improve from 0.03991\n",
            "Epoch 231/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0431 - accuracy: 0.9881 - val_loss: 0.0435 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00231: val_loss did not improve from 0.03991\n",
            "Epoch 232/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0428 - accuracy: 0.9889 - val_loss: 0.0404 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00232: val_loss did not improve from 0.03991\n",
            "Epoch 233/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0478 - accuracy: 0.9847 - val_loss: 0.0436 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00233: val_loss did not improve from 0.03991\n",
            "Epoch 234/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0412 - accuracy: 0.9873 - val_loss: 0.0414 - val_accuracy: 0.9846\n",
            "\n",
            "Epoch 00234: val_loss did not improve from 0.03991\n",
            "Epoch 235/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0511 - accuracy: 0.9865 - val_loss: 0.0431 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00235: val_loss did not improve from 0.03991\n",
            "Epoch 236/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0476 - accuracy: 0.9876 - val_loss: 0.0386 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00236: val_loss improved from 0.03991 to 0.03863, saving model to ./model/0.0386-0.9853-236.hdf5\n",
            "Epoch 237/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0534 - accuracy: 0.9849 - val_loss: 0.0625 - val_accuracy: 0.9814\n",
            "\n",
            "Epoch 00237: val_loss did not improve from 0.03863\n",
            "Epoch 238/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0427 - accuracy: 0.9888 - val_loss: 0.0528 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00238: val_loss did not improve from 0.03863\n",
            "Epoch 239/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0553 - accuracy: 0.9837 - val_loss: 0.0436 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00239: val_loss did not improve from 0.03863\n",
            "Epoch 240/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0439 - accuracy: 0.9893 - val_loss: 0.0422 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00240: val_loss did not improve from 0.03863\n",
            "Epoch 241/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0453 - accuracy: 0.9863 - val_loss: 0.0600 - val_accuracy: 0.9827\n",
            "\n",
            "Epoch 00241: val_loss did not improve from 0.03863\n",
            "Epoch 242/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0544 - accuracy: 0.9861 - val_loss: 0.0458 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00242: val_loss did not improve from 0.03863\n",
            "Epoch 243/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0477 - accuracy: 0.9860 - val_loss: 0.0433 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00243: val_loss did not improve from 0.03863\n",
            "Epoch 244/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0673 - accuracy: 0.9809 - val_loss: 0.0417 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00244: val_loss did not improve from 0.03863\n",
            "Epoch 245/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0410 - accuracy: 0.9897 - val_loss: 0.0397 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00245: val_loss did not improve from 0.03863\n",
            "Epoch 246/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0536 - accuracy: 0.9857 - val_loss: 0.0405 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00246: val_loss did not improve from 0.03863\n",
            "Epoch 247/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0597 - accuracy: 0.9817 - val_loss: 0.0463 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00247: val_loss did not improve from 0.03863\n",
            "Epoch 248/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0538 - accuracy: 0.9840 - val_loss: 0.0453 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00248: val_loss did not improve from 0.03863\n",
            "Epoch 249/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0560 - accuracy: 0.9850 - val_loss: 0.0419 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00249: val_loss did not improve from 0.03863\n",
            "Epoch 250/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0508 - accuracy: 0.9841 - val_loss: 0.0441 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00250: val_loss did not improve from 0.03863\n",
            "Epoch 251/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0382 - accuracy: 0.9901 - val_loss: 0.0649 - val_accuracy: 0.9808\n",
            "\n",
            "Epoch 00251: val_loss did not improve from 0.03863\n",
            "Epoch 252/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0547 - accuracy: 0.9835 - val_loss: 0.0418 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00252: val_loss did not improve from 0.03863\n",
            "Epoch 253/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0357 - accuracy: 0.9911 - val_loss: 0.0714 - val_accuracy: 0.9763\n",
            "\n",
            "Epoch 00253: val_loss did not improve from 0.03863\n",
            "Epoch 254/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0624 - accuracy: 0.9825 - val_loss: 0.0389 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00254: val_loss did not improve from 0.03863\n",
            "Epoch 255/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0451 - accuracy: 0.9872 - val_loss: 0.0422 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00255: val_loss did not improve from 0.03863\n",
            "Epoch 256/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0408 - accuracy: 0.9887 - val_loss: 0.0711 - val_accuracy: 0.9756\n",
            "\n",
            "Epoch 00256: val_loss did not improve from 0.03863\n",
            "Epoch 257/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0454 - accuracy: 0.9893 - val_loss: 0.0412 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00257: val_loss did not improve from 0.03863\n",
            "Epoch 258/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0461 - accuracy: 0.9838 - val_loss: 0.0399 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00258: val_loss did not improve from 0.03863\n",
            "Epoch 259/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0497 - accuracy: 0.9833 - val_loss: 0.0405 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00259: val_loss did not improve from 0.03863\n",
            "Epoch 260/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.0414 - accuracy: 0.9888 - val_loss: 0.0481 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00260: val_loss did not improve from 0.03863\n",
            "Epoch 261/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0537 - accuracy: 0.9860 - val_loss: 0.0409 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00261: val_loss did not improve from 0.03863\n",
            "Epoch 262/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0355 - accuracy: 0.9901 - val_loss: 0.0496 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00262: val_loss did not improve from 0.03863\n",
            "Epoch 263/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0440 - accuracy: 0.9884 - val_loss: 0.0420 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00263: val_loss did not improve from 0.03863\n",
            "Epoch 264/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0452 - accuracy: 0.9879 - val_loss: 0.0436 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00264: val_loss did not improve from 0.03863\n",
            "Epoch 265/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0612 - accuracy: 0.9845 - val_loss: 0.0431 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00265: val_loss did not improve from 0.03863\n",
            "Epoch 266/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0391 - accuracy: 0.9884 - val_loss: 0.0939 - val_accuracy: 0.9679\n",
            "\n",
            "Epoch 00266: val_loss did not improve from 0.03863\n",
            "Epoch 267/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0672 - accuracy: 0.9780 - val_loss: 0.0424 - val_accuracy: 0.9846\n",
            "\n",
            "Epoch 00267: val_loss did not improve from 0.03863\n",
            "Epoch 268/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0429 - accuracy: 0.9886 - val_loss: 0.0435 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00268: val_loss did not improve from 0.03863\n",
            "Epoch 269/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0488 - accuracy: 0.9850 - val_loss: 0.0437 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00269: val_loss did not improve from 0.03863\n",
            "Epoch 270/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0501 - accuracy: 0.9859 - val_loss: 0.0560 - val_accuracy: 0.9846\n",
            "\n",
            "Epoch 00270: val_loss did not improve from 0.03863\n",
            "Epoch 271/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0503 - accuracy: 0.9863 - val_loss: 0.0506 - val_accuracy: 0.9840\n",
            "\n",
            "Epoch 00271: val_loss did not improve from 0.03863\n",
            "Epoch 272/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0516 - accuracy: 0.9873 - val_loss: 0.0396 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00272: val_loss did not improve from 0.03863\n",
            "Epoch 273/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0449 - accuracy: 0.9866 - val_loss: 0.0439 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00273: val_loss did not improve from 0.03863\n",
            "Epoch 274/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0646 - accuracy: 0.9829 - val_loss: 0.0475 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00274: val_loss did not improve from 0.03863\n",
            "Epoch 275/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0502 - accuracy: 0.9870 - val_loss: 0.0529 - val_accuracy: 0.9821\n",
            "\n",
            "Epoch 00275: val_loss did not improve from 0.03863\n",
            "Epoch 276/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0556 - accuracy: 0.9854 - val_loss: 0.0599 - val_accuracy: 0.9827\n",
            "\n",
            "Epoch 00276: val_loss did not improve from 0.03863\n",
            "Epoch 277/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0589 - accuracy: 0.9848 - val_loss: 0.0389 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00277: val_loss did not improve from 0.03863\n",
            "Epoch 278/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0379 - accuracy: 0.9902 - val_loss: 0.0483 - val_accuracy: 0.9846\n",
            "\n",
            "Epoch 00278: val_loss did not improve from 0.03863\n",
            "Epoch 279/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0514 - accuracy: 0.9859 - val_loss: 0.0446 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00279: val_loss did not improve from 0.03863\n",
            "Epoch 280/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0449 - accuracy: 0.9867 - val_loss: 0.0409 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00280: val_loss did not improve from 0.03863\n",
            "Epoch 281/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0514 - accuracy: 0.9854 - val_loss: 0.0435 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00281: val_loss did not improve from 0.03863\n",
            "Epoch 282/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0509 - accuracy: 0.9855 - val_loss: 0.0392 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00282: val_loss did not improve from 0.03863\n",
            "Epoch 283/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0454 - accuracy: 0.9858 - val_loss: 0.0399 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00283: val_loss did not improve from 0.03863\n",
            "Epoch 284/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0415 - accuracy: 0.9894 - val_loss: 0.0397 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00284: val_loss did not improve from 0.03863\n",
            "Epoch 285/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0392 - accuracy: 0.9902 - val_loss: 0.0395 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00285: val_loss did not improve from 0.03863\n",
            "Epoch 286/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0517 - accuracy: 0.9859 - val_loss: 0.0415 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00286: val_loss did not improve from 0.03863\n",
            "Epoch 287/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0456 - accuracy: 0.9885 - val_loss: 0.0411 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00287: val_loss did not improve from 0.03863\n",
            "Epoch 288/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0511 - accuracy: 0.9849 - val_loss: 0.0508 - val_accuracy: 0.9846\n",
            "\n",
            "Epoch 00288: val_loss did not improve from 0.03863\n",
            "Epoch 289/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0412 - accuracy: 0.9876 - val_loss: 0.0636 - val_accuracy: 0.9788\n",
            "\n",
            "Epoch 00289: val_loss did not improve from 0.03863\n",
            "Epoch 290/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0481 - accuracy: 0.9868 - val_loss: 0.0401 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00290: val_loss did not improve from 0.03863\n",
            "Epoch 291/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0505 - accuracy: 0.9855 - val_loss: 0.0397 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00291: val_loss did not improve from 0.03863\n",
            "Epoch 292/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0409 - accuracy: 0.9896 - val_loss: 0.0389 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00292: val_loss did not improve from 0.03863\n",
            "Epoch 293/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0428 - accuracy: 0.9862 - val_loss: 0.0408 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00293: val_loss did not improve from 0.03863\n",
            "Epoch 294/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0498 - accuracy: 0.9866 - val_loss: 0.0424 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00294: val_loss did not improve from 0.03863\n",
            "Epoch 295/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0534 - accuracy: 0.9837 - val_loss: 0.0395 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00295: val_loss did not improve from 0.03863\n",
            "Epoch 296/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0562 - accuracy: 0.9840 - val_loss: 0.0455 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00296: val_loss did not improve from 0.03863\n",
            "Epoch 297/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0441 - accuracy: 0.9880 - val_loss: 0.0492 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00297: val_loss did not improve from 0.03863\n",
            "Epoch 298/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0438 - accuracy: 0.9873 - val_loss: 0.0512 - val_accuracy: 0.9846\n",
            "\n",
            "Epoch 00298: val_loss did not improve from 0.03863\n",
            "Epoch 299/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0491 - accuracy: 0.9868 - val_loss: 0.0414 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00299: val_loss did not improve from 0.03863\n",
            "Epoch 300/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0519 - accuracy: 0.9824 - val_loss: 0.0394 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00300: val_loss did not improve from 0.03863\n",
            "Epoch 301/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0419 - accuracy: 0.9877 - val_loss: 0.0389 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00301: val_loss did not improve from 0.03863\n",
            "Epoch 302/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0437 - accuracy: 0.9865 - val_loss: 0.0389 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00302: val_loss did not improve from 0.03863\n",
            "Epoch 303/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0570 - accuracy: 0.9827 - val_loss: 0.0514 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00303: val_loss did not improve from 0.03863\n",
            "Epoch 304/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0489 - accuracy: 0.9851 - val_loss: 0.0384 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00304: val_loss improved from 0.03863 to 0.03838, saving model to ./model/0.0384-0.9865-304.hdf5\n",
            "Epoch 305/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0395 - accuracy: 0.9885 - val_loss: 0.0410 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00305: val_loss did not improve from 0.03838\n",
            "Epoch 306/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0440 - accuracy: 0.9888 - val_loss: 0.0406 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00306: val_loss did not improve from 0.03838\n",
            "Epoch 307/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0454 - accuracy: 0.9880 - val_loss: 0.0422 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00307: val_loss did not improve from 0.03838\n",
            "Epoch 308/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0440 - accuracy: 0.9886 - val_loss: 0.0435 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00308: val_loss did not improve from 0.03838\n",
            "Epoch 309/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0453 - accuracy: 0.9860 - val_loss: 0.0406 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00309: val_loss did not improve from 0.03838\n",
            "Epoch 310/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0518 - accuracy: 0.9848 - val_loss: 0.0388 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00310: val_loss did not improve from 0.03838\n",
            "Epoch 311/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0458 - accuracy: 0.9880 - val_loss: 0.0400 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00311: val_loss did not improve from 0.03838\n",
            "Epoch 312/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0494 - accuracy: 0.9861 - val_loss: 0.0395 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00312: val_loss did not improve from 0.03838\n",
            "Epoch 313/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0454 - accuracy: 0.9872 - val_loss: 0.0427 - val_accuracy: 0.9840\n",
            "\n",
            "Epoch 00313: val_loss did not improve from 0.03838\n",
            "Epoch 314/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0414 - accuracy: 0.9881 - val_loss: 0.0441 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00314: val_loss did not improve from 0.03838\n",
            "Epoch 315/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0475 - accuracy: 0.9871 - val_loss: 0.0501 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00315: val_loss did not improve from 0.03838\n",
            "Epoch 316/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0534 - accuracy: 0.9867 - val_loss: 0.0401 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00316: val_loss did not improve from 0.03838\n",
            "Epoch 317/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0490 - accuracy: 0.9873 - val_loss: 0.0415 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00317: val_loss did not improve from 0.03838\n",
            "Epoch 318/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0421 - accuracy: 0.9867 - val_loss: 0.0422 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00318: val_loss did not improve from 0.03838\n",
            "Epoch 319/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0469 - accuracy: 0.9881 - val_loss: 0.0394 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00319: val_loss did not improve from 0.03838\n",
            "Epoch 320/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0433 - accuracy: 0.9867 - val_loss: 0.0384 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00320: val_loss did not improve from 0.03838\n",
            "Epoch 321/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0622 - accuracy: 0.9819 - val_loss: 0.0552 - val_accuracy: 0.9801\n",
            "\n",
            "Epoch 00321: val_loss did not improve from 0.03838\n",
            "Epoch 322/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0673 - accuracy: 0.9799 - val_loss: 0.0453 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00322: val_loss did not improve from 0.03838\n",
            "Epoch 323/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0549 - accuracy: 0.9823 - val_loss: 0.1052 - val_accuracy: 0.9654\n",
            "\n",
            "Epoch 00323: val_loss did not improve from 0.03838\n",
            "Epoch 324/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0633 - accuracy: 0.9804 - val_loss: 0.0401 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00324: val_loss did not improve from 0.03838\n",
            "Epoch 325/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0391 - accuracy: 0.9879 - val_loss: 0.0392 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00325: val_loss did not improve from 0.03838\n",
            "Epoch 326/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0449 - accuracy: 0.9873 - val_loss: 0.0395 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00326: val_loss did not improve from 0.03838\n",
            "Epoch 327/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0558 - accuracy: 0.9862 - val_loss: 0.0434 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00327: val_loss did not improve from 0.03838\n",
            "Epoch 328/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0447 - accuracy: 0.9889 - val_loss: 0.0382 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00328: val_loss improved from 0.03838 to 0.03815, saving model to ./model/0.0382-0.9865-328.hdf5\n",
            "Epoch 329/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0365 - accuracy: 0.9892 - val_loss: 0.0670 - val_accuracy: 0.9788\n",
            "\n",
            "Epoch 00329: val_loss did not improve from 0.03815\n",
            "Epoch 330/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0508 - accuracy: 0.9854 - val_loss: 0.0410 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00330: val_loss did not improve from 0.03815\n",
            "Epoch 331/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0523 - accuracy: 0.9844 - val_loss: 0.0473 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00331: val_loss did not improve from 0.03815\n",
            "Epoch 332/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0456 - accuracy: 0.9867 - val_loss: 0.0389 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00332: val_loss did not improve from 0.03815\n",
            "Epoch 333/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0375 - accuracy: 0.9887 - val_loss: 0.0396 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00333: val_loss did not improve from 0.03815\n",
            "Epoch 334/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0451 - accuracy: 0.9870 - val_loss: 0.0397 - val_accuracy: 0.9891\n",
            "\n",
            "Epoch 00334: val_loss did not improve from 0.03815\n",
            "Epoch 335/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0468 - accuracy: 0.9870 - val_loss: 0.0459 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00335: val_loss did not improve from 0.03815\n",
            "Epoch 336/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0480 - accuracy: 0.9899 - val_loss: 0.0387 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00336: val_loss did not improve from 0.03815\n",
            "Epoch 337/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0321 - accuracy: 0.9911 - val_loss: 0.0389 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00337: val_loss did not improve from 0.03815\n",
            "Epoch 338/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0427 - accuracy: 0.9866 - val_loss: 0.0539 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00338: val_loss did not improve from 0.03815\n",
            "Epoch 339/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0526 - accuracy: 0.9879 - val_loss: 0.0384 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00339: val_loss did not improve from 0.03815\n",
            "Epoch 340/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0457 - accuracy: 0.9857 - val_loss: 0.0383 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00340: val_loss did not improve from 0.03815\n",
            "Epoch 341/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0370 - accuracy: 0.9911 - val_loss: 0.0392 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00341: val_loss did not improve from 0.03815\n",
            "Epoch 342/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0527 - accuracy: 0.9848 - val_loss: 0.0462 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00342: val_loss did not improve from 0.03815\n",
            "Epoch 343/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0408 - accuracy: 0.9900 - val_loss: 0.0389 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00343: val_loss did not improve from 0.03815\n",
            "Epoch 344/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0460 - accuracy: 0.9867 - val_loss: 0.0381 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00344: val_loss improved from 0.03815 to 0.03810, saving model to ./model/0.0381-0.9865-344.hdf5\n",
            "Epoch 345/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0445 - accuracy: 0.9868 - val_loss: 0.0405 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00345: val_loss did not improve from 0.03810\n",
            "Epoch 346/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0518 - accuracy: 0.9873 - val_loss: 0.0533 - val_accuracy: 0.9846\n",
            "\n",
            "Epoch 00346: val_loss did not improve from 0.03810\n",
            "Epoch 347/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0588 - accuracy: 0.9811 - val_loss: 0.0442 - val_accuracy: 0.9846\n",
            "\n",
            "Epoch 00347: val_loss did not improve from 0.03810\n",
            "Epoch 348/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0476 - accuracy: 0.9869 - val_loss: 0.0469 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00348: val_loss did not improve from 0.03810\n",
            "Epoch 349/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0344 - accuracy: 0.9893 - val_loss: 0.0393 - val_accuracy: 0.9891\n",
            "\n",
            "Epoch 00349: val_loss did not improve from 0.03810\n",
            "Epoch 350/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0435 - accuracy: 0.9885 - val_loss: 0.0417 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00350: val_loss did not improve from 0.03810\n",
            "Epoch 351/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0461 - accuracy: 0.9891 - val_loss: 0.0396 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00351: val_loss did not improve from 0.03810\n",
            "Epoch 352/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0350 - accuracy: 0.9912 - val_loss: 0.0374 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00352: val_loss improved from 0.03810 to 0.03736, saving model to ./model/0.0374-0.9865-352.hdf5\n",
            "Epoch 353/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0470 - accuracy: 0.9847 - val_loss: 0.0389 - val_accuracy: 0.9846\n",
            "\n",
            "Epoch 00353: val_loss did not improve from 0.03736\n",
            "Epoch 354/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0422 - accuracy: 0.9873 - val_loss: 0.0408 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00354: val_loss did not improve from 0.03736\n",
            "Epoch 355/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0403 - accuracy: 0.9890 - val_loss: 0.0398 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00355: val_loss did not improve from 0.03736\n",
            "Epoch 356/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0396 - accuracy: 0.9889 - val_loss: 0.0410 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00356: val_loss did not improve from 0.03736\n",
            "Epoch 357/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0482 - accuracy: 0.9846 - val_loss: 0.0392 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00357: val_loss did not improve from 0.03736\n",
            "Epoch 358/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0483 - accuracy: 0.9880 - val_loss: 0.1181 - val_accuracy: 0.9538\n",
            "\n",
            "Epoch 00358: val_loss did not improve from 0.03736\n",
            "Epoch 359/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0762 - accuracy: 0.9797 - val_loss: 0.0474 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00359: val_loss did not improve from 0.03736\n",
            "Epoch 360/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0609 - accuracy: 0.9809 - val_loss: 0.0376 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00360: val_loss did not improve from 0.03736\n",
            "Epoch 361/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0478 - accuracy: 0.9865 - val_loss: 0.0373 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00361: val_loss improved from 0.03736 to 0.03729, saving model to ./model/0.0373-0.9872-361.hdf5\n",
            "Epoch 362/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0398 - accuracy: 0.9890 - val_loss: 0.0414 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00362: val_loss did not improve from 0.03729\n",
            "Epoch 363/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0424 - accuracy: 0.9887 - val_loss: 0.0388 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00363: val_loss did not improve from 0.03729\n",
            "Epoch 364/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0419 - accuracy: 0.9880 - val_loss: 0.0380 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00364: val_loss did not improve from 0.03729\n",
            "Epoch 365/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0337 - accuracy: 0.9911 - val_loss: 0.0396 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00365: val_loss did not improve from 0.03729\n",
            "Epoch 366/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0444 - accuracy: 0.9859 - val_loss: 0.0378 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00366: val_loss did not improve from 0.03729\n",
            "Epoch 367/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0406 - accuracy: 0.9879 - val_loss: 0.0394 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00367: val_loss did not improve from 0.03729\n",
            "Epoch 368/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0425 - accuracy: 0.9880 - val_loss: 0.0387 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00368: val_loss did not improve from 0.03729\n",
            "Epoch 369/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0480 - accuracy: 0.9881 - val_loss: 0.0388 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00369: val_loss did not improve from 0.03729\n",
            "Epoch 370/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0467 - accuracy: 0.9856 - val_loss: 0.0455 - val_accuracy: 0.9840\n",
            "\n",
            "Epoch 00370: val_loss did not improve from 0.03729\n",
            "Epoch 371/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0398 - accuracy: 0.9877 - val_loss: 0.0667 - val_accuracy: 0.9763\n",
            "\n",
            "Epoch 00371: val_loss did not improve from 0.03729\n",
            "Epoch 372/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0594 - accuracy: 0.9863 - val_loss: 0.0648 - val_accuracy: 0.9776\n",
            "\n",
            "Epoch 00372: val_loss did not improve from 0.03729\n",
            "Epoch 373/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0493 - accuracy: 0.9861 - val_loss: 0.0417 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00373: val_loss did not improve from 0.03729\n",
            "Epoch 374/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0449 - accuracy: 0.9869 - val_loss: 0.0400 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00374: val_loss did not improve from 0.03729\n",
            "Epoch 375/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0460 - accuracy: 0.9879 - val_loss: 0.0407 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00375: val_loss did not improve from 0.03729\n",
            "Epoch 376/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0421 - accuracy: 0.9904 - val_loss: 0.0387 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00376: val_loss did not improve from 0.03729\n",
            "Epoch 377/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0368 - accuracy: 0.9896 - val_loss: 0.0427 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00377: val_loss did not improve from 0.03729\n",
            "Epoch 378/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0456 - accuracy: 0.9885 - val_loss: 0.0379 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00378: val_loss did not improve from 0.03729\n",
            "Epoch 379/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0468 - accuracy: 0.9867 - val_loss: 0.0370 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00379: val_loss improved from 0.03729 to 0.03697, saving model to ./model/0.0370-0.9872-379.hdf5\n",
            "Epoch 380/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0471 - accuracy: 0.9860 - val_loss: 0.0388 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00380: val_loss did not improve from 0.03697\n",
            "Epoch 381/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0372 - accuracy: 0.9904 - val_loss: 0.0507 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00381: val_loss did not improve from 0.03697\n",
            "Epoch 382/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0523 - accuracy: 0.9856 - val_loss: 0.0398 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00382: val_loss did not improve from 0.03697\n",
            "Epoch 383/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0405 - accuracy: 0.9865 - val_loss: 0.0456 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00383: val_loss did not improve from 0.03697\n",
            "Epoch 384/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0410 - accuracy: 0.9884 - val_loss: 0.0397 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00384: val_loss did not improve from 0.03697\n",
            "Epoch 385/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0425 - accuracy: 0.9887 - val_loss: 0.0394 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00385: val_loss did not improve from 0.03697\n",
            "Epoch 386/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0403 - accuracy: 0.9891 - val_loss: 0.0388 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00386: val_loss did not improve from 0.03697\n",
            "Epoch 387/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0412 - accuracy: 0.9890 - val_loss: 0.0401 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00387: val_loss did not improve from 0.03697\n",
            "Epoch 388/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0474 - accuracy: 0.9841 - val_loss: 0.0420 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00388: val_loss did not improve from 0.03697\n",
            "Epoch 389/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0498 - accuracy: 0.9866 - val_loss: 0.0422 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00389: val_loss did not improve from 0.03697\n",
            "Epoch 390/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0562 - accuracy: 0.9839 - val_loss: 0.0376 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00390: val_loss did not improve from 0.03697\n",
            "Epoch 391/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0489 - accuracy: 0.9878 - val_loss: 0.0408 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00391: val_loss did not improve from 0.03697\n",
            "Epoch 392/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0457 - accuracy: 0.9897 - val_loss: 0.0472 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00392: val_loss did not improve from 0.03697\n",
            "Epoch 393/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0472 - accuracy: 0.9866 - val_loss: 0.0390 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00393: val_loss did not improve from 0.03697\n",
            "Epoch 394/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0330 - accuracy: 0.9910 - val_loss: 0.0457 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00394: val_loss did not improve from 0.03697\n",
            "Epoch 395/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0436 - accuracy: 0.9882 - val_loss: 0.0457 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00395: val_loss did not improve from 0.03697\n",
            "Epoch 396/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0426 - accuracy: 0.9889 - val_loss: 0.0417 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00396: val_loss did not improve from 0.03697\n",
            "Epoch 397/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0412 - accuracy: 0.9882 - val_loss: 0.0525 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00397: val_loss did not improve from 0.03697\n",
            "Epoch 398/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0431 - accuracy: 0.9897 - val_loss: 0.0472 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00398: val_loss did not improve from 0.03697\n",
            "Epoch 399/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0504 - accuracy: 0.9865 - val_loss: 0.0396 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00399: val_loss did not improve from 0.03697\n",
            "Epoch 400/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0442 - accuracy: 0.9856 - val_loss: 0.0414 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00400: val_loss did not improve from 0.03697\n",
            "Epoch 401/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0540 - accuracy: 0.9856 - val_loss: 0.0407 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00401: val_loss did not improve from 0.03697\n",
            "Epoch 402/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0394 - accuracy: 0.9892 - val_loss: 0.0403 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00402: val_loss did not improve from 0.03697\n",
            "Epoch 403/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0508 - accuracy: 0.9865 - val_loss: 0.0416 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00403: val_loss did not improve from 0.03697\n",
            "Epoch 404/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0343 - accuracy: 0.9916 - val_loss: 0.0622 - val_accuracy: 0.9808\n",
            "\n",
            "Epoch 00404: val_loss did not improve from 0.03697\n",
            "Epoch 405/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0487 - accuracy: 0.9856 - val_loss: 0.0382 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00405: val_loss did not improve from 0.03697\n",
            "Epoch 406/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0417 - accuracy: 0.9899 - val_loss: 0.0403 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00406: val_loss did not improve from 0.03697\n",
            "Epoch 407/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0496 - accuracy: 0.9855 - val_loss: 0.0433 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00407: val_loss did not improve from 0.03697\n",
            "Epoch 408/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0420 - accuracy: 0.9895 - val_loss: 0.0457 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00408: val_loss did not improve from 0.03697\n",
            "Epoch 409/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0419 - accuracy: 0.9889 - val_loss: 0.0376 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00409: val_loss did not improve from 0.03697\n",
            "Epoch 410/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0485 - accuracy: 0.9873 - val_loss: 0.0378 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00410: val_loss did not improve from 0.03697\n",
            "Epoch 411/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0365 - accuracy: 0.9888 - val_loss: 0.0382 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00411: val_loss did not improve from 0.03697\n",
            "Epoch 412/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0529 - accuracy: 0.9840 - val_loss: 0.0420 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00412: val_loss did not improve from 0.03697\n",
            "Epoch 413/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0652 - accuracy: 0.9840 - val_loss: 0.0438 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00413: val_loss did not improve from 0.03697\n",
            "Epoch 414/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0496 - accuracy: 0.9897 - val_loss: 0.0382 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00414: val_loss did not improve from 0.03697\n",
            "Epoch 415/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0377 - accuracy: 0.9896 - val_loss: 0.0680 - val_accuracy: 0.9776\n",
            "\n",
            "Epoch 00415: val_loss did not improve from 0.03697\n",
            "Epoch 416/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0568 - accuracy: 0.9844 - val_loss: 0.0466 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00416: val_loss did not improve from 0.03697\n",
            "Epoch 417/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0377 - accuracy: 0.9916 - val_loss: 0.0640 - val_accuracy: 0.9795\n",
            "\n",
            "Epoch 00417: val_loss did not improve from 0.03697\n",
            "Epoch 418/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0454 - accuracy: 0.9887 - val_loss: 0.0361 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00418: val_loss improved from 0.03697 to 0.03606, saving model to ./model/0.0361-0.9859-418.hdf5\n",
            "Epoch 419/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0395 - accuracy: 0.9900 - val_loss: 0.0404 - val_accuracy: 0.9846\n",
            "\n",
            "Epoch 00419: val_loss did not improve from 0.03606\n",
            "Epoch 420/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0484 - accuracy: 0.9859 - val_loss: 0.0384 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00420: val_loss did not improve from 0.03606\n",
            "Epoch 421/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0392 - accuracy: 0.9880 - val_loss: 0.0486 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00421: val_loss did not improve from 0.03606\n",
            "Epoch 422/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0516 - accuracy: 0.9874 - val_loss: 0.0388 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00422: val_loss did not improve from 0.03606\n",
            "Epoch 423/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0488 - accuracy: 0.9865 - val_loss: 0.0390 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00423: val_loss did not improve from 0.03606\n",
            "Epoch 424/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0595 - accuracy: 0.9860 - val_loss: 0.0410 - val_accuracy: 0.9891\n",
            "\n",
            "Epoch 00424: val_loss did not improve from 0.03606\n",
            "Epoch 425/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0450 - accuracy: 0.9879 - val_loss: 0.0431 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00425: val_loss did not improve from 0.03606\n",
            "Epoch 426/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0388 - accuracy: 0.9910 - val_loss: 0.0407 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00426: val_loss did not improve from 0.03606\n",
            "Epoch 427/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0460 - accuracy: 0.9875 - val_loss: 0.0388 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00427: val_loss did not improve from 0.03606\n",
            "Epoch 428/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0475 - accuracy: 0.9880 - val_loss: 0.0408 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00428: val_loss did not improve from 0.03606\n",
            "Epoch 429/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0453 - accuracy: 0.9898 - val_loss: 0.0378 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00429: val_loss did not improve from 0.03606\n",
            "Epoch 430/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0412 - accuracy: 0.9883 - val_loss: 0.0385 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00430: val_loss did not improve from 0.03606\n",
            "Epoch 431/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0375 - accuracy: 0.9893 - val_loss: 0.0507 - val_accuracy: 0.9840\n",
            "\n",
            "Epoch 00431: val_loss did not improve from 0.03606\n",
            "Epoch 432/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0583 - accuracy: 0.9824 - val_loss: 0.0514 - val_accuracy: 0.9840\n",
            "\n",
            "Epoch 00432: val_loss did not improve from 0.03606\n",
            "Epoch 433/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0611 - accuracy: 0.9826 - val_loss: 0.0578 - val_accuracy: 0.9801\n",
            "\n",
            "Epoch 00433: val_loss did not improve from 0.03606\n",
            "Epoch 434/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0694 - accuracy: 0.9832 - val_loss: 0.0402 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00434: val_loss did not improve from 0.03606\n",
            "Epoch 435/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0476 - accuracy: 0.9863 - val_loss: 0.0459 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00435: val_loss did not improve from 0.03606\n",
            "Epoch 436/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0485 - accuracy: 0.9865 - val_loss: 0.0369 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00436: val_loss did not improve from 0.03606\n",
            "Epoch 437/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0379 - accuracy: 0.9902 - val_loss: 0.0405 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00437: val_loss did not improve from 0.03606\n",
            "Epoch 438/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0396 - accuracy: 0.9898 - val_loss: 0.0391 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00438: val_loss did not improve from 0.03606\n",
            "Epoch 439/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0476 - accuracy: 0.9879 - val_loss: 0.0389 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00439: val_loss did not improve from 0.03606\n",
            "Epoch 440/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0513 - accuracy: 0.9860 - val_loss: 0.0378 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00440: val_loss did not improve from 0.03606\n",
            "Epoch 441/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0483 - accuracy: 0.9866 - val_loss: 0.0398 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00441: val_loss did not improve from 0.03606\n",
            "Epoch 442/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0469 - accuracy: 0.9887 - val_loss: 0.0430 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00442: val_loss did not improve from 0.03606\n",
            "Epoch 443/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0496 - accuracy: 0.9878 - val_loss: 0.0431 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00443: val_loss did not improve from 0.03606\n",
            "Epoch 444/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0419 - accuracy: 0.9897 - val_loss: 0.0380 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00444: val_loss did not improve from 0.03606\n",
            "Epoch 445/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0350 - accuracy: 0.9907 - val_loss: 0.0459 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00445: val_loss did not improve from 0.03606\n",
            "Epoch 446/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0481 - accuracy: 0.9883 - val_loss: 0.0405 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00446: val_loss did not improve from 0.03606\n",
            "Epoch 447/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0496 - accuracy: 0.9851 - val_loss: 0.0435 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00447: val_loss did not improve from 0.03606\n",
            "Epoch 448/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0589 - accuracy: 0.9842 - val_loss: 0.0446 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00448: val_loss did not improve from 0.03606\n",
            "Epoch 449/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0425 - accuracy: 0.9879 - val_loss: 0.0356 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00449: val_loss improved from 0.03606 to 0.03557, saving model to ./model/0.0356-0.9865-449.hdf5\n",
            "Epoch 450/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0478 - accuracy: 0.9873 - val_loss: 0.0433 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00450: val_loss did not improve from 0.03557\n",
            "Epoch 451/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0440 - accuracy: 0.9883 - val_loss: 0.0377 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00451: val_loss did not improve from 0.03557\n",
            "Epoch 452/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0481 - accuracy: 0.9863 - val_loss: 0.0406 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00452: val_loss did not improve from 0.03557\n",
            "Epoch 453/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0390 - accuracy: 0.9881 - val_loss: 0.0373 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00453: val_loss did not improve from 0.03557\n",
            "Epoch 454/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0329 - accuracy: 0.9899 - val_loss: 0.0391 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00454: val_loss did not improve from 0.03557\n",
            "Epoch 455/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0309 - accuracy: 0.9915 - val_loss: 0.0376 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00455: val_loss did not improve from 0.03557\n",
            "Epoch 456/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0466 - accuracy: 0.9885 - val_loss: 0.0377 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00456: val_loss did not improve from 0.03557\n",
            "Epoch 457/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0488 - accuracy: 0.9878 - val_loss: 0.0373 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00457: val_loss did not improve from 0.03557\n",
            "Epoch 458/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0361 - accuracy: 0.9914 - val_loss: 0.0411 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00458: val_loss did not improve from 0.03557\n",
            "Epoch 459/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0446 - accuracy: 0.9895 - val_loss: 0.0519 - val_accuracy: 0.9827\n",
            "\n",
            "Epoch 00459: val_loss did not improve from 0.03557\n",
            "Epoch 460/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0433 - accuracy: 0.9883 - val_loss: 0.0411 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00460: val_loss did not improve from 0.03557\n",
            "Epoch 461/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0410 - accuracy: 0.9893 - val_loss: 0.0501 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00461: val_loss did not improve from 0.03557\n",
            "Epoch 462/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0455 - accuracy: 0.9875 - val_loss: 0.0495 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00462: val_loss did not improve from 0.03557\n",
            "Epoch 463/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0616 - accuracy: 0.9841 - val_loss: 0.0474 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00463: val_loss did not improve from 0.03557\n",
            "Epoch 464/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0449 - accuracy: 0.9885 - val_loss: 0.0493 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00464: val_loss did not improve from 0.03557\n",
            "Epoch 465/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0461 - accuracy: 0.9889 - val_loss: 0.0431 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00465: val_loss did not improve from 0.03557\n",
            "Epoch 466/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0441 - accuracy: 0.9880 - val_loss: 0.0399 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00466: val_loss did not improve from 0.03557\n",
            "Epoch 467/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0409 - accuracy: 0.9895 - val_loss: 0.0398 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00467: val_loss did not improve from 0.03557\n",
            "Epoch 468/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0387 - accuracy: 0.9899 - val_loss: 0.0386 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00468: val_loss did not improve from 0.03557\n",
            "Epoch 469/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0454 - accuracy: 0.9870 - val_loss: 0.0852 - val_accuracy: 0.9724\n",
            "\n",
            "Epoch 00469: val_loss did not improve from 0.03557\n",
            "Epoch 470/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0613 - accuracy: 0.9861 - val_loss: 0.0389 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00470: val_loss did not improve from 0.03557\n",
            "Epoch 471/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0526 - accuracy: 0.9853 - val_loss: 0.0412 - val_accuracy: 0.9891\n",
            "\n",
            "Epoch 00471: val_loss did not improve from 0.03557\n",
            "Epoch 472/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0470 - accuracy: 0.9867 - val_loss: 0.0419 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00472: val_loss did not improve from 0.03557\n",
            "Epoch 473/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0439 - accuracy: 0.9861 - val_loss: 0.0377 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00473: val_loss did not improve from 0.03557\n",
            "Epoch 474/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0489 - accuracy: 0.9848 - val_loss: 0.0395 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00474: val_loss did not improve from 0.03557\n",
            "Epoch 475/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0378 - accuracy: 0.9909 - val_loss: 0.0409 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00475: val_loss did not improve from 0.03557\n",
            "Epoch 476/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0441 - accuracy: 0.9884 - val_loss: 0.0720 - val_accuracy: 0.9769\n",
            "\n",
            "Epoch 00476: val_loss did not improve from 0.03557\n",
            "Epoch 477/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0581 - accuracy: 0.9838 - val_loss: 0.0548 - val_accuracy: 0.9846\n",
            "\n",
            "Epoch 00477: val_loss did not improve from 0.03557\n",
            "Epoch 478/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0566 - accuracy: 0.9865 - val_loss: 0.0374 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00478: val_loss did not improve from 0.03557\n",
            "Epoch 479/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0361 - accuracy: 0.9905 - val_loss: 0.0377 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00479: val_loss did not improve from 0.03557\n",
            "Epoch 480/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0358 - accuracy: 0.9903 - val_loss: 0.0453 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00480: val_loss did not improve from 0.03557\n",
            "Epoch 481/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0332 - accuracy: 0.9923 - val_loss: 0.0407 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00481: val_loss did not improve from 0.03557\n",
            "Epoch 482/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0433 - accuracy: 0.9908 - val_loss: 0.0397 - val_accuracy: 0.9891\n",
            "\n",
            "Epoch 00482: val_loss did not improve from 0.03557\n",
            "Epoch 483/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0429 - accuracy: 0.9868 - val_loss: 0.0379 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00483: val_loss did not improve from 0.03557\n",
            "Epoch 484/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0472 - accuracy: 0.9865 - val_loss: 0.0402 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00484: val_loss did not improve from 0.03557\n",
            "Epoch 485/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0437 - accuracy: 0.9874 - val_loss: 0.0818 - val_accuracy: 0.9718\n",
            "\n",
            "Epoch 00485: val_loss did not improve from 0.03557\n",
            "Epoch 486/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0434 - accuracy: 0.9883 - val_loss: 0.0376 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00486: val_loss did not improve from 0.03557\n",
            "Epoch 487/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0340 - accuracy: 0.9904 - val_loss: 0.0443 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00487: val_loss did not improve from 0.03557\n",
            "Epoch 488/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0422 - accuracy: 0.9902 - val_loss: 0.0399 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00488: val_loss did not improve from 0.03557\n",
            "Epoch 489/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0401 - accuracy: 0.9881 - val_loss: 0.0395 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00489: val_loss did not improve from 0.03557\n",
            "Epoch 490/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0405 - accuracy: 0.9896 - val_loss: 0.0386 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00490: val_loss did not improve from 0.03557\n",
            "Epoch 491/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0389 - accuracy: 0.9917 - val_loss: 0.0792 - val_accuracy: 0.9724\n",
            "\n",
            "Epoch 00491: val_loss did not improve from 0.03557\n",
            "Epoch 492/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0551 - accuracy: 0.9821 - val_loss: 0.0414 - val_accuracy: 0.9846\n",
            "\n",
            "Epoch 00492: val_loss did not improve from 0.03557\n",
            "Epoch 493/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0393 - accuracy: 0.9912 - val_loss: 0.0370 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00493: val_loss did not improve from 0.03557\n",
            "Epoch 494/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0428 - accuracy: 0.9896 - val_loss: 0.0372 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00494: val_loss did not improve from 0.03557\n",
            "Epoch 495/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0298 - accuracy: 0.9929 - val_loss: 0.0558 - val_accuracy: 0.9840\n",
            "\n",
            "Epoch 00495: val_loss did not improve from 0.03557\n",
            "Epoch 496/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0448 - accuracy: 0.9867 - val_loss: 0.0501 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00496: val_loss did not improve from 0.03557\n",
            "Epoch 497/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0438 - accuracy: 0.9893 - val_loss: 0.0406 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00497: val_loss did not improve from 0.03557\n",
            "Epoch 498/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0523 - accuracy: 0.9864 - val_loss: 0.0386 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00498: val_loss did not improve from 0.03557\n",
            "Epoch 499/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0344 - accuracy: 0.9909 - val_loss: 0.0378 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00499: val_loss did not improve from 0.03557\n",
            "Epoch 500/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0463 - accuracy: 0.9872 - val_loss: 0.0418 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00500: val_loss did not improve from 0.03557\n",
            "Epoch 501/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0458 - accuracy: 0.9874 - val_loss: 0.0443 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00501: val_loss did not improve from 0.03557\n",
            "Epoch 502/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0438 - accuracy: 0.9877 - val_loss: 0.0523 - val_accuracy: 0.9827\n",
            "\n",
            "Epoch 00502: val_loss did not improve from 0.03557\n",
            "Epoch 503/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0367 - accuracy: 0.9896 - val_loss: 0.0367 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00503: val_loss did not improve from 0.03557\n",
            "Epoch 504/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0400 - accuracy: 0.9880 - val_loss: 0.0517 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00504: val_loss did not improve from 0.03557\n",
            "Epoch 505/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0497 - accuracy: 0.9870 - val_loss: 0.0353 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00505: val_loss improved from 0.03557 to 0.03535, saving model to ./model/0.0353-0.9872-505.hdf5\n",
            "Epoch 506/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0418 - accuracy: 0.9884 - val_loss: 0.0391 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00506: val_loss did not improve from 0.03535\n",
            "Epoch 507/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0462 - accuracy: 0.9869 - val_loss: 0.0458 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00507: val_loss did not improve from 0.03535\n",
            "Epoch 508/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0478 - accuracy: 0.9854 - val_loss: 0.0381 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00508: val_loss did not improve from 0.03535\n",
            "Epoch 509/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0402 - accuracy: 0.9894 - val_loss: 0.0375 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00509: val_loss did not improve from 0.03535\n",
            "Epoch 510/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0442 - accuracy: 0.9875 - val_loss: 0.0406 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00510: val_loss did not improve from 0.03535\n",
            "Epoch 511/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0387 - accuracy: 0.9891 - val_loss: 0.0435 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00511: val_loss did not improve from 0.03535\n",
            "Epoch 512/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0475 - accuracy: 0.9865 - val_loss: 0.0436 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00512: val_loss did not improve from 0.03535\n",
            "Epoch 513/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0496 - accuracy: 0.9868 - val_loss: 0.0490 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00513: val_loss did not improve from 0.03535\n",
            "Epoch 514/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0459 - accuracy: 0.9883 - val_loss: 0.0381 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00514: val_loss did not improve from 0.03535\n",
            "Epoch 515/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0419 - accuracy: 0.9888 - val_loss: 0.0361 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00515: val_loss did not improve from 0.03535\n",
            "Epoch 516/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0490 - accuracy: 0.9868 - val_loss: 0.0461 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00516: val_loss did not improve from 0.03535\n",
            "Epoch 517/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0409 - accuracy: 0.9892 - val_loss: 0.0360 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00517: val_loss did not improve from 0.03535\n",
            "Epoch 518/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0794 - accuracy: 0.9777 - val_loss: 0.0406 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00518: val_loss did not improve from 0.03535\n",
            "Epoch 519/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0407 - accuracy: 0.9891 - val_loss: 0.0369 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00519: val_loss did not improve from 0.03535\n",
            "Epoch 520/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0407 - accuracy: 0.9881 - val_loss: 0.0378 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00520: val_loss did not improve from 0.03535\n",
            "Epoch 521/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0421 - accuracy: 0.9891 - val_loss: 0.0619 - val_accuracy: 0.9814\n",
            "\n",
            "Epoch 00521: val_loss did not improve from 0.03535\n",
            "Epoch 522/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0441 - accuracy: 0.9873 - val_loss: 0.0387 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00522: val_loss did not improve from 0.03535\n",
            "Epoch 523/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0589 - accuracy: 0.9853 - val_loss: 0.0373 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00523: val_loss did not improve from 0.03535\n",
            "Epoch 524/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0437 - accuracy: 0.9869 - val_loss: 0.0371 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00524: val_loss did not improve from 0.03535\n",
            "Epoch 525/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0392 - accuracy: 0.9892 - val_loss: 0.0372 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00525: val_loss did not improve from 0.03535\n",
            "Epoch 526/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0427 - accuracy: 0.9889 - val_loss: 0.0378 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00526: val_loss did not improve from 0.03535\n",
            "Epoch 527/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0454 - accuracy: 0.9891 - val_loss: 0.0413 - val_accuracy: 0.9833\n",
            "\n",
            "Epoch 00527: val_loss did not improve from 0.03535\n",
            "Epoch 528/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0565 - accuracy: 0.9811 - val_loss: 0.0414 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00528: val_loss did not improve from 0.03535\n",
            "Epoch 529/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0493 - accuracy: 0.9891 - val_loss: 0.0428 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00529: val_loss did not improve from 0.03535\n",
            "Epoch 530/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0529 - accuracy: 0.9854 - val_loss: 0.0360 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00530: val_loss did not improve from 0.03535\n",
            "Epoch 531/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0395 - accuracy: 0.9900 - val_loss: 0.0354 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00531: val_loss did not improve from 0.03535\n",
            "Epoch 532/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0501 - accuracy: 0.9871 - val_loss: 0.0374 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00532: val_loss did not improve from 0.03535\n",
            "Epoch 533/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0406 - accuracy: 0.9901 - val_loss: 0.0362 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00533: val_loss did not improve from 0.03535\n",
            "Epoch 534/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0579 - accuracy: 0.9828 - val_loss: 0.0359 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00534: val_loss did not improve from 0.03535\n",
            "Epoch 535/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0412 - accuracy: 0.9862 - val_loss: 0.0428 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00535: val_loss did not improve from 0.03535\n",
            "Epoch 536/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0550 - accuracy: 0.9872 - val_loss: 0.0438 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00536: val_loss did not improve from 0.03535\n",
            "Epoch 537/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0571 - accuracy: 0.9836 - val_loss: 0.0385 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00537: val_loss did not improve from 0.03535\n",
            "Epoch 538/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0397 - accuracy: 0.9888 - val_loss: 0.0361 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00538: val_loss did not improve from 0.03535\n",
            "Epoch 539/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0393 - accuracy: 0.9884 - val_loss: 0.0443 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00539: val_loss did not improve from 0.03535\n",
            "Epoch 540/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0495 - accuracy: 0.9866 - val_loss: 0.0405 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00540: val_loss did not improve from 0.03535\n",
            "Epoch 541/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0455 - accuracy: 0.9884 - val_loss: 0.0417 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00541: val_loss did not improve from 0.03535\n",
            "Epoch 542/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0456 - accuracy: 0.9855 - val_loss: 0.0372 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00542: val_loss did not improve from 0.03535\n",
            "Epoch 543/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0385 - accuracy: 0.9895 - val_loss: 0.0385 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00543: val_loss did not improve from 0.03535\n",
            "Epoch 544/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0326 - accuracy: 0.9912 - val_loss: 0.0363 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00544: val_loss did not improve from 0.03535\n",
            "Epoch 545/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0362 - accuracy: 0.9918 - val_loss: 0.0386 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00545: val_loss did not improve from 0.03535\n",
            "Epoch 546/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0412 - accuracy: 0.9900 - val_loss: 0.0355 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00546: val_loss did not improve from 0.03535\n",
            "Epoch 547/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0434 - accuracy: 0.9865 - val_loss: 0.0357 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00547: val_loss did not improve from 0.03535\n",
            "Epoch 548/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0430 - accuracy: 0.9884 - val_loss: 0.0371 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00548: val_loss did not improve from 0.03535\n",
            "Epoch 549/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0356 - accuracy: 0.9917 - val_loss: 0.0378 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00549: val_loss did not improve from 0.03535\n",
            "Epoch 550/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0398 - accuracy: 0.9907 - val_loss: 0.0407 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00550: val_loss did not improve from 0.03535\n",
            "Epoch 551/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0414 - accuracy: 0.9881 - val_loss: 0.0383 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00551: val_loss did not improve from 0.03535\n",
            "Epoch 552/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0338 - accuracy: 0.9909 - val_loss: 0.0360 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00552: val_loss did not improve from 0.03535\n",
            "Epoch 553/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0431 - accuracy: 0.9883 - val_loss: 0.0467 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00553: val_loss did not improve from 0.03535\n",
            "Epoch 554/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0393 - accuracy: 0.9897 - val_loss: 0.0362 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00554: val_loss did not improve from 0.03535\n",
            "Epoch 555/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0437 - accuracy: 0.9885 - val_loss: 0.0376 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00555: val_loss did not improve from 0.03535\n",
            "Epoch 556/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0460 - accuracy: 0.9890 - val_loss: 0.0386 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00556: val_loss did not improve from 0.03535\n",
            "Epoch 557/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0320 - accuracy: 0.9918 - val_loss: 0.0468 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00557: val_loss did not improve from 0.03535\n",
            "Epoch 558/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0497 - accuracy: 0.9863 - val_loss: 0.0497 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00558: val_loss did not improve from 0.03535\n",
            "Epoch 559/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0400 - accuracy: 0.9894 - val_loss: 0.0596 - val_accuracy: 0.9808\n",
            "\n",
            "Epoch 00559: val_loss did not improve from 0.03535\n",
            "Epoch 560/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0581 - accuracy: 0.9847 - val_loss: 0.0357 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00560: val_loss did not improve from 0.03535\n",
            "Epoch 561/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0402 - accuracy: 0.9881 - val_loss: 0.0384 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00561: val_loss did not improve from 0.03535\n",
            "Epoch 562/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0395 - accuracy: 0.9890 - val_loss: 0.0376 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00562: val_loss did not improve from 0.03535\n",
            "Epoch 563/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0402 - accuracy: 0.9893 - val_loss: 0.0385 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00563: val_loss did not improve from 0.03535\n",
            "Epoch 564/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0427 - accuracy: 0.9891 - val_loss: 0.0365 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00564: val_loss did not improve from 0.03535\n",
            "Epoch 565/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0457 - accuracy: 0.9880 - val_loss: 0.0385 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00565: val_loss did not improve from 0.03535\n",
            "Epoch 566/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0460 - accuracy: 0.9894 - val_loss: 0.0402 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00566: val_loss did not improve from 0.03535\n",
            "Epoch 567/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0467 - accuracy: 0.9869 - val_loss: 0.0370 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00567: val_loss did not improve from 0.03535\n",
            "Epoch 568/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0391 - accuracy: 0.9892 - val_loss: 0.0367 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00568: val_loss did not improve from 0.03535\n",
            "Epoch 569/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0486 - accuracy: 0.9881 - val_loss: 0.0388 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00569: val_loss did not improve from 0.03535\n",
            "Epoch 570/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0501 - accuracy: 0.9882 - val_loss: 0.0384 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00570: val_loss did not improve from 0.03535\n",
            "Epoch 571/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0438 - accuracy: 0.9892 - val_loss: 0.0380 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00571: val_loss did not improve from 0.03535\n",
            "Epoch 572/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0431 - accuracy: 0.9886 - val_loss: 0.0434 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00572: val_loss did not improve from 0.03535\n",
            "Epoch 573/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0388 - accuracy: 0.9899 - val_loss: 0.0378 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00573: val_loss did not improve from 0.03535\n",
            "Epoch 574/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0373 - accuracy: 0.9902 - val_loss: 0.0370 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00574: val_loss did not improve from 0.03535\n",
            "Epoch 575/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0369 - accuracy: 0.9918 - val_loss: 0.0377 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00575: val_loss did not improve from 0.03535\n",
            "Epoch 576/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0443 - accuracy: 0.9877 - val_loss: 0.0404 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00576: val_loss did not improve from 0.03535\n",
            "Epoch 577/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0416 - accuracy: 0.9892 - val_loss: 0.0399 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00577: val_loss did not improve from 0.03535\n",
            "Epoch 578/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0462 - accuracy: 0.9858 - val_loss: 0.0358 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00578: val_loss did not improve from 0.03535\n",
            "Epoch 579/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0359 - accuracy: 0.9882 - val_loss: 0.0373 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00579: val_loss did not improve from 0.03535\n",
            "Epoch 580/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0355 - accuracy: 0.9894 - val_loss: 0.0379 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00580: val_loss did not improve from 0.03535\n",
            "Epoch 581/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0399 - accuracy: 0.9878 - val_loss: 0.0608 - val_accuracy: 0.9814\n",
            "\n",
            "Epoch 00581: val_loss did not improve from 0.03535\n",
            "Epoch 582/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0479 - accuracy: 0.9830 - val_loss: 0.0438 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00582: val_loss did not improve from 0.03535\n",
            "Epoch 583/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0433 - accuracy: 0.9877 - val_loss: 0.0378 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00583: val_loss did not improve from 0.03535\n",
            "Epoch 584/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0420 - accuracy: 0.9901 - val_loss: 0.0361 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00584: val_loss did not improve from 0.03535\n",
            "Epoch 585/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0414 - accuracy: 0.9901 - val_loss: 0.0406 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00585: val_loss did not improve from 0.03535\n",
            "Epoch 586/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0385 - accuracy: 0.9883 - val_loss: 0.0369 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00586: val_loss did not improve from 0.03535\n",
            "Epoch 587/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0322 - accuracy: 0.9915 - val_loss: 0.0380 - val_accuracy: 0.9891\n",
            "\n",
            "Epoch 00587: val_loss did not improve from 0.03535\n",
            "Epoch 588/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0440 - accuracy: 0.9881 - val_loss: 0.0417 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00588: val_loss did not improve from 0.03535\n",
            "Epoch 589/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0344 - accuracy: 0.9916 - val_loss: 0.0360 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00589: val_loss did not improve from 0.03535\n",
            "Epoch 590/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0403 - accuracy: 0.9899 - val_loss: 0.0375 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00590: val_loss did not improve from 0.03535\n",
            "Epoch 591/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0316 - accuracy: 0.9892 - val_loss: 0.0421 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00591: val_loss did not improve from 0.03535\n",
            "Epoch 592/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0456 - accuracy: 0.9908 - val_loss: 0.0366 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00592: val_loss did not improve from 0.03535\n",
            "Epoch 593/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0364 - accuracy: 0.9892 - val_loss: 0.0381 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00593: val_loss did not improve from 0.03535\n",
            "Epoch 594/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0378 - accuracy: 0.9894 - val_loss: 0.0458 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00594: val_loss did not improve from 0.03535\n",
            "Epoch 595/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0444 - accuracy: 0.9886 - val_loss: 0.0376 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00595: val_loss did not improve from 0.03535\n",
            "Epoch 596/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0454 - accuracy: 0.9878 - val_loss: 0.0419 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00596: val_loss did not improve from 0.03535\n",
            "Epoch 597/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0415 - accuracy: 0.9892 - val_loss: 0.0677 - val_accuracy: 0.9782\n",
            "\n",
            "Epoch 00597: val_loss did not improve from 0.03535\n",
            "Epoch 598/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0519 - accuracy: 0.9837 - val_loss: 0.0399 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00598: val_loss did not improve from 0.03535\n",
            "Epoch 599/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0399 - accuracy: 0.9897 - val_loss: 0.0509 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00599: val_loss did not improve from 0.03535\n",
            "Epoch 600/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0548 - accuracy: 0.9854 - val_loss: 0.0396 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00600: val_loss did not improve from 0.03535\n",
            "Epoch 601/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0469 - accuracy: 0.9872 - val_loss: 0.0371 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00601: val_loss did not improve from 0.03535\n",
            "Epoch 602/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0387 - accuracy: 0.9878 - val_loss: 0.0403 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00602: val_loss did not improve from 0.03535\n",
            "Epoch 603/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0334 - accuracy: 0.9921 - val_loss: 0.0362 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00603: val_loss did not improve from 0.03535\n",
            "Epoch 604/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0434 - accuracy: 0.9890 - val_loss: 0.0390 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00604: val_loss did not improve from 0.03535\n",
            "Epoch 605/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0390 - accuracy: 0.9896 - val_loss: 0.0386 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00605: val_loss did not improve from 0.03535\n",
            "Epoch 606/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0442 - accuracy: 0.9901 - val_loss: 0.0425 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00606: val_loss did not improve from 0.03535\n",
            "Epoch 607/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0407 - accuracy: 0.9866 - val_loss: 0.0445 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00607: val_loss did not improve from 0.03535\n",
            "Epoch 608/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0534 - accuracy: 0.9840 - val_loss: 0.0359 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00608: val_loss did not improve from 0.03535\n",
            "Epoch 609/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0413 - accuracy: 0.9890 - val_loss: 0.0687 - val_accuracy: 0.9814\n",
            "\n",
            "Epoch 00609: val_loss did not improve from 0.03535\n",
            "Epoch 610/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0580 - accuracy: 0.9879 - val_loss: 0.0472 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00610: val_loss did not improve from 0.03535\n",
            "Epoch 611/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0414 - accuracy: 0.9904 - val_loss: 0.0385 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00611: val_loss did not improve from 0.03535\n",
            "Epoch 612/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0361 - accuracy: 0.9894 - val_loss: 0.0365 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00612: val_loss did not improve from 0.03535\n",
            "Epoch 613/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0394 - accuracy: 0.9863 - val_loss: 0.0382 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00613: val_loss did not improve from 0.03535\n",
            "Epoch 614/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0397 - accuracy: 0.9891 - val_loss: 0.0376 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00614: val_loss did not improve from 0.03535\n",
            "Epoch 615/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0367 - accuracy: 0.9892 - val_loss: 0.0417 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00615: val_loss did not improve from 0.03535\n",
            "Epoch 616/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0321 - accuracy: 0.9908 - val_loss: 0.0446 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00616: val_loss did not improve from 0.03535\n",
            "Epoch 617/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0597 - accuracy: 0.9837 - val_loss: 0.0404 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00617: val_loss did not improve from 0.03535\n",
            "Epoch 618/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0305 - accuracy: 0.9910 - val_loss: 0.0391 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00618: val_loss did not improve from 0.03535\n",
            "Epoch 619/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0401 - accuracy: 0.9898 - val_loss: 0.0552 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00619: val_loss did not improve from 0.03535\n",
            "Epoch 620/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0467 - accuracy: 0.9886 - val_loss: 0.0366 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00620: val_loss did not improve from 0.03535\n",
            "Epoch 621/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0421 - accuracy: 0.9907 - val_loss: 0.0393 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00621: val_loss did not improve from 0.03535\n",
            "Epoch 622/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0425 - accuracy: 0.9880 - val_loss: 0.0419 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00622: val_loss did not improve from 0.03535\n",
            "Epoch 623/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0392 - accuracy: 0.9898 - val_loss: 0.0502 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00623: val_loss did not improve from 0.03535\n",
            "Epoch 624/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0471 - accuracy: 0.9890 - val_loss: 0.0386 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00624: val_loss did not improve from 0.03535\n",
            "Epoch 625/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0460 - accuracy: 0.9882 - val_loss: 0.0374 - val_accuracy: 0.9891\n",
            "\n",
            "Epoch 00625: val_loss did not improve from 0.03535\n",
            "Epoch 626/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0336 - accuracy: 0.9909 - val_loss: 0.0366 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00626: val_loss did not improve from 0.03535\n",
            "Epoch 627/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0500 - accuracy: 0.9865 - val_loss: 0.0384 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00627: val_loss did not improve from 0.03535\n",
            "Epoch 628/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0413 - accuracy: 0.9900 - val_loss: 0.0367 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00628: val_loss did not improve from 0.03535\n",
            "Epoch 629/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0408 - accuracy: 0.9903 - val_loss: 0.0404 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00629: val_loss did not improve from 0.03535\n",
            "Epoch 630/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0468 - accuracy: 0.9859 - val_loss: 0.0528 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00630: val_loss did not improve from 0.03535\n",
            "Epoch 631/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0529 - accuracy: 0.9858 - val_loss: 0.0427 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00631: val_loss did not improve from 0.03535\n",
            "Epoch 632/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0485 - accuracy: 0.9875 - val_loss: 0.0391 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00632: val_loss did not improve from 0.03535\n",
            "Epoch 633/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0379 - accuracy: 0.9904 - val_loss: 0.0345 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00633: val_loss improved from 0.03535 to 0.03455, saving model to ./model/0.0345-0.9885-633.hdf5\n",
            "Epoch 634/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0340 - accuracy: 0.9910 - val_loss: 0.0400 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00634: val_loss did not improve from 0.03455\n",
            "Epoch 635/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0317 - accuracy: 0.9906 - val_loss: 0.0471 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00635: val_loss did not improve from 0.03455\n",
            "Epoch 636/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0461 - accuracy: 0.9860 - val_loss: 0.0433 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00636: val_loss did not improve from 0.03455\n",
            "Epoch 637/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0463 - accuracy: 0.9880 - val_loss: 0.0395 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00637: val_loss did not improve from 0.03455\n",
            "Epoch 638/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0451 - accuracy: 0.9875 - val_loss: 0.0360 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00638: val_loss did not improve from 0.03455\n",
            "Epoch 639/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.0376 - accuracy: 0.9894 - val_loss: 0.0392 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00639: val_loss did not improve from 0.03455\n",
            "Epoch 640/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0430 - accuracy: 0.9891 - val_loss: 0.0379 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00640: val_loss did not improve from 0.03455\n",
            "Epoch 641/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0403 - accuracy: 0.9910 - val_loss: 0.0359 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00641: val_loss did not improve from 0.03455\n",
            "Epoch 642/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0485 - accuracy: 0.9861 - val_loss: 0.0372 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00642: val_loss did not improve from 0.03455\n",
            "Epoch 643/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0434 - accuracy: 0.9880 - val_loss: 0.0388 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00643: val_loss did not improve from 0.03455\n",
            "Epoch 644/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0444 - accuracy: 0.9886 - val_loss: 0.0411 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00644: val_loss did not improve from 0.03455\n",
            "Epoch 645/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0489 - accuracy: 0.9870 - val_loss: 0.0461 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00645: val_loss did not improve from 0.03455\n",
            "Epoch 646/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0538 - accuracy: 0.9871 - val_loss: 0.0370 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00646: val_loss did not improve from 0.03455\n",
            "Epoch 647/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0401 - accuracy: 0.9893 - val_loss: 0.0386 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00647: val_loss did not improve from 0.03455\n",
            "Epoch 648/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0486 - accuracy: 0.9860 - val_loss: 0.0357 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00648: val_loss did not improve from 0.03455\n",
            "Epoch 649/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0343 - accuracy: 0.9923 - val_loss: 0.0476 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00649: val_loss did not improve from 0.03455\n",
            "Epoch 650/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0404 - accuracy: 0.9891 - val_loss: 0.0619 - val_accuracy: 0.9821\n",
            "\n",
            "Epoch 00650: val_loss did not improve from 0.03455\n",
            "Epoch 651/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0470 - accuracy: 0.9897 - val_loss: 0.0384 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00651: val_loss did not improve from 0.03455\n",
            "Epoch 652/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0435 - accuracy: 0.9886 - val_loss: 0.0358 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00652: val_loss did not improve from 0.03455\n",
            "Epoch 653/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0458 - accuracy: 0.9893 - val_loss: 0.0453 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00653: val_loss did not improve from 0.03455\n",
            "Epoch 654/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0498 - accuracy: 0.9883 - val_loss: 0.0456 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00654: val_loss did not improve from 0.03455\n",
            "Epoch 655/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0392 - accuracy: 0.9892 - val_loss: 0.0441 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00655: val_loss did not improve from 0.03455\n",
            "Epoch 656/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0432 - accuracy: 0.9857 - val_loss: 0.0544 - val_accuracy: 0.9833\n",
            "\n",
            "Epoch 00656: val_loss did not improve from 0.03455\n",
            "Epoch 657/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0325 - accuracy: 0.9923 - val_loss: 0.0385 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00657: val_loss did not improve from 0.03455\n",
            "Epoch 658/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0322 - accuracy: 0.9919 - val_loss: 0.0341 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00658: val_loss improved from 0.03455 to 0.03410, saving model to ./model/0.0341-0.9885-658.hdf5\n",
            "Epoch 659/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0465 - accuracy: 0.9850 - val_loss: 0.0373 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00659: val_loss did not improve from 0.03410\n",
            "Epoch 660/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0414 - accuracy: 0.9875 - val_loss: 0.0340 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00660: val_loss improved from 0.03410 to 0.03401, saving model to ./model/0.0340-0.9865-660.hdf5\n",
            "Epoch 661/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0353 - accuracy: 0.9913 - val_loss: 0.0377 - val_accuracy: 0.9891\n",
            "\n",
            "Epoch 00661: val_loss did not improve from 0.03401\n",
            "Epoch 662/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0472 - accuracy: 0.9870 - val_loss: 0.0346 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00662: val_loss did not improve from 0.03401\n",
            "Epoch 663/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0341 - accuracy: 0.9899 - val_loss: 0.0431 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00663: val_loss did not improve from 0.03401\n",
            "Epoch 664/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0391 - accuracy: 0.9901 - val_loss: 0.0426 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00664: val_loss did not improve from 0.03401\n",
            "Epoch 665/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0452 - accuracy: 0.9873 - val_loss: 0.0395 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00665: val_loss did not improve from 0.03401\n",
            "Epoch 666/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0330 - accuracy: 0.9918 - val_loss: 0.0387 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00666: val_loss did not improve from 0.03401\n",
            "Epoch 667/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0398 - accuracy: 0.9880 - val_loss: 0.0397 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00667: val_loss did not improve from 0.03401\n",
            "Epoch 668/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0478 - accuracy: 0.9864 - val_loss: 0.0373 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00668: val_loss did not improve from 0.03401\n",
            "Epoch 669/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0322 - accuracy: 0.9905 - val_loss: 0.0380 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00669: val_loss did not improve from 0.03401\n",
            "Epoch 670/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0483 - accuracy: 0.9858 - val_loss: 0.0365 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00670: val_loss did not improve from 0.03401\n",
            "Epoch 671/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0361 - accuracy: 0.9900 - val_loss: 0.0376 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00671: val_loss did not improve from 0.03401\n",
            "Epoch 672/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0350 - accuracy: 0.9927 - val_loss: 0.0432 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00672: val_loss did not improve from 0.03401\n",
            "Epoch 673/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0391 - accuracy: 0.9902 - val_loss: 0.0350 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00673: val_loss did not improve from 0.03401\n",
            "Epoch 674/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0500 - accuracy: 0.9847 - val_loss: 0.0380 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00674: val_loss did not improve from 0.03401\n",
            "Epoch 675/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0431 - accuracy: 0.9885 - val_loss: 0.0362 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00675: val_loss did not improve from 0.03401\n",
            "Epoch 676/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0558 - accuracy: 0.9840 - val_loss: 0.0359 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00676: val_loss did not improve from 0.03401\n",
            "Epoch 677/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0381 - accuracy: 0.9920 - val_loss: 0.0355 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00677: val_loss did not improve from 0.03401\n",
            "Epoch 678/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0354 - accuracy: 0.9914 - val_loss: 0.0367 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00678: val_loss did not improve from 0.03401\n",
            "Epoch 679/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0401 - accuracy: 0.9888 - val_loss: 0.0358 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00679: val_loss did not improve from 0.03401\n",
            "Epoch 680/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0390 - accuracy: 0.9899 - val_loss: 0.0371 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00680: val_loss did not improve from 0.03401\n",
            "Epoch 681/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.0488 - accuracy: 0.9878 - val_loss: 0.0381 - val_accuracy: 0.9891\n",
            "\n",
            "Epoch 00681: val_loss did not improve from 0.03401\n",
            "Epoch 682/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0363 - accuracy: 0.9908 - val_loss: 0.0352 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00682: val_loss did not improve from 0.03401\n",
            "Epoch 683/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0366 - accuracy: 0.9898 - val_loss: 0.0471 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00683: val_loss did not improve from 0.03401\n",
            "Epoch 684/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0367 - accuracy: 0.9906 - val_loss: 0.0369 - val_accuracy: 0.9897\n",
            "\n",
            "Epoch 00684: val_loss did not improve from 0.03401\n",
            "Epoch 685/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0417 - accuracy: 0.9896 - val_loss: 0.0404 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00685: val_loss did not improve from 0.03401\n",
            "Epoch 686/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0348 - accuracy: 0.9920 - val_loss: 0.0361 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00686: val_loss did not improve from 0.03401\n",
            "Epoch 687/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0355 - accuracy: 0.9905 - val_loss: 0.0358 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00687: val_loss did not improve from 0.03401\n",
            "Epoch 688/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0353 - accuracy: 0.9897 - val_loss: 0.0375 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00688: val_loss did not improve from 0.03401\n",
            "Epoch 689/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0420 - accuracy: 0.9901 - val_loss: 0.0408 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00689: val_loss did not improve from 0.03401\n",
            "Epoch 690/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0336 - accuracy: 0.9907 - val_loss: 0.0343 - val_accuracy: 0.9904\n",
            "\n",
            "Epoch 00690: val_loss did not improve from 0.03401\n",
            "Epoch 691/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0412 - accuracy: 0.9899 - val_loss: 0.0359 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00691: val_loss did not improve from 0.03401\n",
            "Epoch 692/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0412 - accuracy: 0.9886 - val_loss: 0.0340 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00692: val_loss improved from 0.03401 to 0.03397, saving model to ./model/0.0340-0.9885-692.hdf5\n",
            "Epoch 693/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0360 - accuracy: 0.9892 - val_loss: 0.0377 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00693: val_loss did not improve from 0.03397\n",
            "Epoch 694/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0351 - accuracy: 0.9912 - val_loss: 0.0420 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00694: val_loss did not improve from 0.03397\n",
            "Epoch 695/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0364 - accuracy: 0.9898 - val_loss: 0.0372 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00695: val_loss did not improve from 0.03397\n",
            "Epoch 696/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0357 - accuracy: 0.9896 - val_loss: 0.0337 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00696: val_loss improved from 0.03397 to 0.03366, saving model to ./model/0.0337-0.9872-696.hdf5\n",
            "Epoch 697/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0389 - accuracy: 0.9903 - val_loss: 0.0342 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00697: val_loss did not improve from 0.03366\n",
            "Epoch 698/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0430 - accuracy: 0.9889 - val_loss: 0.0379 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00698: val_loss did not improve from 0.03366\n",
            "Epoch 699/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0633 - accuracy: 0.9858 - val_loss: 0.0349 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00699: val_loss did not improve from 0.03366\n",
            "Epoch 700/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0348 - accuracy: 0.9899 - val_loss: 0.0393 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00700: val_loss did not improve from 0.03366\n",
            "Epoch 701/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0435 - accuracy: 0.9894 - val_loss: 0.0372 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00701: val_loss did not improve from 0.03366\n",
            "Epoch 702/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0431 - accuracy: 0.9872 - val_loss: 0.0368 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00702: val_loss did not improve from 0.03366\n",
            "Epoch 703/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0318 - accuracy: 0.9909 - val_loss: 0.0376 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00703: val_loss did not improve from 0.03366\n",
            "Epoch 704/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0310 - accuracy: 0.9926 - val_loss: 0.0405 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00704: val_loss did not improve from 0.03366\n",
            "Epoch 705/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0495 - accuracy: 0.9865 - val_loss: 0.0343 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00705: val_loss did not improve from 0.03366\n",
            "Epoch 706/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0314 - accuracy: 0.9905 - val_loss: 0.0380 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00706: val_loss did not improve from 0.03366\n",
            "Epoch 707/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0439 - accuracy: 0.9864 - val_loss: 0.0469 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00707: val_loss did not improve from 0.03366\n",
            "Epoch 708/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0435 - accuracy: 0.9880 - val_loss: 0.0381 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00708: val_loss did not improve from 0.03366\n",
            "Epoch 709/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0350 - accuracy: 0.9897 - val_loss: 0.0364 - val_accuracy: 0.9891\n",
            "\n",
            "Epoch 00709: val_loss did not improve from 0.03366\n",
            "Epoch 710/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0391 - accuracy: 0.9899 - val_loss: 0.0385 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00710: val_loss did not improve from 0.03366\n",
            "Epoch 711/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0373 - accuracy: 0.9895 - val_loss: 0.0460 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00711: val_loss did not improve from 0.03366\n",
            "Epoch 712/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0383 - accuracy: 0.9899 - val_loss: 0.0355 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00712: val_loss did not improve from 0.03366\n",
            "Epoch 713/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0367 - accuracy: 0.9892 - val_loss: 0.0377 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00713: val_loss did not improve from 0.03366\n",
            "Epoch 714/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0364 - accuracy: 0.9899 - val_loss: 0.0342 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00714: val_loss did not improve from 0.03366\n",
            "Epoch 715/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0306 - accuracy: 0.9936 - val_loss: 0.0356 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00715: val_loss did not improve from 0.03366\n",
            "Epoch 716/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0359 - accuracy: 0.9910 - val_loss: 0.0359 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00716: val_loss did not improve from 0.03366\n",
            "Epoch 717/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0358 - accuracy: 0.9908 - val_loss: 0.0379 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00717: val_loss did not improve from 0.03366\n",
            "Epoch 718/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0402 - accuracy: 0.9899 - val_loss: 0.0370 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00718: val_loss did not improve from 0.03366\n",
            "Epoch 719/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0381 - accuracy: 0.9904 - val_loss: 0.0362 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00719: val_loss did not improve from 0.03366\n",
            "Epoch 720/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0345 - accuracy: 0.9899 - val_loss: 0.0385 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00720: val_loss did not improve from 0.03366\n",
            "Epoch 721/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0453 - accuracy: 0.9885 - val_loss: 0.0357 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00721: val_loss did not improve from 0.03366\n",
            "Epoch 722/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0457 - accuracy: 0.9891 - val_loss: 0.0567 - val_accuracy: 0.9821\n",
            "\n",
            "Epoch 00722: val_loss did not improve from 0.03366\n",
            "Epoch 723/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0576 - accuracy: 0.9830 - val_loss: 0.0363 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00723: val_loss did not improve from 0.03366\n",
            "Epoch 724/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0351 - accuracy: 0.9899 - val_loss: 0.0486 - val_accuracy: 0.9840\n",
            "\n",
            "Epoch 00724: val_loss did not improve from 0.03366\n",
            "Epoch 725/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0398 - accuracy: 0.9880 - val_loss: 0.0372 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00725: val_loss did not improve from 0.03366\n",
            "Epoch 726/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0332 - accuracy: 0.9884 - val_loss: 0.0611 - val_accuracy: 0.9821\n",
            "\n",
            "Epoch 00726: val_loss did not improve from 0.03366\n",
            "Epoch 727/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0492 - accuracy: 0.9891 - val_loss: 0.0350 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00727: val_loss did not improve from 0.03366\n",
            "Epoch 728/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0361 - accuracy: 0.9904 - val_loss: 0.0437 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00728: val_loss did not improve from 0.03366\n",
            "Epoch 729/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0319 - accuracy: 0.9910 - val_loss: 0.0355 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00729: val_loss did not improve from 0.03366\n",
            "Epoch 730/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0358 - accuracy: 0.9906 - val_loss: 0.0364 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00730: val_loss did not improve from 0.03366\n",
            "Epoch 731/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0469 - accuracy: 0.9862 - val_loss: 0.0478 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00731: val_loss did not improve from 0.03366\n",
            "Epoch 732/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0439 - accuracy: 0.9903 - val_loss: 0.0399 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00732: val_loss did not improve from 0.03366\n",
            "Epoch 733/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0474 - accuracy: 0.9847 - val_loss: 0.0344 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00733: val_loss did not improve from 0.03366\n",
            "Epoch 734/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0337 - accuracy: 0.9905 - val_loss: 0.0468 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00734: val_loss did not improve from 0.03366\n",
            "Epoch 735/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0335 - accuracy: 0.9921 - val_loss: 0.0357 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00735: val_loss did not improve from 0.03366\n",
            "Epoch 736/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0418 - accuracy: 0.9878 - val_loss: 0.0386 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00736: val_loss did not improve from 0.03366\n",
            "Epoch 737/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0294 - accuracy: 0.9920 - val_loss: 0.0354 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00737: val_loss did not improve from 0.03366\n",
            "Epoch 738/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0402 - accuracy: 0.9886 - val_loss: 0.0361 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00738: val_loss did not improve from 0.03366\n",
            "Epoch 739/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0356 - accuracy: 0.9898 - val_loss: 0.0361 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00739: val_loss did not improve from 0.03366\n",
            "Epoch 740/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.0398 - accuracy: 0.9901 - val_loss: 0.0371 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00740: val_loss did not improve from 0.03366\n",
            "Epoch 741/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0336 - accuracy: 0.9918 - val_loss: 0.0451 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00741: val_loss did not improve from 0.03366\n",
            "Epoch 742/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0329 - accuracy: 0.9923 - val_loss: 0.0350 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00742: val_loss did not improve from 0.03366\n",
            "Epoch 743/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0360 - accuracy: 0.9895 - val_loss: 0.0409 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00743: val_loss did not improve from 0.03366\n",
            "Epoch 744/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0342 - accuracy: 0.9912 - val_loss: 0.0350 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00744: val_loss did not improve from 0.03366\n",
            "Epoch 745/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0456 - accuracy: 0.9876 - val_loss: 0.0396 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00745: val_loss did not improve from 0.03366\n",
            "Epoch 746/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0390 - accuracy: 0.9900 - val_loss: 0.0346 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00746: val_loss did not improve from 0.03366\n",
            "Epoch 747/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0401 - accuracy: 0.9904 - val_loss: 0.0387 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00747: val_loss did not improve from 0.03366\n",
            "Epoch 748/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0401 - accuracy: 0.9888 - val_loss: 0.0334 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00748: val_loss improved from 0.03366 to 0.03339, saving model to ./model/0.0334-0.9878-748.hdf5\n",
            "Epoch 749/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0410 - accuracy: 0.9889 - val_loss: 0.0375 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00749: val_loss did not improve from 0.03339\n",
            "Epoch 750/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0385 - accuracy: 0.9895 - val_loss: 0.0414 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00750: val_loss did not improve from 0.03339\n",
            "Epoch 751/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0303 - accuracy: 0.9929 - val_loss: 0.0350 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00751: val_loss did not improve from 0.03339\n",
            "Epoch 752/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0390 - accuracy: 0.9892 - val_loss: 0.0530 - val_accuracy: 0.9840\n",
            "\n",
            "Epoch 00752: val_loss did not improve from 0.03339\n",
            "Epoch 753/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0321 - accuracy: 0.9906 - val_loss: 0.0369 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00753: val_loss did not improve from 0.03339\n",
            "Epoch 754/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0362 - accuracy: 0.9914 - val_loss: 0.0405 - val_accuracy: 0.9891\n",
            "\n",
            "Epoch 00754: val_loss did not improve from 0.03339\n",
            "Epoch 755/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0515 - accuracy: 0.9866 - val_loss: 0.0403 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00755: val_loss did not improve from 0.03339\n",
            "Epoch 756/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0382 - accuracy: 0.9891 - val_loss: 0.0348 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00756: val_loss did not improve from 0.03339\n",
            "Epoch 757/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0528 - accuracy: 0.9855 - val_loss: 0.0349 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00757: val_loss did not improve from 0.03339\n",
            "Epoch 758/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0312 - accuracy: 0.9920 - val_loss: 0.0460 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00758: val_loss did not improve from 0.03339\n",
            "Epoch 759/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0341 - accuracy: 0.9906 - val_loss: 0.0394 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00759: val_loss did not improve from 0.03339\n",
            "Epoch 760/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0315 - accuracy: 0.9918 - val_loss: 0.0343 - val_accuracy: 0.9891\n",
            "\n",
            "Epoch 00760: val_loss did not improve from 0.03339\n",
            "Epoch 761/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0387 - accuracy: 0.9894 - val_loss: 0.0467 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00761: val_loss did not improve from 0.03339\n",
            "Epoch 762/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0367 - accuracy: 0.9910 - val_loss: 0.0361 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00762: val_loss did not improve from 0.03339\n",
            "Epoch 763/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0334 - accuracy: 0.9917 - val_loss: 0.0346 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00763: val_loss did not improve from 0.03339\n",
            "Epoch 764/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0388 - accuracy: 0.9885 - val_loss: 0.0366 - val_accuracy: 0.9891\n",
            "\n",
            "Epoch 00764: val_loss did not improve from 0.03339\n",
            "Epoch 765/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0428 - accuracy: 0.9880 - val_loss: 0.0385 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00765: val_loss did not improve from 0.03339\n",
            "Epoch 766/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0330 - accuracy: 0.9912 - val_loss: 0.0381 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00766: val_loss did not improve from 0.03339\n",
            "Epoch 767/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0429 - accuracy: 0.9877 - val_loss: 0.0348 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00767: val_loss did not improve from 0.03339\n",
            "Epoch 768/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0349 - accuracy: 0.9910 - val_loss: 0.0358 - val_accuracy: 0.9891\n",
            "\n",
            "Epoch 00768: val_loss did not improve from 0.03339\n",
            "Epoch 769/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0368 - accuracy: 0.9905 - val_loss: 0.0382 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00769: val_loss did not improve from 0.03339\n",
            "Epoch 770/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.0335 - accuracy: 0.9918 - val_loss: 0.0324 - val_accuracy: 0.9904\n",
            "\n",
            "Epoch 00770: val_loss improved from 0.03339 to 0.03238, saving model to ./model/0.0324-0.9904-770.hdf5\n",
            "Epoch 771/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0344 - accuracy: 0.9914 - val_loss: 0.0400 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00771: val_loss did not improve from 0.03238\n",
            "Epoch 772/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0322 - accuracy: 0.9917 - val_loss: 0.0448 - val_accuracy: 0.9846\n",
            "\n",
            "Epoch 00772: val_loss did not improve from 0.03238\n",
            "Epoch 773/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0300 - accuracy: 0.9924 - val_loss: 0.0434 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00773: val_loss did not improve from 0.03238\n",
            "Epoch 774/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0420 - accuracy: 0.9877 - val_loss: 0.0338 - val_accuracy: 0.9891\n",
            "\n",
            "Epoch 00774: val_loss did not improve from 0.03238\n",
            "Epoch 775/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0327 - accuracy: 0.9923 - val_loss: 0.0357 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00775: val_loss did not improve from 0.03238\n",
            "Epoch 776/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0451 - accuracy: 0.9901 - val_loss: 0.0429 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00776: val_loss did not improve from 0.03238\n",
            "Epoch 777/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0318 - accuracy: 0.9915 - val_loss: 0.0435 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00777: val_loss did not improve from 0.03238\n",
            "Epoch 778/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0316 - accuracy: 0.9898 - val_loss: 0.0424 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00778: val_loss did not improve from 0.03238\n",
            "Epoch 779/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0374 - accuracy: 0.9913 - val_loss: 0.0364 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00779: val_loss did not improve from 0.03238\n",
            "Epoch 780/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.0481 - accuracy: 0.9875 - val_loss: 0.0345 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00780: val_loss did not improve from 0.03238\n",
            "Epoch 781/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.0438 - accuracy: 0.9886 - val_loss: 0.0497 - val_accuracy: 0.9833\n",
            "\n",
            "Epoch 00781: val_loss did not improve from 0.03238\n",
            "Epoch 782/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0507 - accuracy: 0.9845 - val_loss: 0.0379 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00782: val_loss did not improve from 0.03238\n",
            "Epoch 783/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0363 - accuracy: 0.9892 - val_loss: 0.0373 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00783: val_loss did not improve from 0.03238\n",
            "Epoch 784/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0460 - accuracy: 0.9888 - val_loss: 0.0338 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00784: val_loss did not improve from 0.03238\n",
            "Epoch 785/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 0.0324 - accuracy: 0.9899 - val_loss: 0.0364 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00785: val_loss did not improve from 0.03238\n",
            "Epoch 786/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0375 - accuracy: 0.9882 - val_loss: 0.0416 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00786: val_loss did not improve from 0.03238\n",
            "Epoch 787/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0437 - accuracy: 0.9897 - val_loss: 0.0425 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00787: val_loss did not improve from 0.03238\n",
            "Epoch 788/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.0412 - accuracy: 0.9895 - val_loss: 0.0319 - val_accuracy: 0.9891\n",
            "\n",
            "Epoch 00788: val_loss improved from 0.03238 to 0.03189, saving model to ./model/0.0319-0.9891-788.hdf5\n",
            "Epoch 789/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0414 - accuracy: 0.9886 - val_loss: 0.0362 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00789: val_loss did not improve from 0.03189\n",
            "Epoch 790/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0399 - accuracy: 0.9900 - val_loss: 0.0497 - val_accuracy: 0.9840\n",
            "\n",
            "Epoch 00790: val_loss did not improve from 0.03189\n",
            "Epoch 791/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0428 - accuracy: 0.9872 - val_loss: 0.0343 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00791: val_loss did not improve from 0.03189\n",
            "Epoch 792/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0324 - accuracy: 0.9900 - val_loss: 0.0372 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00792: val_loss did not improve from 0.03189\n",
            "Epoch 793/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0347 - accuracy: 0.9907 - val_loss: 0.0363 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00793: val_loss did not improve from 0.03189\n",
            "Epoch 794/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0359 - accuracy: 0.9890 - val_loss: 0.0323 - val_accuracy: 0.9891\n",
            "\n",
            "Epoch 00794: val_loss did not improve from 0.03189\n",
            "Epoch 795/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0354 - accuracy: 0.9914 - val_loss: 0.0407 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00795: val_loss did not improve from 0.03189\n",
            "Epoch 796/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.0320 - accuracy: 0.9922 - val_loss: 0.0371 - val_accuracy: 0.9897\n",
            "\n",
            "Epoch 00796: val_loss did not improve from 0.03189\n",
            "Epoch 797/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0370 - accuracy: 0.9893 - val_loss: 0.0324 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00797: val_loss did not improve from 0.03189\n",
            "Epoch 798/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0332 - accuracy: 0.9881 - val_loss: 0.0397 - val_accuracy: 0.9891\n",
            "\n",
            "Epoch 00798: val_loss did not improve from 0.03189\n",
            "Epoch 799/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0347 - accuracy: 0.9912 - val_loss: 0.0343 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00799: val_loss did not improve from 0.03189\n",
            "Epoch 800/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0374 - accuracy: 0.9877 - val_loss: 0.0353 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00800: val_loss did not improve from 0.03189\n",
            "Epoch 801/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0359 - accuracy: 0.9891 - val_loss: 0.0350 - val_accuracy: 0.9891\n",
            "\n",
            "Epoch 00801: val_loss did not improve from 0.03189\n",
            "Epoch 802/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0334 - accuracy: 0.9907 - val_loss: 0.0342 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00802: val_loss did not improve from 0.03189\n",
            "Epoch 803/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0347 - accuracy: 0.9897 - val_loss: 0.0425 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00803: val_loss did not improve from 0.03189\n",
            "Epoch 804/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0403 - accuracy: 0.9895 - val_loss: 0.0369 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00804: val_loss did not improve from 0.03189\n",
            "Epoch 805/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0332 - accuracy: 0.9918 - val_loss: 0.0349 - val_accuracy: 0.9891\n",
            "\n",
            "Epoch 00805: val_loss did not improve from 0.03189\n",
            "Epoch 806/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0345 - accuracy: 0.9906 - val_loss: 0.0633 - val_accuracy: 0.9821\n",
            "\n",
            "Epoch 00806: val_loss did not improve from 0.03189\n",
            "Epoch 807/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0439 - accuracy: 0.9866 - val_loss: 0.0376 - val_accuracy: 0.9897\n",
            "\n",
            "Epoch 00807: val_loss did not improve from 0.03189\n",
            "Epoch 808/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0461 - accuracy: 0.9882 - val_loss: 0.0409 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00808: val_loss did not improve from 0.03189\n",
            "Epoch 809/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0460 - accuracy: 0.9862 - val_loss: 0.0331 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00809: val_loss did not improve from 0.03189\n",
            "Epoch 810/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.0331 - accuracy: 0.9923 - val_loss: 0.0365 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00810: val_loss did not improve from 0.03189\n",
            "Epoch 811/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0358 - accuracy: 0.9898 - val_loss: 0.0336 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00811: val_loss did not improve from 0.03189\n",
            "Epoch 812/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.0413 - accuracy: 0.9888 - val_loss: 0.0376 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00812: val_loss did not improve from 0.03189\n",
            "Epoch 813/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0412 - accuracy: 0.9901 - val_loss: 0.0339 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00813: val_loss did not improve from 0.03189\n",
            "Epoch 814/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0490 - accuracy: 0.9873 - val_loss: 0.0405 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00814: val_loss did not improve from 0.03189\n",
            "Epoch 815/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0323 - accuracy: 0.9914 - val_loss: 0.0356 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00815: val_loss did not improve from 0.03189\n",
            "Epoch 816/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.0388 - accuracy: 0.9889 - val_loss: 0.0378 - val_accuracy: 0.9891\n",
            "\n",
            "Epoch 00816: val_loss did not improve from 0.03189\n",
            "Epoch 817/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0386 - accuracy: 0.9910 - val_loss: 0.0347 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00817: val_loss did not improve from 0.03189\n",
            "Epoch 818/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0338 - accuracy: 0.9910 - val_loss: 0.0344 - val_accuracy: 0.9897\n",
            "\n",
            "Epoch 00818: val_loss did not improve from 0.03189\n",
            "Epoch 819/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0386 - accuracy: 0.9886 - val_loss: 0.0344 - val_accuracy: 0.9891\n",
            "\n",
            "Epoch 00819: val_loss did not improve from 0.03189\n",
            "Epoch 820/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0484 - accuracy: 0.9864 - val_loss: 0.0444 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00820: val_loss did not improve from 0.03189\n",
            "Epoch 821/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0355 - accuracy: 0.9890 - val_loss: 0.0349 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00821: val_loss did not improve from 0.03189\n",
            "Epoch 822/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0435 - accuracy: 0.9885 - val_loss: 0.0404 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00822: val_loss did not improve from 0.03189\n",
            "Epoch 823/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0504 - accuracy: 0.9853 - val_loss: 0.0385 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00823: val_loss did not improve from 0.03189\n",
            "Epoch 824/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0464 - accuracy: 0.9882 - val_loss: 0.0351 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00824: val_loss did not improve from 0.03189\n",
            "Epoch 825/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0375 - accuracy: 0.9885 - val_loss: 0.0399 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00825: val_loss did not improve from 0.03189\n",
            "Epoch 826/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0475 - accuracy: 0.9857 - val_loss: 0.0356 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00826: val_loss did not improve from 0.03189\n",
            "Epoch 827/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0271 - accuracy: 0.9921 - val_loss: 0.0351 - val_accuracy: 0.9891\n",
            "\n",
            "Epoch 00827: val_loss did not improve from 0.03189\n",
            "Epoch 828/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0309 - accuracy: 0.9910 - val_loss: 0.0417 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00828: val_loss did not improve from 0.03189\n",
            "Epoch 829/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0388 - accuracy: 0.9894 - val_loss: 0.0339 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00829: val_loss did not improve from 0.03189\n",
            "Epoch 830/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0403 - accuracy: 0.9888 - val_loss: 0.0505 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00830: val_loss did not improve from 0.03189\n",
            "Epoch 831/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0386 - accuracy: 0.9893 - val_loss: 0.0340 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00831: val_loss did not improve from 0.03189\n",
            "Epoch 832/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0424 - accuracy: 0.9869 - val_loss: 0.0363 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00832: val_loss did not improve from 0.03189\n",
            "Epoch 833/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0366 - accuracy: 0.9900 - val_loss: 0.0384 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00833: val_loss did not improve from 0.03189\n",
            "Epoch 834/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0352 - accuracy: 0.9902 - val_loss: 0.0384 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00834: val_loss did not improve from 0.03189\n",
            "Epoch 835/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0382 - accuracy: 0.9898 - val_loss: 0.0334 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00835: val_loss did not improve from 0.03189\n",
            "Epoch 836/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.0295 - accuracy: 0.9925 - val_loss: 0.0349 - val_accuracy: 0.9891\n",
            "\n",
            "Epoch 00836: val_loss did not improve from 0.03189\n",
            "Epoch 837/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0354 - accuracy: 0.9901 - val_loss: 0.0374 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00837: val_loss did not improve from 0.03189\n",
            "Epoch 838/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0360 - accuracy: 0.9899 - val_loss: 0.0408 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00838: val_loss did not improve from 0.03189\n",
            "Epoch 839/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0365 - accuracy: 0.9896 - val_loss: 0.0350 - val_accuracy: 0.9891\n",
            "\n",
            "Epoch 00839: val_loss did not improve from 0.03189\n",
            "Epoch 840/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0371 - accuracy: 0.9908 - val_loss: 0.0362 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00840: val_loss did not improve from 0.03189\n",
            "Epoch 841/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0335 - accuracy: 0.9913 - val_loss: 0.0357 - val_accuracy: 0.9891\n",
            "\n",
            "Epoch 00841: val_loss did not improve from 0.03189\n",
            "Epoch 842/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0417 - accuracy: 0.9898 - val_loss: 0.0338 - val_accuracy: 0.9891\n",
            "\n",
            "Epoch 00842: val_loss did not improve from 0.03189\n",
            "Epoch 843/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0441 - accuracy: 0.9884 - val_loss: 0.0348 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00843: val_loss did not improve from 0.03189\n",
            "Epoch 844/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0331 - accuracy: 0.9919 - val_loss: 0.0332 - val_accuracy: 0.9891\n",
            "\n",
            "Epoch 00844: val_loss did not improve from 0.03189\n",
            "Epoch 845/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0354 - accuracy: 0.9887 - val_loss: 0.0335 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00845: val_loss did not improve from 0.03189\n",
            "Epoch 846/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0387 - accuracy: 0.9897 - val_loss: 0.0383 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00846: val_loss did not improve from 0.03189\n",
            "Epoch 847/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.0525 - accuracy: 0.9880 - val_loss: 0.0388 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00847: val_loss did not improve from 0.03189\n",
            "Epoch 848/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0467 - accuracy: 0.9887 - val_loss: 0.0451 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00848: val_loss did not improve from 0.03189\n",
            "Epoch 849/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0342 - accuracy: 0.9909 - val_loss: 0.0369 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00849: val_loss did not improve from 0.03189\n",
            "Epoch 850/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0267 - accuracy: 0.9935 - val_loss: 0.0347 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00850: val_loss did not improve from 0.03189\n",
            "Epoch 851/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0444 - accuracy: 0.9895 - val_loss: 0.0345 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00851: val_loss did not improve from 0.03189\n",
            "Epoch 852/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0384 - accuracy: 0.9890 - val_loss: 0.0350 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00852: val_loss did not improve from 0.03189\n",
            "Epoch 853/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0289 - accuracy: 0.9925 - val_loss: 0.0357 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00853: val_loss did not improve from 0.03189\n",
            "Epoch 854/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0290 - accuracy: 0.9920 - val_loss: 0.0349 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00854: val_loss did not improve from 0.03189\n",
            "Epoch 855/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0411 - accuracy: 0.9878 - val_loss: 0.0370 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00855: val_loss did not improve from 0.03189\n",
            "Epoch 856/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0534 - accuracy: 0.9885 - val_loss: 0.0356 - val_accuracy: 0.9897\n",
            "\n",
            "Epoch 00856: val_loss did not improve from 0.03189\n",
            "Epoch 857/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0460 - accuracy: 0.9887 - val_loss: 0.0387 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00857: val_loss did not improve from 0.03189\n",
            "Epoch 858/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0358 - accuracy: 0.9905 - val_loss: 0.0331 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00858: val_loss did not improve from 0.03189\n",
            "Epoch 859/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0420 - accuracy: 0.9888 - val_loss: 0.0362 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00859: val_loss did not improve from 0.03189\n",
            "Epoch 860/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0402 - accuracy: 0.9882 - val_loss: 0.0340 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00860: val_loss did not improve from 0.03189\n",
            "Epoch 861/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0330 - accuracy: 0.9915 - val_loss: 0.0320 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00861: val_loss did not improve from 0.03189\n",
            "Epoch 862/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0354 - accuracy: 0.9900 - val_loss: 0.0460 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00862: val_loss did not improve from 0.03189\n",
            "Epoch 863/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0403 - accuracy: 0.9873 - val_loss: 0.0370 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00863: val_loss did not improve from 0.03189\n",
            "Epoch 864/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0278 - accuracy: 0.9925 - val_loss: 0.0351 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00864: val_loss did not improve from 0.03189\n",
            "Epoch 865/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0298 - accuracy: 0.9939 - val_loss: 0.0458 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00865: val_loss did not improve from 0.03189\n",
            "Epoch 866/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0370 - accuracy: 0.9883 - val_loss: 0.0436 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00866: val_loss did not improve from 0.03189\n",
            "Epoch 867/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0383 - accuracy: 0.9900 - val_loss: 0.0425 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00867: val_loss did not improve from 0.03189\n",
            "Epoch 868/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0500 - accuracy: 0.9880 - val_loss: 0.0397 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00868: val_loss did not improve from 0.03189\n",
            "Epoch 869/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0364 - accuracy: 0.9904 - val_loss: 0.0369 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00869: val_loss did not improve from 0.03189\n",
            "Epoch 870/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0425 - accuracy: 0.9899 - val_loss: 0.0341 - val_accuracy: 0.9897\n",
            "\n",
            "Epoch 00870: val_loss did not improve from 0.03189\n",
            "Epoch 871/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0331 - accuracy: 0.9921 - val_loss: 0.0434 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00871: val_loss did not improve from 0.03189\n",
            "Epoch 872/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0393 - accuracy: 0.9902 - val_loss: 0.0389 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00872: val_loss did not improve from 0.03189\n",
            "Epoch 873/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0317 - accuracy: 0.9916 - val_loss: 0.0415 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00873: val_loss did not improve from 0.03189\n",
            "Epoch 874/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0338 - accuracy: 0.9909 - val_loss: 0.0337 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00874: val_loss did not improve from 0.03189\n",
            "Epoch 875/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0308 - accuracy: 0.9918 - val_loss: 0.0342 - val_accuracy: 0.9904\n",
            "\n",
            "Epoch 00875: val_loss did not improve from 0.03189\n",
            "Epoch 876/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.0325 - accuracy: 0.9923 - val_loss: 0.0417 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00876: val_loss did not improve from 0.03189\n",
            "Epoch 877/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0413 - accuracy: 0.9877 - val_loss: 0.0433 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00877: val_loss did not improve from 0.03189\n",
            "Epoch 878/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0488 - accuracy: 0.9877 - val_loss: 0.0339 - val_accuracy: 0.9891\n",
            "\n",
            "Epoch 00878: val_loss did not improve from 0.03189\n",
            "Epoch 879/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0303 - accuracy: 0.9920 - val_loss: 0.0441 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00879: val_loss did not improve from 0.03189\n",
            "Epoch 880/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0335 - accuracy: 0.9902 - val_loss: 0.0418 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00880: val_loss did not improve from 0.03189\n",
            "Epoch 881/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0489 - accuracy: 0.9874 - val_loss: 0.0338 - val_accuracy: 0.9891\n",
            "\n",
            "Epoch 00881: val_loss did not improve from 0.03189\n",
            "Epoch 882/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0339 - accuracy: 0.9895 - val_loss: 0.0370 - val_accuracy: 0.9891\n",
            "\n",
            "Epoch 00882: val_loss did not improve from 0.03189\n",
            "Epoch 883/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0389 - accuracy: 0.9891 - val_loss: 0.0387 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00883: val_loss did not improve from 0.03189\n",
            "Epoch 884/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0421 - accuracy: 0.9872 - val_loss: 0.0380 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00884: val_loss did not improve from 0.03189\n",
            "Epoch 885/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0409 - accuracy: 0.9888 - val_loss: 0.0506 - val_accuracy: 0.9827\n",
            "\n",
            "Epoch 00885: val_loss did not improve from 0.03189\n",
            "Epoch 886/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0438 - accuracy: 0.9871 - val_loss: 0.0329 - val_accuracy: 0.9891\n",
            "\n",
            "Epoch 00886: val_loss did not improve from 0.03189\n",
            "Epoch 887/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0387 - accuracy: 0.9905 - val_loss: 0.0350 - val_accuracy: 0.9891\n",
            "\n",
            "Epoch 00887: val_loss did not improve from 0.03189\n",
            "Epoch 888/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0389 - accuracy: 0.9889 - val_loss: 0.0347 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00888: val_loss did not improve from 0.03189\n",
            "Epoch 889/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0331 - accuracy: 0.9896 - val_loss: 0.0485 - val_accuracy: 0.9840\n",
            "\n",
            "Epoch 00889: val_loss did not improve from 0.03189\n",
            "Epoch 890/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0441 - accuracy: 0.9857 - val_loss: 0.0315 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00890: val_loss improved from 0.03189 to 0.03148, saving model to ./model/0.0315-0.9878-890.hdf5\n",
            "Epoch 891/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0400 - accuracy: 0.9900 - val_loss: 0.0345 - val_accuracy: 0.9897\n",
            "\n",
            "Epoch 00891: val_loss did not improve from 0.03148\n",
            "Epoch 892/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0304 - accuracy: 0.9920 - val_loss: 0.0448 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00892: val_loss did not improve from 0.03148\n",
            "Epoch 893/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0379 - accuracy: 0.9888 - val_loss: 0.0524 - val_accuracy: 0.9840\n",
            "\n",
            "Epoch 00893: val_loss did not improve from 0.03148\n",
            "Epoch 894/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0415 - accuracy: 0.9895 - val_loss: 0.0355 - val_accuracy: 0.9904\n",
            "\n",
            "Epoch 00894: val_loss did not improve from 0.03148\n",
            "Epoch 895/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0475 - accuracy: 0.9853 - val_loss: 0.0333 - val_accuracy: 0.9891\n",
            "\n",
            "Epoch 00895: val_loss did not improve from 0.03148\n",
            "Epoch 896/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0262 - accuracy: 0.9937 - val_loss: 0.0369 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00896: val_loss did not improve from 0.03148\n",
            "Epoch 897/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0354 - accuracy: 0.9909 - val_loss: 0.0609 - val_accuracy: 0.9821\n",
            "\n",
            "Epoch 00897: val_loss did not improve from 0.03148\n",
            "Epoch 898/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0433 - accuracy: 0.9890 - val_loss: 0.0328 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00898: val_loss did not improve from 0.03148\n",
            "Epoch 899/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.0470 - accuracy: 0.9880 - val_loss: 0.0330 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00899: val_loss did not improve from 0.03148\n",
            "Epoch 900/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0468 - accuracy: 0.9883 - val_loss: 0.0402 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00900: val_loss did not improve from 0.03148\n",
            "Epoch 901/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0290 - accuracy: 0.9927 - val_loss: 0.0419 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00901: val_loss did not improve from 0.03148\n",
            "Epoch 902/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.0368 - accuracy: 0.9897 - val_loss: 0.0359 - val_accuracy: 0.9891\n",
            "\n",
            "Epoch 00902: val_loss did not improve from 0.03148\n",
            "Epoch 903/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0396 - accuracy: 0.9870 - val_loss: 0.0332 - val_accuracy: 0.9891\n",
            "\n",
            "Epoch 00903: val_loss did not improve from 0.03148\n",
            "Epoch 904/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0448 - accuracy: 0.9881 - val_loss: 0.0361 - val_accuracy: 0.9904\n",
            "\n",
            "Epoch 00904: val_loss did not improve from 0.03148\n",
            "Epoch 905/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0390 - accuracy: 0.9883 - val_loss: 0.0329 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00905: val_loss did not improve from 0.03148\n",
            "Epoch 906/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.0279 - accuracy: 0.9934 - val_loss: 0.0411 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00906: val_loss did not improve from 0.03148\n",
            "Epoch 907/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0308 - accuracy: 0.9918 - val_loss: 0.0422 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00907: val_loss did not improve from 0.03148\n",
            "Epoch 908/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0352 - accuracy: 0.9906 - val_loss: 0.0486 - val_accuracy: 0.9833\n",
            "\n",
            "Epoch 00908: val_loss did not improve from 0.03148\n",
            "Epoch 909/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.0524 - accuracy: 0.9828 - val_loss: 0.0429 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00909: val_loss did not improve from 0.03148\n",
            "Epoch 910/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0376 - accuracy: 0.9903 - val_loss: 0.0334 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00910: val_loss did not improve from 0.03148\n",
            "Epoch 911/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0367 - accuracy: 0.9910 - val_loss: 0.0462 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00911: val_loss did not improve from 0.03148\n",
            "Epoch 912/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0372 - accuracy: 0.9910 - val_loss: 0.0347 - val_accuracy: 0.9891\n",
            "\n",
            "Epoch 00912: val_loss did not improve from 0.03148\n",
            "Epoch 913/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0331 - accuracy: 0.9885 - val_loss: 0.0314 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00913: val_loss improved from 0.03148 to 0.03137, saving model to ./model/0.0314-0.9885-913.hdf5\n",
            "Epoch 914/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0320 - accuracy: 0.9918 - val_loss: 0.0436 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00914: val_loss did not improve from 0.03137\n",
            "Epoch 915/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0344 - accuracy: 0.9914 - val_loss: 0.0372 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00915: val_loss did not improve from 0.03137\n",
            "Epoch 916/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0277 - accuracy: 0.9929 - val_loss: 0.0397 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00916: val_loss did not improve from 0.03137\n",
            "Epoch 917/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0433 - accuracy: 0.9909 - val_loss: 0.0341 - val_accuracy: 0.9897\n",
            "\n",
            "Epoch 00917: val_loss did not improve from 0.03137\n",
            "Epoch 918/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0363 - accuracy: 0.9875 - val_loss: 0.0367 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00918: val_loss did not improve from 0.03137\n",
            "Epoch 919/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0253 - accuracy: 0.9937 - val_loss: 0.0444 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00919: val_loss did not improve from 0.03137\n",
            "Epoch 920/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.0449 - accuracy: 0.9904 - val_loss: 0.0353 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00920: val_loss did not improve from 0.03137\n",
            "Epoch 921/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0389 - accuracy: 0.9895 - val_loss: 0.0380 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00921: val_loss did not improve from 0.03137\n",
            "Epoch 922/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0287 - accuracy: 0.9927 - val_loss: 0.0374 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00922: val_loss did not improve from 0.03137\n",
            "Epoch 923/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0457 - accuracy: 0.9846 - val_loss: 0.0394 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00923: val_loss did not improve from 0.03137\n",
            "Epoch 924/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0304 - accuracy: 0.9922 - val_loss: 0.0348 - val_accuracy: 0.9891\n",
            "\n",
            "Epoch 00924: val_loss did not improve from 0.03137\n",
            "Epoch 925/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0347 - accuracy: 0.9913 - val_loss: 0.0387 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00925: val_loss did not improve from 0.03137\n",
            "Epoch 926/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.0388 - accuracy: 0.9888 - val_loss: 0.0327 - val_accuracy: 0.9891\n",
            "\n",
            "Epoch 00926: val_loss did not improve from 0.03137\n",
            "Epoch 927/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0278 - accuracy: 0.9933 - val_loss: 0.0371 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00927: val_loss did not improve from 0.03137\n",
            "Epoch 928/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0485 - accuracy: 0.9853 - val_loss: 0.0317 - val_accuracy: 0.9897\n",
            "\n",
            "Epoch 00928: val_loss did not improve from 0.03137\n",
            "Epoch 929/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.0402 - accuracy: 0.9879 - val_loss: 0.0356 - val_accuracy: 0.9891\n",
            "\n",
            "Epoch 00929: val_loss did not improve from 0.03137\n",
            "Epoch 930/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0282 - accuracy: 0.9922 - val_loss: 0.0351 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00930: val_loss did not improve from 0.03137\n",
            "Epoch 931/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0257 - accuracy: 0.9928 - val_loss: 0.0338 - val_accuracy: 0.9891\n",
            "\n",
            "Epoch 00931: val_loss did not improve from 0.03137\n",
            "Epoch 932/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.0386 - accuracy: 0.9889 - val_loss: 0.0361 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00932: val_loss did not improve from 0.03137\n",
            "Epoch 933/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0351 - accuracy: 0.9896 - val_loss: 0.0338 - val_accuracy: 0.9897\n",
            "\n",
            "Epoch 00933: val_loss did not improve from 0.03137\n",
            "Epoch 934/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0293 - accuracy: 0.9928 - val_loss: 0.0387 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00934: val_loss did not improve from 0.03137\n",
            "Epoch 935/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0401 - accuracy: 0.9871 - val_loss: 0.0364 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00935: val_loss did not improve from 0.03137\n",
            "Epoch 936/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0444 - accuracy: 0.9880 - val_loss: 0.0349 - val_accuracy: 0.9891\n",
            "\n",
            "Epoch 00936: val_loss did not improve from 0.03137\n",
            "Epoch 937/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0384 - accuracy: 0.9893 - val_loss: 0.0353 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00937: val_loss did not improve from 0.03137\n",
            "Epoch 938/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0344 - accuracy: 0.9915 - val_loss: 0.0323 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00938: val_loss did not improve from 0.03137\n",
            "Epoch 939/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.0383 - accuracy: 0.9890 - val_loss: 0.0327 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00939: val_loss did not improve from 0.03137\n",
            "Epoch 940/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0383 - accuracy: 0.9895 - val_loss: 0.0405 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00940: val_loss did not improve from 0.03137\n",
            "Epoch 941/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0700 - accuracy: 0.9820 - val_loss: 0.0405 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00941: val_loss did not improve from 0.03137\n",
            "Epoch 942/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0286 - accuracy: 0.9914 - val_loss: 0.0331 - val_accuracy: 0.9891\n",
            "\n",
            "Epoch 00942: val_loss did not improve from 0.03137\n",
            "Epoch 943/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0283 - accuracy: 0.9923 - val_loss: 0.0335 - val_accuracy: 0.9904\n",
            "\n",
            "Epoch 00943: val_loss did not improve from 0.03137\n",
            "Epoch 944/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.0322 - accuracy: 0.9914 - val_loss: 0.0361 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00944: val_loss did not improve from 0.03137\n",
            "Epoch 945/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0298 - accuracy: 0.9918 - val_loss: 0.0326 - val_accuracy: 0.9891\n",
            "\n",
            "Epoch 00945: val_loss did not improve from 0.03137\n",
            "Epoch 946/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.0387 - accuracy: 0.9885 - val_loss: 0.0342 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00946: val_loss did not improve from 0.03137\n",
            "Epoch 947/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0345 - accuracy: 0.9903 - val_loss: 0.0317 - val_accuracy: 0.9891\n",
            "\n",
            "Epoch 00947: val_loss did not improve from 0.03137\n",
            "Epoch 948/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0403 - accuracy: 0.9883 - val_loss: 0.0525 - val_accuracy: 0.9840\n",
            "\n",
            "Epoch 00948: val_loss did not improve from 0.03137\n",
            "Epoch 949/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0365 - accuracy: 0.9902 - val_loss: 0.0353 - val_accuracy: 0.9904\n",
            "\n",
            "Epoch 00949: val_loss did not improve from 0.03137\n",
            "Epoch 950/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0306 - accuracy: 0.9905 - val_loss: 0.0310 - val_accuracy: 0.9891\n",
            "\n",
            "Epoch 00950: val_loss improved from 0.03137 to 0.03096, saving model to ./model/0.0310-0.9891-950.hdf5\n",
            "Epoch 951/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0289 - accuracy: 0.9923 - val_loss: 0.0357 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00951: val_loss did not improve from 0.03096\n",
            "Epoch 952/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0485 - accuracy: 0.9877 - val_loss: 0.0441 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00952: val_loss did not improve from 0.03096\n",
            "Epoch 953/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.0318 - accuracy: 0.9920 - val_loss: 0.0335 - val_accuracy: 0.9891\n",
            "\n",
            "Epoch 00953: val_loss did not improve from 0.03096\n",
            "Epoch 954/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0405 - accuracy: 0.9888 - val_loss: 0.0395 - val_accuracy: 0.9891\n",
            "\n",
            "Epoch 00954: val_loss did not improve from 0.03096\n",
            "Epoch 955/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0389 - accuracy: 0.9889 - val_loss: 0.0368 - val_accuracy: 0.9904\n",
            "\n",
            "Epoch 00955: val_loss did not improve from 0.03096\n",
            "Epoch 956/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0388 - accuracy: 0.9902 - val_loss: 0.0338 - val_accuracy: 0.9910\n",
            "\n",
            "Epoch 00956: val_loss did not improve from 0.03096\n",
            "Epoch 957/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0345 - accuracy: 0.9894 - val_loss: 0.0306 - val_accuracy: 0.9904\n",
            "\n",
            "Epoch 00957: val_loss improved from 0.03096 to 0.03060, saving model to ./model/0.0306-0.9904-957.hdf5\n",
            "Epoch 958/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0360 - accuracy: 0.9900 - val_loss: 0.0347 - val_accuracy: 0.9897\n",
            "\n",
            "Epoch 00958: val_loss did not improve from 0.03060\n",
            "Epoch 959/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0314 - accuracy: 0.9916 - val_loss: 0.0332 - val_accuracy: 0.9897\n",
            "\n",
            "Epoch 00959: val_loss did not improve from 0.03060\n",
            "Epoch 960/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0335 - accuracy: 0.9915 - val_loss: 0.0335 - val_accuracy: 0.9904\n",
            "\n",
            "Epoch 00960: val_loss did not improve from 0.03060\n",
            "Epoch 961/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.0320 - accuracy: 0.9906 - val_loss: 0.0379 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00961: val_loss did not improve from 0.03060\n",
            "Epoch 962/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.0362 - accuracy: 0.9908 - val_loss: 0.0328 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00962: val_loss did not improve from 0.03060\n",
            "Epoch 963/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0316 - accuracy: 0.9931 - val_loss: 0.0368 - val_accuracy: 0.9891\n",
            "\n",
            "Epoch 00963: val_loss did not improve from 0.03060\n",
            "Epoch 964/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0346 - accuracy: 0.9919 - val_loss: 0.0358 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00964: val_loss did not improve from 0.03060\n",
            "Epoch 965/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0291 - accuracy: 0.9917 - val_loss: 0.0547 - val_accuracy: 0.9821\n",
            "\n",
            "Epoch 00965: val_loss did not improve from 0.03060\n",
            "Epoch 966/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0370 - accuracy: 0.9903 - val_loss: 0.0372 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00966: val_loss did not improve from 0.03060\n",
            "Epoch 967/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0336 - accuracy: 0.9912 - val_loss: 0.0404 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00967: val_loss did not improve from 0.03060\n",
            "Epoch 968/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0397 - accuracy: 0.9896 - val_loss: 0.0349 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00968: val_loss did not improve from 0.03060\n",
            "Epoch 969/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.0397 - accuracy: 0.9883 - val_loss: 0.0508 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00969: val_loss did not improve from 0.03060\n",
            "Epoch 970/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0489 - accuracy: 0.9863 - val_loss: 0.0362 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00970: val_loss did not improve from 0.03060\n",
            "Epoch 971/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.0461 - accuracy: 0.9879 - val_loss: 0.0354 - val_accuracy: 0.9891\n",
            "\n",
            "Epoch 00971: val_loss did not improve from 0.03060\n",
            "Epoch 972/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.0339 - accuracy: 0.9914 - val_loss: 0.0327 - val_accuracy: 0.9897\n",
            "\n",
            "Epoch 00972: val_loss did not improve from 0.03060\n",
            "Epoch 973/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0365 - accuracy: 0.9915 - val_loss: 0.0360 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00973: val_loss did not improve from 0.03060\n",
            "Epoch 974/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0360 - accuracy: 0.9904 - val_loss: 0.0340 - val_accuracy: 0.9891\n",
            "\n",
            "Epoch 00974: val_loss did not improve from 0.03060\n",
            "Epoch 975/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0368 - accuracy: 0.9914 - val_loss: 0.0499 - val_accuracy: 0.9840\n",
            "\n",
            "Epoch 00975: val_loss did not improve from 0.03060\n",
            "Epoch 976/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0354 - accuracy: 0.9912 - val_loss: 0.0336 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00976: val_loss did not improve from 0.03060\n",
            "Epoch 977/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0339 - accuracy: 0.9886 - val_loss: 0.0359 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00977: val_loss did not improve from 0.03060\n",
            "Epoch 978/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0450 - accuracy: 0.9872 - val_loss: 0.0328 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00978: val_loss did not improve from 0.03060\n",
            "Epoch 979/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.0433 - accuracy: 0.9864 - val_loss: 0.0356 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00979: val_loss did not improve from 0.03060\n",
            "Epoch 980/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.0424 - accuracy: 0.9860 - val_loss: 0.0330 - val_accuracy: 0.9897\n",
            "\n",
            "Epoch 00980: val_loss did not improve from 0.03060\n",
            "Epoch 981/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0371 - accuracy: 0.9905 - val_loss: 0.0329 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00981: val_loss did not improve from 0.03060\n",
            "Epoch 982/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.0410 - accuracy: 0.9881 - val_loss: 0.0326 - val_accuracy: 0.9897\n",
            "\n",
            "Epoch 00982: val_loss did not improve from 0.03060\n",
            "Epoch 983/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0402 - accuracy: 0.9903 - val_loss: 0.0322 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00983: val_loss did not improve from 0.03060\n",
            "Epoch 984/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0410 - accuracy: 0.9893 - val_loss: 0.0335 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00984: val_loss did not improve from 0.03060\n",
            "Epoch 985/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.0345 - accuracy: 0.9928 - val_loss: 0.0325 - val_accuracy: 0.9897\n",
            "\n",
            "Epoch 00985: val_loss did not improve from 0.03060\n",
            "Epoch 986/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.0379 - accuracy: 0.9912 - val_loss: 0.0320 - val_accuracy: 0.9891\n",
            "\n",
            "Epoch 00986: val_loss did not improve from 0.03060\n",
            "Epoch 987/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.0380 - accuracy: 0.9897 - val_loss: 0.0470 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00987: val_loss did not improve from 0.03060\n",
            "Epoch 988/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0388 - accuracy: 0.9892 - val_loss: 0.0371 - val_accuracy: 0.9891\n",
            "\n",
            "Epoch 00988: val_loss did not improve from 0.03060\n",
            "Epoch 989/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0361 - accuracy: 0.9899 - val_loss: 0.0386 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00989: val_loss did not improve from 0.03060\n",
            "Epoch 990/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.0401 - accuracy: 0.9899 - val_loss: 0.0332 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00990: val_loss did not improve from 0.03060\n",
            "Epoch 991/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0451 - accuracy: 0.9880 - val_loss: 0.0311 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00991: val_loss did not improve from 0.03060\n",
            "Epoch 992/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.0303 - accuracy: 0.9907 - val_loss: 0.0365 - val_accuracy: 0.9904\n",
            "\n",
            "Epoch 00992: val_loss did not improve from 0.03060\n",
            "Epoch 993/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0404 - accuracy: 0.9871 - val_loss: 0.0364 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00993: val_loss did not improve from 0.03060\n",
            "Epoch 994/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0370 - accuracy: 0.9886 - val_loss: 0.0434 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00994: val_loss did not improve from 0.03060\n",
            "Epoch 995/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0329 - accuracy: 0.9911 - val_loss: 0.0309 - val_accuracy: 0.9910\n",
            "\n",
            "Epoch 00995: val_loss did not improve from 0.03060\n",
            "Epoch 996/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0348 - accuracy: 0.9907 - val_loss: 0.0322 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00996: val_loss did not improve from 0.03060\n",
            "Epoch 997/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0328 - accuracy: 0.9912 - val_loss: 0.0328 - val_accuracy: 0.9897\n",
            "\n",
            "Epoch 00997: val_loss did not improve from 0.03060\n",
            "Epoch 998/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0351 - accuracy: 0.9907 - val_loss: 0.0361 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00998: val_loss did not improve from 0.03060\n",
            "Epoch 999/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.0318 - accuracy: 0.9899 - val_loss: 0.0464 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00999: val_loss did not improve from 0.03060\n",
            "Epoch 1000/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0420 - accuracy: 0.9907 - val_loss: 0.0321 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 01000: val_loss did not improve from 0.03060\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEb2BptsHySI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d406c460-fc6f-46b2-e5a5-eb456de5a1d6"
      },
      "source": [
        "'''model0.fit(x0_train, y0_train, epochs=100, batch_size=200, #와인질\n",
        "          validation_split=0.2, verbose=0, callbacks=[checkpointer0])\n",
        "'''\n",
        "wineclass = model0.fit(x0_train, y0_train, epochs=1000, batch_size=100, #와인질\n",
        "         validation_split=0.3, verbose=1, callbacks=[checkpointer0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "37/37 [==============================] - 90s 11ms/step - loss: 15.2826 - accuracy: 0.1748 - val_loss: 2.1652 - val_accuracy: 0.2244\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 2.16515, saving model to ./model0/2.1652-0.2244-01.hdf5\n",
            "Epoch 2/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.8500 - accuracy: 0.2498 - val_loss: 1.3843 - val_accuracy: 0.4128\n",
            "\n",
            "Epoch 00002: val_loss improved from 2.16515 to 1.38434, saving model to ./model0/1.3843-0.4128-02.hdf5\n",
            "Epoch 3/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.4137 - accuracy: 0.3839 - val_loss: 1.3055 - val_accuracy: 0.3981\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.38434 to 1.30550, saving model to ./model0/1.3055-0.3981-03.hdf5\n",
            "Epoch 4/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.3541 - accuracy: 0.3867 - val_loss: 1.2940 - val_accuracy: 0.4256\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.30550 to 1.29398, saving model to ./model0/1.2940-0.4256-04.hdf5\n",
            "Epoch 5/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.3158 - accuracy: 0.4077 - val_loss: 1.2701 - val_accuracy: 0.4340\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.29398 to 1.27007, saving model to ./model0/1.2701-0.4340-05.hdf5\n",
            "Epoch 6/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.3374 - accuracy: 0.4040 - val_loss: 1.2496 - val_accuracy: 0.4526\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.27007 to 1.24958, saving model to ./model0/1.2496-0.4526-06.hdf5\n",
            "Epoch 7/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.2944 - accuracy: 0.4311 - val_loss: 1.2415 - val_accuracy: 0.4526\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.24958 to 1.24154, saving model to ./model0/1.2415-0.4526-07.hdf5\n",
            "Epoch 8/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.3010 - accuracy: 0.4371 - val_loss: 1.2409 - val_accuracy: 0.4481\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.24154 to 1.24089, saving model to ./model0/1.2409-0.4481-08.hdf5\n",
            "Epoch 9/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.2825 - accuracy: 0.4569 - val_loss: 1.2226 - val_accuracy: 0.4647\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.24089 to 1.22262, saving model to ./model0/1.2226-0.4647-09.hdf5\n",
            "Epoch 10/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.2857 - accuracy: 0.4208 - val_loss: 1.2175 - val_accuracy: 0.4577\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.22262 to 1.21751, saving model to ./model0/1.2175-0.4577-10.hdf5\n",
            "Epoch 11/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.2715 - accuracy: 0.4270 - val_loss: 1.2065 - val_accuracy: 0.4622\n",
            "\n",
            "Epoch 00011: val_loss improved from 1.21751 to 1.20648, saving model to ./model0/1.2065-0.4622-11.hdf5\n",
            "Epoch 12/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.2657 - accuracy: 0.4554 - val_loss: 1.2064 - val_accuracy: 0.4590\n",
            "\n",
            "Epoch 00012: val_loss improved from 1.20648 to 1.20637, saving model to ./model0/1.2064-0.4590-12.hdf5\n",
            "Epoch 13/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.2566 - accuracy: 0.4317 - val_loss: 1.1913 - val_accuracy: 0.4609\n",
            "\n",
            "Epoch 00013: val_loss improved from 1.20637 to 1.19125, saving model to ./model0/1.1913-0.4609-13.hdf5\n",
            "Epoch 14/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.2446 - accuracy: 0.4494 - val_loss: 1.1841 - val_accuracy: 0.4654\n",
            "\n",
            "Epoch 00014: val_loss improved from 1.19125 to 1.18410, saving model to ./model0/1.1841-0.4654-14.hdf5\n",
            "Epoch 15/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.2327 - accuracy: 0.4407 - val_loss: 1.1877 - val_accuracy: 0.4654\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 1.18410\n",
            "Epoch 16/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.2296 - accuracy: 0.4539 - val_loss: 1.1770 - val_accuracy: 0.4756\n",
            "\n",
            "Epoch 00016: val_loss improved from 1.18410 to 1.17703, saving model to ./model0/1.1770-0.4756-16.hdf5\n",
            "Epoch 17/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.2353 - accuracy: 0.4481 - val_loss: 1.1710 - val_accuracy: 0.4628\n",
            "\n",
            "Epoch 00017: val_loss improved from 1.17703 to 1.17103, saving model to ./model0/1.1710-0.4628-17.hdf5\n",
            "Epoch 18/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.2235 - accuracy: 0.4733 - val_loss: 1.1643 - val_accuracy: 0.4667\n",
            "\n",
            "Epoch 00018: val_loss improved from 1.17103 to 1.16426, saving model to ./model0/1.1643-0.4667-18.hdf5\n",
            "Epoch 19/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.2133 - accuracy: 0.4716 - val_loss: 1.1699 - val_accuracy: 0.4846\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 1.16426\n",
            "Epoch 20/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.1921 - accuracy: 0.4564 - val_loss: 1.1621 - val_accuracy: 0.4679\n",
            "\n",
            "Epoch 00020: val_loss improved from 1.16426 to 1.16213, saving model to ./model0/1.1621-0.4679-20.hdf5\n",
            "Epoch 21/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.1900 - accuracy: 0.4839 - val_loss: 1.1700 - val_accuracy: 0.4705\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 1.16213\n",
            "Epoch 22/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.1782 - accuracy: 0.4742 - val_loss: 1.1521 - val_accuracy: 0.4769\n",
            "\n",
            "Epoch 00022: val_loss improved from 1.16213 to 1.15211, saving model to ./model0/1.1521-0.4769-22.hdf5\n",
            "Epoch 23/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.2193 - accuracy: 0.4615 - val_loss: 1.1436 - val_accuracy: 0.4782\n",
            "\n",
            "Epoch 00023: val_loss improved from 1.15211 to 1.14362, saving model to ./model0/1.1436-0.4782-23.hdf5\n",
            "Epoch 24/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.1794 - accuracy: 0.4734 - val_loss: 1.1773 - val_accuracy: 0.4615\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 1.14362\n",
            "Epoch 25/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.2003 - accuracy: 0.4615 - val_loss: 1.1398 - val_accuracy: 0.4904\n",
            "\n",
            "Epoch 00025: val_loss improved from 1.14362 to 1.13980, saving model to ./model0/1.1398-0.4904-25.hdf5\n",
            "Epoch 26/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.1756 - accuracy: 0.5013 - val_loss: 1.1449 - val_accuracy: 0.4853\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 1.13980\n",
            "Epoch 27/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.1877 - accuracy: 0.4664 - val_loss: 1.1379 - val_accuracy: 0.4929\n",
            "\n",
            "Epoch 00027: val_loss improved from 1.13980 to 1.13790, saving model to ./model0/1.1379-0.4929-27.hdf5\n",
            "Epoch 28/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.1887 - accuracy: 0.4638 - val_loss: 1.1281 - val_accuracy: 0.4974\n",
            "\n",
            "Epoch 00028: val_loss improved from 1.13790 to 1.12807, saving model to ./model0/1.1281-0.4974-28.hdf5\n",
            "Epoch 29/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.1656 - accuracy: 0.4958 - val_loss: 1.1269 - val_accuracy: 0.4974\n",
            "\n",
            "Epoch 00029: val_loss improved from 1.12807 to 1.12695, saving model to ./model0/1.1269-0.4974-29.hdf5\n",
            "Epoch 30/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.1609 - accuracy: 0.4947 - val_loss: 1.1269 - val_accuracy: 0.4987\n",
            "\n",
            "Epoch 00030: val_loss improved from 1.12695 to 1.12692, saving model to ./model0/1.1269-0.4987-30.hdf5\n",
            "Epoch 31/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.1521 - accuracy: 0.4939 - val_loss: 1.1177 - val_accuracy: 0.5096\n",
            "\n",
            "Epoch 00031: val_loss improved from 1.12692 to 1.11770, saving model to ./model0/1.1177-0.5096-31.hdf5\n",
            "Epoch 32/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.1725 - accuracy: 0.5007 - val_loss: 1.1146 - val_accuracy: 0.5051\n",
            "\n",
            "Epoch 00032: val_loss improved from 1.11770 to 1.11460, saving model to ./model0/1.1146-0.5051-32.hdf5\n",
            "Epoch 33/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.1495 - accuracy: 0.5019 - val_loss: 1.1098 - val_accuracy: 0.5179\n",
            "\n",
            "Epoch 00033: val_loss improved from 1.11460 to 1.10980, saving model to ./model0/1.1098-0.5179-33.hdf5\n",
            "Epoch 34/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.1382 - accuracy: 0.5139 - val_loss: 1.1179 - val_accuracy: 0.5147\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 1.10980\n",
            "Epoch 35/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.1428 - accuracy: 0.4969 - val_loss: 1.1159 - val_accuracy: 0.5045\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 1.10980\n",
            "Epoch 36/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.1746 - accuracy: 0.4919 - val_loss: 1.1092 - val_accuracy: 0.5224\n",
            "\n",
            "Epoch 00036: val_loss improved from 1.10980 to 1.10916, saving model to ./model0/1.1092-0.5224-36.hdf5\n",
            "Epoch 37/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.1290 - accuracy: 0.5085 - val_loss: 1.1099 - val_accuracy: 0.5045\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 1.10916\n",
            "Epoch 38/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.1531 - accuracy: 0.4975 - val_loss: 1.1443 - val_accuracy: 0.4955\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 1.10916\n",
            "Epoch 39/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.1376 - accuracy: 0.4970 - val_loss: 1.1364 - val_accuracy: 0.5013\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 1.10916\n",
            "Epoch 40/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.1346 - accuracy: 0.5222 - val_loss: 1.1139 - val_accuracy: 0.5077\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 1.10916\n",
            "Epoch 41/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.1339 - accuracy: 0.4947 - val_loss: 1.1091 - val_accuracy: 0.5064\n",
            "\n",
            "Epoch 00041: val_loss improved from 1.10916 to 1.10910, saving model to ./model0/1.1091-0.5064-41.hdf5\n",
            "Epoch 42/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.1147 - accuracy: 0.5213 - val_loss: 1.0947 - val_accuracy: 0.5224\n",
            "\n",
            "Epoch 00042: val_loss improved from 1.10910 to 1.09470, saving model to ./model0/1.0947-0.5224-42.hdf5\n",
            "Epoch 43/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.1264 - accuracy: 0.5124 - val_loss: 1.1143 - val_accuracy: 0.5019\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 1.09470\n",
            "Epoch 44/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.1337 - accuracy: 0.4947 - val_loss: 1.0931 - val_accuracy: 0.5327\n",
            "\n",
            "Epoch 00044: val_loss improved from 1.09470 to 1.09312, saving model to ./model0/1.0931-0.5327-44.hdf5\n",
            "Epoch 45/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.1249 - accuracy: 0.5237 - val_loss: 1.1001 - val_accuracy: 0.5327\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 1.09312\n",
            "Epoch 46/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.1421 - accuracy: 0.5029 - val_loss: 1.1042 - val_accuracy: 0.5147\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 1.09312\n",
            "Epoch 47/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.1054 - accuracy: 0.5189 - val_loss: 1.1153 - val_accuracy: 0.5013\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 1.09312\n",
            "Epoch 48/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.1552 - accuracy: 0.4978 - val_loss: 1.1084 - val_accuracy: 0.5173\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 1.09312\n",
            "Epoch 49/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.1310 - accuracy: 0.5028 - val_loss: 1.0931 - val_accuracy: 0.5321\n",
            "\n",
            "Epoch 00049: val_loss improved from 1.09312 to 1.09308, saving model to ./model0/1.0931-0.5321-49.hdf5\n",
            "Epoch 50/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.1252 - accuracy: 0.5008 - val_loss: 1.1540 - val_accuracy: 0.4955\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 1.09308\n",
            "Epoch 51/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.1095 - accuracy: 0.5258 - val_loss: 1.1175 - val_accuracy: 0.5122\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 1.09308\n",
            "Epoch 52/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.1098 - accuracy: 0.5354 - val_loss: 1.1060 - val_accuracy: 0.5109\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 1.09308\n",
            "Epoch 53/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.1019 - accuracy: 0.5147 - val_loss: 1.1096 - val_accuracy: 0.5115\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 1.09308\n",
            "Epoch 54/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.1349 - accuracy: 0.4974 - val_loss: 1.0999 - val_accuracy: 0.5083\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 1.09308\n",
            "Epoch 55/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0981 - accuracy: 0.5318 - val_loss: 1.0887 - val_accuracy: 0.5340\n",
            "\n",
            "Epoch 00055: val_loss improved from 1.09308 to 1.08868, saving model to ./model0/1.0887-0.5340-55.hdf5\n",
            "Epoch 56/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.1091 - accuracy: 0.5300 - val_loss: 1.1400 - val_accuracy: 0.4769\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 1.08868\n",
            "Epoch 57/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.1175 - accuracy: 0.5020 - val_loss: 1.1144 - val_accuracy: 0.5128\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 1.08868\n",
            "Epoch 58/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.1026 - accuracy: 0.5223 - val_loss: 1.0841 - val_accuracy: 0.5250\n",
            "\n",
            "Epoch 00058: val_loss improved from 1.08868 to 1.08413, saving model to ./model0/1.0841-0.5250-58.hdf5\n",
            "Epoch 59/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.1032 - accuracy: 0.5303 - val_loss: 1.0922 - val_accuracy: 0.5237\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 1.08413\n",
            "Epoch 60/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.1027 - accuracy: 0.5288 - val_loss: 1.1027 - val_accuracy: 0.5096\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 1.08413\n",
            "Epoch 61/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0970 - accuracy: 0.5261 - val_loss: 1.0773 - val_accuracy: 0.5327\n",
            "\n",
            "Epoch 00061: val_loss improved from 1.08413 to 1.07733, saving model to ./model0/1.0773-0.5327-61.hdf5\n",
            "Epoch 62/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0959 - accuracy: 0.5323 - val_loss: 1.0986 - val_accuracy: 0.5096\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 1.07733\n",
            "Epoch 63/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.1280 - accuracy: 0.5204 - val_loss: 1.0965 - val_accuracy: 0.5308\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 1.07733\n",
            "Epoch 64/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.1278 - accuracy: 0.5020 - val_loss: 1.0835 - val_accuracy: 0.5404\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 1.07733\n",
            "Epoch 65/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.1355 - accuracy: 0.5176 - val_loss: 1.0844 - val_accuracy: 0.5205\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 1.07733\n",
            "Epoch 66/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.1026 - accuracy: 0.5150 - val_loss: 1.0737 - val_accuracy: 0.5314\n",
            "\n",
            "Epoch 00066: val_loss improved from 1.07733 to 1.07368, saving model to ./model0/1.0737-0.5314-66.hdf5\n",
            "Epoch 67/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.1147 - accuracy: 0.5270 - val_loss: 1.0804 - val_accuracy: 0.5385\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 1.07368\n",
            "Epoch 68/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.1035 - accuracy: 0.5260 - val_loss: 1.0800 - val_accuracy: 0.5378\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 1.07368\n",
            "Epoch 69/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0938 - accuracy: 0.5302 - val_loss: 1.0776 - val_accuracy: 0.5308\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 1.07368\n",
            "Epoch 70/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0977 - accuracy: 0.5343 - val_loss: 1.0824 - val_accuracy: 0.5353\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 1.07368\n",
            "Epoch 71/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.1211 - accuracy: 0.5264 - val_loss: 1.1003 - val_accuracy: 0.5237\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 1.07368\n",
            "Epoch 72/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.1107 - accuracy: 0.5258 - val_loss: 1.0814 - val_accuracy: 0.5340\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 1.07368\n",
            "Epoch 73/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0930 - accuracy: 0.5329 - val_loss: 1.0712 - val_accuracy: 0.5327\n",
            "\n",
            "Epoch 00073: val_loss improved from 1.07368 to 1.07118, saving model to ./model0/1.0712-0.5327-73.hdf5\n",
            "Epoch 74/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0905 - accuracy: 0.5413 - val_loss: 1.0839 - val_accuracy: 0.5321\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 1.07118\n",
            "Epoch 75/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.1004 - accuracy: 0.5429 - val_loss: 1.1096 - val_accuracy: 0.5141\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 1.07118\n",
            "Epoch 76/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.1285 - accuracy: 0.5097 - val_loss: 1.0827 - val_accuracy: 0.5186\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 1.07118\n",
            "Epoch 77/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.1066 - accuracy: 0.5270 - val_loss: 1.0737 - val_accuracy: 0.5250\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 1.07118\n",
            "Epoch 78/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0948 - accuracy: 0.5162 - val_loss: 1.0765 - val_accuracy: 0.5327\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 1.07118\n",
            "Epoch 79/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0776 - accuracy: 0.5332 - val_loss: 1.0721 - val_accuracy: 0.5212\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 1.07118\n",
            "Epoch 80/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.1135 - accuracy: 0.5193 - val_loss: 1.0843 - val_accuracy: 0.5308\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 1.07118\n",
            "Epoch 81/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0957 - accuracy: 0.5274 - val_loss: 1.0823 - val_accuracy: 0.5301\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 1.07118\n",
            "Epoch 82/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.1137 - accuracy: 0.5207 - val_loss: 1.0696 - val_accuracy: 0.5378\n",
            "\n",
            "Epoch 00082: val_loss improved from 1.07118 to 1.06962, saving model to ./model0/1.0696-0.5378-82.hdf5\n",
            "Epoch 83/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.1202 - accuracy: 0.5127 - val_loss: 1.0830 - val_accuracy: 0.5231\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 1.06962\n",
            "Epoch 84/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.1138 - accuracy: 0.5162 - val_loss: 1.0728 - val_accuracy: 0.5295\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 1.06962\n",
            "Epoch 85/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.1024 - accuracy: 0.5261 - val_loss: 1.0727 - val_accuracy: 0.5346\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 1.06962\n",
            "Epoch 86/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.1131 - accuracy: 0.5176 - val_loss: 1.0889 - val_accuracy: 0.5179\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 1.06962\n",
            "Epoch 87/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0915 - accuracy: 0.5274 - val_loss: 1.1250 - val_accuracy: 0.5045\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 1.06962\n",
            "Epoch 88/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.1008 - accuracy: 0.5224 - val_loss: 1.0695 - val_accuracy: 0.5333\n",
            "\n",
            "Epoch 00088: val_loss improved from 1.06962 to 1.06946, saving model to ./model0/1.0695-0.5333-88.hdf5\n",
            "Epoch 89/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0789 - accuracy: 0.5255 - val_loss: 1.0716 - val_accuracy: 0.5378\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 1.06946\n",
            "Epoch 90/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0944 - accuracy: 0.5253 - val_loss: 1.0670 - val_accuracy: 0.5365\n",
            "\n",
            "Epoch 00090: val_loss improved from 1.06946 to 1.06700, saving model to ./model0/1.0670-0.5365-90.hdf5\n",
            "Epoch 91/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.1037 - accuracy: 0.5278 - val_loss: 1.0743 - val_accuracy: 0.5276\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 1.06700\n",
            "Epoch 92/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0708 - accuracy: 0.5341 - val_loss: 1.0928 - val_accuracy: 0.5199\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 1.06700\n",
            "Epoch 93/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.1221 - accuracy: 0.5073 - val_loss: 1.0697 - val_accuracy: 0.5333\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 1.06700\n",
            "Epoch 94/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0949 - accuracy: 0.5266 - val_loss: 1.0760 - val_accuracy: 0.5231\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 1.06700\n",
            "Epoch 95/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.1052 - accuracy: 0.5283 - val_loss: 1.1270 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 1.06700\n",
            "Epoch 96/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.1048 - accuracy: 0.5108 - val_loss: 1.0938 - val_accuracy: 0.5179\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 1.06700\n",
            "Epoch 97/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.1014 - accuracy: 0.5131 - val_loss: 1.0743 - val_accuracy: 0.5263\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 1.06700\n",
            "Epoch 98/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.1161 - accuracy: 0.5264 - val_loss: 1.0946 - val_accuracy: 0.5115\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 1.06700\n",
            "Epoch 99/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.1035 - accuracy: 0.5079 - val_loss: 1.0679 - val_accuracy: 0.5301\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 1.06700\n",
            "Epoch 100/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0956 - accuracy: 0.5287 - val_loss: 1.0620 - val_accuracy: 0.5372\n",
            "\n",
            "Epoch 00100: val_loss improved from 1.06700 to 1.06198, saving model to ./model0/1.0620-0.5372-100.hdf5\n",
            "Epoch 101/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0814 - accuracy: 0.5355 - val_loss: 1.0758 - val_accuracy: 0.5333\n",
            "\n",
            "Epoch 00101: val_loss did not improve from 1.06198\n",
            "Epoch 102/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.0863 - accuracy: 0.5179 - val_loss: 1.0678 - val_accuracy: 0.5436\n",
            "\n",
            "Epoch 00102: val_loss did not improve from 1.06198\n",
            "Epoch 103/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0784 - accuracy: 0.5311 - val_loss: 1.0832 - val_accuracy: 0.5231\n",
            "\n",
            "Epoch 00103: val_loss did not improve from 1.06198\n",
            "Epoch 104/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0866 - accuracy: 0.5212 - val_loss: 1.0645 - val_accuracy: 0.5455\n",
            "\n",
            "Epoch 00104: val_loss did not improve from 1.06198\n",
            "Epoch 105/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0947 - accuracy: 0.5307 - val_loss: 1.0662 - val_accuracy: 0.5340\n",
            "\n",
            "Epoch 00105: val_loss did not improve from 1.06198\n",
            "Epoch 106/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0791 - accuracy: 0.5311 - val_loss: 1.0861 - val_accuracy: 0.5276\n",
            "\n",
            "Epoch 00106: val_loss did not improve from 1.06198\n",
            "Epoch 107/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.1115 - accuracy: 0.5337 - val_loss: 1.0701 - val_accuracy: 0.5474\n",
            "\n",
            "Epoch 00107: val_loss did not improve from 1.06198\n",
            "Epoch 108/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.1094 - accuracy: 0.5150 - val_loss: 1.0647 - val_accuracy: 0.5372\n",
            "\n",
            "Epoch 00108: val_loss did not improve from 1.06198\n",
            "Epoch 109/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0715 - accuracy: 0.5301 - val_loss: 1.0747 - val_accuracy: 0.5192\n",
            "\n",
            "Epoch 00109: val_loss did not improve from 1.06198\n",
            "Epoch 110/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.1045 - accuracy: 0.5149 - val_loss: 1.0767 - val_accuracy: 0.5288\n",
            "\n",
            "Epoch 00110: val_loss did not improve from 1.06198\n",
            "Epoch 111/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0835 - accuracy: 0.5239 - val_loss: 1.0787 - val_accuracy: 0.5263\n",
            "\n",
            "Epoch 00111: val_loss did not improve from 1.06198\n",
            "Epoch 112/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0818 - accuracy: 0.5274 - val_loss: 1.0747 - val_accuracy: 0.5237\n",
            "\n",
            "Epoch 00112: val_loss did not improve from 1.06198\n",
            "Epoch 113/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0638 - accuracy: 0.5339 - val_loss: 1.0660 - val_accuracy: 0.5327\n",
            "\n",
            "Epoch 00113: val_loss did not improve from 1.06198\n",
            "Epoch 114/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.0896 - accuracy: 0.5253 - val_loss: 1.0636 - val_accuracy: 0.5429\n",
            "\n",
            "Epoch 00114: val_loss did not improve from 1.06198\n",
            "Epoch 115/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0983 - accuracy: 0.5194 - val_loss: 1.0678 - val_accuracy: 0.5282\n",
            "\n",
            "Epoch 00115: val_loss did not improve from 1.06198\n",
            "Epoch 116/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0569 - accuracy: 0.5310 - val_loss: 1.1146 - val_accuracy: 0.5122\n",
            "\n",
            "Epoch 00116: val_loss did not improve from 1.06198\n",
            "Epoch 117/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.1082 - accuracy: 0.5164 - val_loss: 1.0673 - val_accuracy: 0.5417\n",
            "\n",
            "Epoch 00117: val_loss did not improve from 1.06198\n",
            "Epoch 118/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0785 - accuracy: 0.5343 - val_loss: 1.0637 - val_accuracy: 0.5333\n",
            "\n",
            "Epoch 00118: val_loss did not improve from 1.06198\n",
            "Epoch 119/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.1090 - accuracy: 0.5251 - val_loss: 1.0892 - val_accuracy: 0.5231\n",
            "\n",
            "Epoch 00119: val_loss did not improve from 1.06198\n",
            "Epoch 120/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.0919 - accuracy: 0.5255 - val_loss: 1.0707 - val_accuracy: 0.5333\n",
            "\n",
            "Epoch 00120: val_loss did not improve from 1.06198\n",
            "Epoch 121/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0662 - accuracy: 0.5349 - val_loss: 1.0669 - val_accuracy: 0.5429\n",
            "\n",
            "Epoch 00121: val_loss did not improve from 1.06198\n",
            "Epoch 122/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0894 - accuracy: 0.5271 - val_loss: 1.0593 - val_accuracy: 0.5365\n",
            "\n",
            "Epoch 00122: val_loss improved from 1.06198 to 1.05927, saving model to ./model0/1.0593-0.5365-122.hdf5\n",
            "Epoch 123/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0593 - accuracy: 0.5376 - val_loss: 1.0586 - val_accuracy: 0.5378\n",
            "\n",
            "Epoch 00123: val_loss improved from 1.05927 to 1.05863, saving model to ./model0/1.0586-0.5378-123.hdf5\n",
            "Epoch 124/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0969 - accuracy: 0.5235 - val_loss: 1.0623 - val_accuracy: 0.5474\n",
            "\n",
            "Epoch 00124: val_loss did not improve from 1.05863\n",
            "Epoch 125/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0693 - accuracy: 0.5360 - val_loss: 1.0722 - val_accuracy: 0.5417\n",
            "\n",
            "Epoch 00125: val_loss did not improve from 1.05863\n",
            "Epoch 126/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0956 - accuracy: 0.5210 - val_loss: 1.0652 - val_accuracy: 0.5321\n",
            "\n",
            "Epoch 00126: val_loss did not improve from 1.05863\n",
            "Epoch 127/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0789 - accuracy: 0.5304 - val_loss: 1.0641 - val_accuracy: 0.5321\n",
            "\n",
            "Epoch 00127: val_loss did not improve from 1.05863\n",
            "Epoch 128/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0907 - accuracy: 0.5306 - val_loss: 1.0718 - val_accuracy: 0.5314\n",
            "\n",
            "Epoch 00128: val_loss did not improve from 1.05863\n",
            "Epoch 129/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.1043 - accuracy: 0.5169 - val_loss: 1.0700 - val_accuracy: 0.5346\n",
            "\n",
            "Epoch 00129: val_loss did not improve from 1.05863\n",
            "Epoch 130/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0763 - accuracy: 0.5306 - val_loss: 1.0622 - val_accuracy: 0.5436\n",
            "\n",
            "Epoch 00130: val_loss did not improve from 1.05863\n",
            "Epoch 131/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.1056 - accuracy: 0.5217 - val_loss: 1.0635 - val_accuracy: 0.5391\n",
            "\n",
            "Epoch 00131: val_loss did not improve from 1.05863\n",
            "Epoch 132/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0793 - accuracy: 0.5359 - val_loss: 1.0680 - val_accuracy: 0.5397\n",
            "\n",
            "Epoch 00132: val_loss did not improve from 1.05863\n",
            "Epoch 133/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.0904 - accuracy: 0.5274 - val_loss: 1.1695 - val_accuracy: 0.4795\n",
            "\n",
            "Epoch 00133: val_loss did not improve from 1.05863\n",
            "Epoch 134/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.1293 - accuracy: 0.5088 - val_loss: 1.0798 - val_accuracy: 0.5365\n",
            "\n",
            "Epoch 00134: val_loss did not improve from 1.05863\n",
            "Epoch 135/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0881 - accuracy: 0.5283 - val_loss: 1.0616 - val_accuracy: 0.5327\n",
            "\n",
            "Epoch 00135: val_loss did not improve from 1.05863\n",
            "Epoch 136/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0869 - accuracy: 0.5348 - val_loss: 1.1022 - val_accuracy: 0.5115\n",
            "\n",
            "Epoch 00136: val_loss did not improve from 1.05863\n",
            "Epoch 137/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.1066 - accuracy: 0.5250 - val_loss: 1.1008 - val_accuracy: 0.5179\n",
            "\n",
            "Epoch 00137: val_loss did not improve from 1.05863\n",
            "Epoch 138/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0998 - accuracy: 0.5197 - val_loss: 1.0717 - val_accuracy: 0.5256\n",
            "\n",
            "Epoch 00138: val_loss did not improve from 1.05863\n",
            "Epoch 139/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0733 - accuracy: 0.5349 - val_loss: 1.0659 - val_accuracy: 0.5410\n",
            "\n",
            "Epoch 00139: val_loss did not improve from 1.05863\n",
            "Epoch 140/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0702 - accuracy: 0.5408 - val_loss: 1.0610 - val_accuracy: 0.5301\n",
            "\n",
            "Epoch 00140: val_loss did not improve from 1.05863\n",
            "Epoch 141/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0800 - accuracy: 0.5333 - val_loss: 1.0635 - val_accuracy: 0.5314\n",
            "\n",
            "Epoch 00141: val_loss did not improve from 1.05863\n",
            "Epoch 142/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0992 - accuracy: 0.5337 - val_loss: 1.0608 - val_accuracy: 0.5346\n",
            "\n",
            "Epoch 00142: val_loss did not improve from 1.05863\n",
            "Epoch 143/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.1008 - accuracy: 0.5212 - val_loss: 1.0705 - val_accuracy: 0.5321\n",
            "\n",
            "Epoch 00143: val_loss did not improve from 1.05863\n",
            "Epoch 144/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.0832 - accuracy: 0.5246 - val_loss: 1.0620 - val_accuracy: 0.5404\n",
            "\n",
            "Epoch 00144: val_loss did not improve from 1.05863\n",
            "Epoch 145/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0804 - accuracy: 0.5264 - val_loss: 1.0901 - val_accuracy: 0.5250\n",
            "\n",
            "Epoch 00145: val_loss did not improve from 1.05863\n",
            "Epoch 146/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0583 - accuracy: 0.5347 - val_loss: 1.0891 - val_accuracy: 0.5109\n",
            "\n",
            "Epoch 00146: val_loss did not improve from 1.05863\n",
            "Epoch 147/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.1121 - accuracy: 0.5163 - val_loss: 1.0691 - val_accuracy: 0.5353\n",
            "\n",
            "Epoch 00147: val_loss did not improve from 1.05863\n",
            "Epoch 148/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0884 - accuracy: 0.5193 - val_loss: 1.0802 - val_accuracy: 0.5231\n",
            "\n",
            "Epoch 00148: val_loss did not improve from 1.05863\n",
            "Epoch 149/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0912 - accuracy: 0.5204 - val_loss: 1.0691 - val_accuracy: 0.5308\n",
            "\n",
            "Epoch 00149: val_loss did not improve from 1.05863\n",
            "Epoch 150/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.1008 - accuracy: 0.5307 - val_loss: 1.0599 - val_accuracy: 0.5340\n",
            "\n",
            "Epoch 00150: val_loss did not improve from 1.05863\n",
            "Epoch 151/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0887 - accuracy: 0.5238 - val_loss: 1.0604 - val_accuracy: 0.5353\n",
            "\n",
            "Epoch 00151: val_loss did not improve from 1.05863\n",
            "Epoch 152/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0683 - accuracy: 0.5293 - val_loss: 1.0564 - val_accuracy: 0.5404\n",
            "\n",
            "Epoch 00152: val_loss improved from 1.05863 to 1.05636, saving model to ./model0/1.0564-0.5404-152.hdf5\n",
            "Epoch 153/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0698 - accuracy: 0.5331 - val_loss: 1.0648 - val_accuracy: 0.5327\n",
            "\n",
            "Epoch 00153: val_loss did not improve from 1.05636\n",
            "Epoch 154/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0742 - accuracy: 0.5321 - val_loss: 1.0605 - val_accuracy: 0.5314\n",
            "\n",
            "Epoch 00154: val_loss did not improve from 1.05636\n",
            "Epoch 155/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0677 - accuracy: 0.5380 - val_loss: 1.0579 - val_accuracy: 0.5436\n",
            "\n",
            "Epoch 00155: val_loss did not improve from 1.05636\n",
            "Epoch 156/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0578 - accuracy: 0.5378 - val_loss: 1.0618 - val_accuracy: 0.5295\n",
            "\n",
            "Epoch 00156: val_loss did not improve from 1.05636\n",
            "Epoch 157/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0830 - accuracy: 0.5298 - val_loss: 1.0669 - val_accuracy: 0.5333\n",
            "\n",
            "Epoch 00157: val_loss did not improve from 1.05636\n",
            "Epoch 158/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0854 - accuracy: 0.5382 - val_loss: 1.0564 - val_accuracy: 0.5365\n",
            "\n",
            "Epoch 00158: val_loss did not improve from 1.05636\n",
            "Epoch 159/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0552 - accuracy: 0.5310 - val_loss: 1.1110 - val_accuracy: 0.5013\n",
            "\n",
            "Epoch 00159: val_loss did not improve from 1.05636\n",
            "Epoch 160/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0768 - accuracy: 0.5157 - val_loss: 1.0726 - val_accuracy: 0.5256\n",
            "\n",
            "Epoch 00160: val_loss did not improve from 1.05636\n",
            "Epoch 161/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0818 - accuracy: 0.5397 - val_loss: 1.0659 - val_accuracy: 0.5378\n",
            "\n",
            "Epoch 00161: val_loss did not improve from 1.05636\n",
            "Epoch 162/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.0750 - accuracy: 0.5473 - val_loss: 1.0599 - val_accuracy: 0.5365\n",
            "\n",
            "Epoch 00162: val_loss did not improve from 1.05636\n",
            "Epoch 163/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0941 - accuracy: 0.5312 - val_loss: 1.0652 - val_accuracy: 0.5423\n",
            "\n",
            "Epoch 00163: val_loss did not improve from 1.05636\n",
            "Epoch 164/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0829 - accuracy: 0.5260 - val_loss: 1.0629 - val_accuracy: 0.5417\n",
            "\n",
            "Epoch 00164: val_loss did not improve from 1.05636\n",
            "Epoch 165/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0668 - accuracy: 0.5309 - val_loss: 1.0774 - val_accuracy: 0.5212\n",
            "\n",
            "Epoch 00165: val_loss did not improve from 1.05636\n",
            "Epoch 166/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0840 - accuracy: 0.5269 - val_loss: 1.0577 - val_accuracy: 0.5436\n",
            "\n",
            "Epoch 00166: val_loss did not improve from 1.05636\n",
            "Epoch 167/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0827 - accuracy: 0.5233 - val_loss: 1.0598 - val_accuracy: 0.5423\n",
            "\n",
            "Epoch 00167: val_loss did not improve from 1.05636\n",
            "Epoch 168/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0788 - accuracy: 0.5324 - val_loss: 1.0580 - val_accuracy: 0.5417\n",
            "\n",
            "Epoch 00168: val_loss did not improve from 1.05636\n",
            "Epoch 169/1000\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.0663 - accuracy: 0.5446 - val_loss: 1.0690 - val_accuracy: 0.5385\n",
            "\n",
            "Epoch 00169: val_loss did not improve from 1.05636\n",
            "Epoch 170/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0716 - accuracy: 0.5305 - val_loss: 1.0775 - val_accuracy: 0.5301\n",
            "\n",
            "Epoch 00170: val_loss did not improve from 1.05636\n",
            "Epoch 171/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0687 - accuracy: 0.5280 - val_loss: 1.0602 - val_accuracy: 0.5378\n",
            "\n",
            "Epoch 00171: val_loss did not improve from 1.05636\n",
            "Epoch 172/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0968 - accuracy: 0.5244 - val_loss: 1.0603 - val_accuracy: 0.5410\n",
            "\n",
            "Epoch 00172: val_loss did not improve from 1.05636\n",
            "Epoch 173/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0757 - accuracy: 0.5360 - val_loss: 1.0841 - val_accuracy: 0.5212\n",
            "\n",
            "Epoch 00173: val_loss did not improve from 1.05636\n",
            "Epoch 174/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0881 - accuracy: 0.5286 - val_loss: 1.0606 - val_accuracy: 0.5224\n",
            "\n",
            "Epoch 00174: val_loss did not improve from 1.05636\n",
            "Epoch 175/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0644 - accuracy: 0.5427 - val_loss: 1.0637 - val_accuracy: 0.5340\n",
            "\n",
            "Epoch 00175: val_loss did not improve from 1.05636\n",
            "Epoch 176/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0816 - accuracy: 0.5271 - val_loss: 1.0929 - val_accuracy: 0.5122\n",
            "\n",
            "Epoch 00176: val_loss did not improve from 1.05636\n",
            "Epoch 177/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0811 - accuracy: 0.5300 - val_loss: 1.0665 - val_accuracy: 0.5353\n",
            "\n",
            "Epoch 00177: val_loss did not improve from 1.05636\n",
            "Epoch 178/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0705 - accuracy: 0.5326 - val_loss: 1.0666 - val_accuracy: 0.5391\n",
            "\n",
            "Epoch 00178: val_loss did not improve from 1.05636\n",
            "Epoch 179/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0702 - accuracy: 0.5419 - val_loss: 1.0708 - val_accuracy: 0.5321\n",
            "\n",
            "Epoch 00179: val_loss did not improve from 1.05636\n",
            "Epoch 180/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0881 - accuracy: 0.5296 - val_loss: 1.0619 - val_accuracy: 0.5308\n",
            "\n",
            "Epoch 00180: val_loss did not improve from 1.05636\n",
            "Epoch 181/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0745 - accuracy: 0.5267 - val_loss: 1.0612 - val_accuracy: 0.5359\n",
            "\n",
            "Epoch 00181: val_loss did not improve from 1.05636\n",
            "Epoch 182/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0670 - accuracy: 0.5410 - val_loss: 1.0796 - val_accuracy: 0.5282\n",
            "\n",
            "Epoch 00182: val_loss did not improve from 1.05636\n",
            "Epoch 183/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0663 - accuracy: 0.5394 - val_loss: 1.0639 - val_accuracy: 0.5365\n",
            "\n",
            "Epoch 00183: val_loss did not improve from 1.05636\n",
            "Epoch 184/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0836 - accuracy: 0.5258 - val_loss: 1.0595 - val_accuracy: 0.5397\n",
            "\n",
            "Epoch 00184: val_loss did not improve from 1.05636\n",
            "Epoch 185/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0797 - accuracy: 0.5370 - val_loss: 1.0592 - val_accuracy: 0.5340\n",
            "\n",
            "Epoch 00185: val_loss did not improve from 1.05636\n",
            "Epoch 186/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0760 - accuracy: 0.5196 - val_loss: 1.0807 - val_accuracy: 0.5276\n",
            "\n",
            "Epoch 00186: val_loss did not improve from 1.05636\n",
            "Epoch 187/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0799 - accuracy: 0.5376 - val_loss: 1.0878 - val_accuracy: 0.5282\n",
            "\n",
            "Epoch 00187: val_loss did not improve from 1.05636\n",
            "Epoch 188/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0670 - accuracy: 0.5553 - val_loss: 1.0548 - val_accuracy: 0.5365\n",
            "\n",
            "Epoch 00188: val_loss improved from 1.05636 to 1.05482, saving model to ./model0/1.0548-0.5365-188.hdf5\n",
            "Epoch 189/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0864 - accuracy: 0.5379 - val_loss: 1.0675 - val_accuracy: 0.5391\n",
            "\n",
            "Epoch 00189: val_loss did not improve from 1.05482\n",
            "Epoch 190/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0722 - accuracy: 0.5395 - val_loss: 1.1241 - val_accuracy: 0.5064\n",
            "\n",
            "Epoch 00190: val_loss did not improve from 1.05482\n",
            "Epoch 191/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0726 - accuracy: 0.5266 - val_loss: 1.0548 - val_accuracy: 0.5404\n",
            "\n",
            "Epoch 00191: val_loss did not improve from 1.05482\n",
            "Epoch 192/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0635 - accuracy: 0.5289 - val_loss: 1.0956 - val_accuracy: 0.5199\n",
            "\n",
            "Epoch 00192: val_loss did not improve from 1.05482\n",
            "Epoch 193/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0840 - accuracy: 0.5281 - val_loss: 1.0590 - val_accuracy: 0.5327\n",
            "\n",
            "Epoch 00193: val_loss did not improve from 1.05482\n",
            "Epoch 194/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0941 - accuracy: 0.5415 - val_loss: 1.0572 - val_accuracy: 0.5353\n",
            "\n",
            "Epoch 00194: val_loss did not improve from 1.05482\n",
            "Epoch 195/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0900 - accuracy: 0.5360 - val_loss: 1.0759 - val_accuracy: 0.5231\n",
            "\n",
            "Epoch 00195: val_loss did not improve from 1.05482\n",
            "Epoch 196/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0506 - accuracy: 0.5376 - val_loss: 1.0917 - val_accuracy: 0.5147\n",
            "\n",
            "Epoch 00196: val_loss did not improve from 1.05482\n",
            "Epoch 197/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.1145 - accuracy: 0.5132 - val_loss: 1.0528 - val_accuracy: 0.5429\n",
            "\n",
            "Epoch 00197: val_loss improved from 1.05482 to 1.05283, saving model to ./model0/1.0528-0.5429-197.hdf5\n",
            "Epoch 198/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0560 - accuracy: 0.5421 - val_loss: 1.0526 - val_accuracy: 0.5340\n",
            "\n",
            "Epoch 00198: val_loss improved from 1.05283 to 1.05260, saving model to ./model0/1.0526-0.5340-198.hdf5\n",
            "Epoch 199/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0479 - accuracy: 0.5388 - val_loss: 1.0691 - val_accuracy: 0.5359\n",
            "\n",
            "Epoch 00199: val_loss did not improve from 1.05260\n",
            "Epoch 200/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0861 - accuracy: 0.5263 - val_loss: 1.0535 - val_accuracy: 0.5359\n",
            "\n",
            "Epoch 00200: val_loss did not improve from 1.05260\n",
            "Epoch 201/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0726 - accuracy: 0.5252 - val_loss: 1.0794 - val_accuracy: 0.5256\n",
            "\n",
            "Epoch 00201: val_loss did not improve from 1.05260\n",
            "Epoch 202/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0561 - accuracy: 0.5475 - val_loss: 1.0607 - val_accuracy: 0.5353\n",
            "\n",
            "Epoch 00202: val_loss did not improve from 1.05260\n",
            "Epoch 203/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0649 - accuracy: 0.5450 - val_loss: 1.0519 - val_accuracy: 0.5346\n",
            "\n",
            "Epoch 00203: val_loss improved from 1.05260 to 1.05190, saving model to ./model0/1.0519-0.5346-203.hdf5\n",
            "Epoch 204/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0721 - accuracy: 0.5408 - val_loss: 1.0533 - val_accuracy: 0.5423\n",
            "\n",
            "Epoch 00204: val_loss did not improve from 1.05190\n",
            "Epoch 205/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0588 - accuracy: 0.5380 - val_loss: 1.0706 - val_accuracy: 0.5282\n",
            "\n",
            "Epoch 00205: val_loss did not improve from 1.05190\n",
            "Epoch 206/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0450 - accuracy: 0.5463 - val_loss: 1.0638 - val_accuracy: 0.5372\n",
            "\n",
            "Epoch 00206: val_loss did not improve from 1.05190\n",
            "Epoch 207/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1.0697 - accuracy: 0.5378 - val_loss: 1.0645 - val_accuracy: 0.5410\n",
            "\n",
            "Epoch 00207: val_loss did not improve from 1.05190\n",
            "Epoch 208/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0680 - accuracy: 0.5389 - val_loss: 1.0556 - val_accuracy: 0.5353\n",
            "\n",
            "Epoch 00208: val_loss did not improve from 1.05190\n",
            "Epoch 209/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0620 - accuracy: 0.5394 - val_loss: 1.0606 - val_accuracy: 0.5391\n",
            "\n",
            "Epoch 00209: val_loss did not improve from 1.05190\n",
            "Epoch 210/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0678 - accuracy: 0.5412 - val_loss: 1.0765 - val_accuracy: 0.5295\n",
            "\n",
            "Epoch 00210: val_loss did not improve from 1.05190\n",
            "Epoch 211/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.1066 - accuracy: 0.5236 - val_loss: 1.0584 - val_accuracy: 0.5295\n",
            "\n",
            "Epoch 00211: val_loss did not improve from 1.05190\n",
            "Epoch 212/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0578 - accuracy: 0.5411 - val_loss: 1.0672 - val_accuracy: 0.5282\n",
            "\n",
            "Epoch 00212: val_loss did not improve from 1.05190\n",
            "Epoch 213/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0390 - accuracy: 0.5611 - val_loss: 1.0579 - val_accuracy: 0.5436\n",
            "\n",
            "Epoch 00213: val_loss did not improve from 1.05190\n",
            "Epoch 214/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0594 - accuracy: 0.5442 - val_loss: 1.0543 - val_accuracy: 0.5359\n",
            "\n",
            "Epoch 00214: val_loss did not improve from 1.05190\n",
            "Epoch 215/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0483 - accuracy: 0.5428 - val_loss: 1.0504 - val_accuracy: 0.5423\n",
            "\n",
            "Epoch 00215: val_loss improved from 1.05190 to 1.05041, saving model to ./model0/1.0504-0.5423-215.hdf5\n",
            "Epoch 216/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0745 - accuracy: 0.5226 - val_loss: 1.0528 - val_accuracy: 0.5397\n",
            "\n",
            "Epoch 00216: val_loss did not improve from 1.05041\n",
            "Epoch 217/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0521 - accuracy: 0.5552 - val_loss: 1.0803 - val_accuracy: 0.5244\n",
            "\n",
            "Epoch 00217: val_loss did not improve from 1.05041\n",
            "Epoch 218/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0519 - accuracy: 0.5474 - val_loss: 1.0574 - val_accuracy: 0.5359\n",
            "\n",
            "Epoch 00218: val_loss did not improve from 1.05041\n",
            "Epoch 219/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0828 - accuracy: 0.5297 - val_loss: 1.0604 - val_accuracy: 0.5378\n",
            "\n",
            "Epoch 00219: val_loss did not improve from 1.05041\n",
            "Epoch 220/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0899 - accuracy: 0.5273 - val_loss: 1.0549 - val_accuracy: 0.5365\n",
            "\n",
            "Epoch 00220: val_loss did not improve from 1.05041\n",
            "Epoch 221/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0536 - accuracy: 0.5518 - val_loss: 1.0609 - val_accuracy: 0.5359\n",
            "\n",
            "Epoch 00221: val_loss did not improve from 1.05041\n",
            "Epoch 222/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0699 - accuracy: 0.5419 - val_loss: 1.0777 - val_accuracy: 0.5269\n",
            "\n",
            "Epoch 00222: val_loss did not improve from 1.05041\n",
            "Epoch 223/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0747 - accuracy: 0.5295 - val_loss: 1.0917 - val_accuracy: 0.5199\n",
            "\n",
            "Epoch 00223: val_loss did not improve from 1.05041\n",
            "Epoch 224/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0872 - accuracy: 0.5223 - val_loss: 1.0634 - val_accuracy: 0.5346\n",
            "\n",
            "Epoch 00224: val_loss did not improve from 1.05041\n",
            "Epoch 225/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0708 - accuracy: 0.5331 - val_loss: 1.0683 - val_accuracy: 0.5321\n",
            "\n",
            "Epoch 00225: val_loss did not improve from 1.05041\n",
            "Epoch 226/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0782 - accuracy: 0.5409 - val_loss: 1.0539 - val_accuracy: 0.5474\n",
            "\n",
            "Epoch 00226: val_loss did not improve from 1.05041\n",
            "Epoch 227/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0636 - accuracy: 0.5448 - val_loss: 1.0525 - val_accuracy: 0.5442\n",
            "\n",
            "Epoch 00227: val_loss did not improve from 1.05041\n",
            "Epoch 228/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0645 - accuracy: 0.5376 - val_loss: 1.0939 - val_accuracy: 0.5147\n",
            "\n",
            "Epoch 00228: val_loss did not improve from 1.05041\n",
            "Epoch 229/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0807 - accuracy: 0.5195 - val_loss: 1.0982 - val_accuracy: 0.5276\n",
            "\n",
            "Epoch 00229: val_loss did not improve from 1.05041\n",
            "Epoch 230/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0761 - accuracy: 0.5414 - val_loss: 1.0670 - val_accuracy: 0.5276\n",
            "\n",
            "Epoch 00230: val_loss did not improve from 1.05041\n",
            "Epoch 231/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0433 - accuracy: 0.5384 - val_loss: 1.0543 - val_accuracy: 0.5455\n",
            "\n",
            "Epoch 00231: val_loss did not improve from 1.05041\n",
            "Epoch 232/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0473 - accuracy: 0.5457 - val_loss: 1.0646 - val_accuracy: 0.5372\n",
            "\n",
            "Epoch 00232: val_loss did not improve from 1.05041\n",
            "Epoch 233/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0580 - accuracy: 0.5415 - val_loss: 1.0534 - val_accuracy: 0.5378\n",
            "\n",
            "Epoch 00233: val_loss did not improve from 1.05041\n",
            "Epoch 234/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0523 - accuracy: 0.5557 - val_loss: 1.0583 - val_accuracy: 0.5359\n",
            "\n",
            "Epoch 00234: val_loss did not improve from 1.05041\n",
            "Epoch 235/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0616 - accuracy: 0.5401 - val_loss: 1.0574 - val_accuracy: 0.5481\n",
            "\n",
            "Epoch 00235: val_loss did not improve from 1.05041\n",
            "Epoch 236/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0771 - accuracy: 0.5328 - val_loss: 1.0605 - val_accuracy: 0.5385\n",
            "\n",
            "Epoch 00236: val_loss did not improve from 1.05041\n",
            "Epoch 237/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0486 - accuracy: 0.5413 - val_loss: 1.0577 - val_accuracy: 0.5365\n",
            "\n",
            "Epoch 00237: val_loss did not improve from 1.05041\n",
            "Epoch 238/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0629 - accuracy: 0.5453 - val_loss: 1.0573 - val_accuracy: 0.5417\n",
            "\n",
            "Epoch 00238: val_loss did not improve from 1.05041\n",
            "Epoch 239/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0495 - accuracy: 0.5502 - val_loss: 1.0574 - val_accuracy: 0.5301\n",
            "\n",
            "Epoch 00239: val_loss did not improve from 1.05041\n",
            "Epoch 240/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0516 - accuracy: 0.5377 - val_loss: 1.0465 - val_accuracy: 0.5436\n",
            "\n",
            "Epoch 00240: val_loss improved from 1.05041 to 1.04654, saving model to ./model0/1.0465-0.5436-240.hdf5\n",
            "Epoch 241/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0595 - accuracy: 0.5472 - val_loss: 1.0589 - val_accuracy: 0.5359\n",
            "\n",
            "Epoch 00241: val_loss did not improve from 1.04654\n",
            "Epoch 242/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0654 - accuracy: 0.5448 - val_loss: 1.0578 - val_accuracy: 0.5468\n",
            "\n",
            "Epoch 00242: val_loss did not improve from 1.04654\n",
            "Epoch 243/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0504 - accuracy: 0.5436 - val_loss: 1.0583 - val_accuracy: 0.5436\n",
            "\n",
            "Epoch 00243: val_loss did not improve from 1.04654\n",
            "Epoch 244/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0535 - accuracy: 0.5522 - val_loss: 1.0491 - val_accuracy: 0.5385\n",
            "\n",
            "Epoch 00244: val_loss did not improve from 1.04654\n",
            "Epoch 245/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0853 - accuracy: 0.5191 - val_loss: 1.0783 - val_accuracy: 0.5244\n",
            "\n",
            "Epoch 00245: val_loss did not improve from 1.04654\n",
            "Epoch 246/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0723 - accuracy: 0.5370 - val_loss: 1.0497 - val_accuracy: 0.5397\n",
            "\n",
            "Epoch 00246: val_loss did not improve from 1.04654\n",
            "Epoch 247/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0379 - accuracy: 0.5442 - val_loss: 1.0595 - val_accuracy: 0.5429\n",
            "\n",
            "Epoch 00247: val_loss did not improve from 1.04654\n",
            "Epoch 248/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0627 - accuracy: 0.5390 - val_loss: 1.0519 - val_accuracy: 0.5346\n",
            "\n",
            "Epoch 00248: val_loss did not improve from 1.04654\n",
            "Epoch 249/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0365 - accuracy: 0.5535 - val_loss: 1.0669 - val_accuracy: 0.5282\n",
            "\n",
            "Epoch 00249: val_loss did not improve from 1.04654\n",
            "Epoch 250/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0613 - accuracy: 0.5429 - val_loss: 1.0584 - val_accuracy: 0.5404\n",
            "\n",
            "Epoch 00250: val_loss did not improve from 1.04654\n",
            "Epoch 251/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0613 - accuracy: 0.5364 - val_loss: 1.1470 - val_accuracy: 0.4936\n",
            "\n",
            "Epoch 00251: val_loss did not improve from 1.04654\n",
            "Epoch 252/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0611 - accuracy: 0.5348 - val_loss: 1.0635 - val_accuracy: 0.5301\n",
            "\n",
            "Epoch 00252: val_loss did not improve from 1.04654\n",
            "Epoch 253/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0580 - accuracy: 0.5411 - val_loss: 1.0691 - val_accuracy: 0.5263\n",
            "\n",
            "Epoch 00253: val_loss did not improve from 1.04654\n",
            "Epoch 254/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0677 - accuracy: 0.5298 - val_loss: 1.1005 - val_accuracy: 0.5096\n",
            "\n",
            "Epoch 00254: val_loss did not improve from 1.04654\n",
            "Epoch 255/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0887 - accuracy: 0.5135 - val_loss: 1.0541 - val_accuracy: 0.5327\n",
            "\n",
            "Epoch 00255: val_loss did not improve from 1.04654\n",
            "Epoch 256/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0576 - accuracy: 0.5398 - val_loss: 1.0510 - val_accuracy: 0.5417\n",
            "\n",
            "Epoch 00256: val_loss did not improve from 1.04654\n",
            "Epoch 257/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0366 - accuracy: 0.5454 - val_loss: 1.0505 - val_accuracy: 0.5449\n",
            "\n",
            "Epoch 00257: val_loss did not improve from 1.04654\n",
            "Epoch 258/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0922 - accuracy: 0.5308 - val_loss: 1.0492 - val_accuracy: 0.5404\n",
            "\n",
            "Epoch 00258: val_loss did not improve from 1.04654\n",
            "Epoch 259/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0660 - accuracy: 0.5368 - val_loss: 1.0638 - val_accuracy: 0.5308\n",
            "\n",
            "Epoch 00259: val_loss did not improve from 1.04654\n",
            "Epoch 260/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0725 - accuracy: 0.5418 - val_loss: 1.0537 - val_accuracy: 0.5410\n",
            "\n",
            "Epoch 00260: val_loss did not improve from 1.04654\n",
            "Epoch 261/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0470 - accuracy: 0.5474 - val_loss: 1.0579 - val_accuracy: 0.5321\n",
            "\n",
            "Epoch 00261: val_loss did not improve from 1.04654\n",
            "Epoch 262/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0432 - accuracy: 0.5584 - val_loss: 1.0687 - val_accuracy: 0.5378\n",
            "\n",
            "Epoch 00262: val_loss did not improve from 1.04654\n",
            "Epoch 263/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0510 - accuracy: 0.5505 - val_loss: 1.0531 - val_accuracy: 0.5397\n",
            "\n",
            "Epoch 00263: val_loss did not improve from 1.04654\n",
            "Epoch 264/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0468 - accuracy: 0.5537 - val_loss: 1.0563 - val_accuracy: 0.5327\n",
            "\n",
            "Epoch 00264: val_loss did not improve from 1.04654\n",
            "Epoch 265/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0762 - accuracy: 0.5234 - val_loss: 1.0510 - val_accuracy: 0.5474\n",
            "\n",
            "Epoch 00265: val_loss did not improve from 1.04654\n",
            "Epoch 266/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0484 - accuracy: 0.5467 - val_loss: 1.0969 - val_accuracy: 0.5173\n",
            "\n",
            "Epoch 00266: val_loss did not improve from 1.04654\n",
            "Epoch 267/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0465 - accuracy: 0.5501 - val_loss: 1.0595 - val_accuracy: 0.5263\n",
            "\n",
            "Epoch 00267: val_loss did not improve from 1.04654\n",
            "Epoch 268/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0450 - accuracy: 0.5602 - val_loss: 1.0706 - val_accuracy: 0.5237\n",
            "\n",
            "Epoch 00268: val_loss did not improve from 1.04654\n",
            "Epoch 269/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0568 - accuracy: 0.5358 - val_loss: 1.0551 - val_accuracy: 0.5365\n",
            "\n",
            "Epoch 00269: val_loss did not improve from 1.04654\n",
            "Epoch 270/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0513 - accuracy: 0.5484 - val_loss: 1.0732 - val_accuracy: 0.5333\n",
            "\n",
            "Epoch 00270: val_loss did not improve from 1.04654\n",
            "Epoch 271/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0811 - accuracy: 0.5314 - val_loss: 1.0705 - val_accuracy: 0.5359\n",
            "\n",
            "Epoch 00271: val_loss did not improve from 1.04654\n",
            "Epoch 272/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1.0525 - accuracy: 0.5438 - val_loss: 1.0512 - val_accuracy: 0.5353\n",
            "\n",
            "Epoch 00272: val_loss did not improve from 1.04654\n",
            "Epoch 273/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0475 - accuracy: 0.5412 - val_loss: 1.0533 - val_accuracy: 0.5410\n",
            "\n",
            "Epoch 00273: val_loss did not improve from 1.04654\n",
            "Epoch 274/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0338 - accuracy: 0.5544 - val_loss: 1.0621 - val_accuracy: 0.5340\n",
            "\n",
            "Epoch 00274: val_loss did not improve from 1.04654\n",
            "Epoch 275/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0508 - accuracy: 0.5278 - val_loss: 1.0655 - val_accuracy: 0.5301\n",
            "\n",
            "Epoch 00275: val_loss did not improve from 1.04654\n",
            "Epoch 276/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0664 - accuracy: 0.5405 - val_loss: 1.0484 - val_accuracy: 0.5423\n",
            "\n",
            "Epoch 00276: val_loss did not improve from 1.04654\n",
            "Epoch 277/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0368 - accuracy: 0.5544 - val_loss: 1.0540 - val_accuracy: 0.5404\n",
            "\n",
            "Epoch 00277: val_loss did not improve from 1.04654\n",
            "Epoch 278/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0544 - accuracy: 0.5379 - val_loss: 1.0580 - val_accuracy: 0.5372\n",
            "\n",
            "Epoch 00278: val_loss did not improve from 1.04654\n",
            "Epoch 279/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0520 - accuracy: 0.5542 - val_loss: 1.0434 - val_accuracy: 0.5372\n",
            "\n",
            "Epoch 00279: val_loss improved from 1.04654 to 1.04342, saving model to ./model0/1.0434-0.5372-279.hdf5\n",
            "Epoch 280/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0483 - accuracy: 0.5463 - val_loss: 1.0565 - val_accuracy: 0.5353\n",
            "\n",
            "Epoch 00280: val_loss did not improve from 1.04342\n",
            "Epoch 281/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0316 - accuracy: 0.5471 - val_loss: 1.0515 - val_accuracy: 0.5404\n",
            "\n",
            "Epoch 00281: val_loss did not improve from 1.04342\n",
            "Epoch 282/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0636 - accuracy: 0.5360 - val_loss: 1.0528 - val_accuracy: 0.5397\n",
            "\n",
            "Epoch 00282: val_loss did not improve from 1.04342\n",
            "Epoch 283/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0430 - accuracy: 0.5365 - val_loss: 1.0569 - val_accuracy: 0.5314\n",
            "\n",
            "Epoch 00283: val_loss did not improve from 1.04342\n",
            "Epoch 284/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1.0307 - accuracy: 0.5587 - val_loss: 1.0598 - val_accuracy: 0.5391\n",
            "\n",
            "Epoch 00284: val_loss did not improve from 1.04342\n",
            "Epoch 285/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0476 - accuracy: 0.5457 - val_loss: 1.1334 - val_accuracy: 0.4865\n",
            "\n",
            "Epoch 00285: val_loss did not improve from 1.04342\n",
            "Epoch 286/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0765 - accuracy: 0.5342 - val_loss: 1.0561 - val_accuracy: 0.5481\n",
            "\n",
            "Epoch 00286: val_loss did not improve from 1.04342\n",
            "Epoch 287/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0817 - accuracy: 0.5317 - val_loss: 1.0611 - val_accuracy: 0.5365\n",
            "\n",
            "Epoch 00287: val_loss did not improve from 1.04342\n",
            "Epoch 288/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0572 - accuracy: 0.5466 - val_loss: 1.0539 - val_accuracy: 0.5385\n",
            "\n",
            "Epoch 00288: val_loss did not improve from 1.04342\n",
            "Epoch 289/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0487 - accuracy: 0.5410 - val_loss: 1.0625 - val_accuracy: 0.5397\n",
            "\n",
            "Epoch 00289: val_loss did not improve from 1.04342\n",
            "Epoch 290/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0333 - accuracy: 0.5536 - val_loss: 1.0722 - val_accuracy: 0.5410\n",
            "\n",
            "Epoch 00290: val_loss did not improve from 1.04342\n",
            "Epoch 291/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0504 - accuracy: 0.5422 - val_loss: 1.0515 - val_accuracy: 0.5442\n",
            "\n",
            "Epoch 00291: val_loss did not improve from 1.04342\n",
            "Epoch 292/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0601 - accuracy: 0.5258 - val_loss: 1.0521 - val_accuracy: 0.5468\n",
            "\n",
            "Epoch 00292: val_loss did not improve from 1.04342\n",
            "Epoch 293/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0336 - accuracy: 0.5508 - val_loss: 1.0502 - val_accuracy: 0.5468\n",
            "\n",
            "Epoch 00293: val_loss did not improve from 1.04342\n",
            "Epoch 294/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0282 - accuracy: 0.5603 - val_loss: 1.0533 - val_accuracy: 0.5481\n",
            "\n",
            "Epoch 00294: val_loss did not improve from 1.04342\n",
            "Epoch 295/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0440 - accuracy: 0.5553 - val_loss: 1.0543 - val_accuracy: 0.5359\n",
            "\n",
            "Epoch 00295: val_loss did not improve from 1.04342\n",
            "Epoch 296/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0527 - accuracy: 0.5463 - val_loss: 1.0609 - val_accuracy: 0.5494\n",
            "\n",
            "Epoch 00296: val_loss did not improve from 1.04342\n",
            "Epoch 297/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0455 - accuracy: 0.5596 - val_loss: 1.0521 - val_accuracy: 0.5417\n",
            "\n",
            "Epoch 00297: val_loss did not improve from 1.04342\n",
            "Epoch 298/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0437 - accuracy: 0.5573 - val_loss: 1.0634 - val_accuracy: 0.5288\n",
            "\n",
            "Epoch 00298: val_loss did not improve from 1.04342\n",
            "Epoch 299/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0398 - accuracy: 0.5553 - val_loss: 1.0592 - val_accuracy: 0.5397\n",
            "\n",
            "Epoch 00299: val_loss did not improve from 1.04342\n",
            "Epoch 300/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0202 - accuracy: 0.5629 - val_loss: 1.0697 - val_accuracy: 0.5385\n",
            "\n",
            "Epoch 00300: val_loss did not improve from 1.04342\n",
            "Epoch 301/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0668 - accuracy: 0.5380 - val_loss: 1.0687 - val_accuracy: 0.5321\n",
            "\n",
            "Epoch 00301: val_loss did not improve from 1.04342\n",
            "Epoch 302/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0413 - accuracy: 0.5506 - val_loss: 1.0645 - val_accuracy: 0.5295\n",
            "\n",
            "Epoch 00302: val_loss did not improve from 1.04342\n",
            "Epoch 303/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0780 - accuracy: 0.5373 - val_loss: 1.0548 - val_accuracy: 0.5346\n",
            "\n",
            "Epoch 00303: val_loss did not improve from 1.04342\n",
            "Epoch 304/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0172 - accuracy: 0.5639 - val_loss: 1.0618 - val_accuracy: 0.5365\n",
            "\n",
            "Epoch 00304: val_loss did not improve from 1.04342\n",
            "Epoch 305/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0634 - accuracy: 0.5411 - val_loss: 1.0698 - val_accuracy: 0.5333\n",
            "\n",
            "Epoch 00305: val_loss did not improve from 1.04342\n",
            "Epoch 306/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0421 - accuracy: 0.5481 - val_loss: 1.0519 - val_accuracy: 0.5404\n",
            "\n",
            "Epoch 00306: val_loss did not improve from 1.04342\n",
            "Epoch 307/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0501 - accuracy: 0.5463 - val_loss: 1.0475 - val_accuracy: 0.5423\n",
            "\n",
            "Epoch 00307: val_loss did not improve from 1.04342\n",
            "Epoch 308/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0463 - accuracy: 0.5493 - val_loss: 1.0523 - val_accuracy: 0.5449\n",
            "\n",
            "Epoch 00308: val_loss did not improve from 1.04342\n",
            "Epoch 309/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0552 - accuracy: 0.5408 - val_loss: 1.1012 - val_accuracy: 0.5115\n",
            "\n",
            "Epoch 00309: val_loss did not improve from 1.04342\n",
            "Epoch 310/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0657 - accuracy: 0.5385 - val_loss: 1.0783 - val_accuracy: 0.5263\n",
            "\n",
            "Epoch 00310: val_loss did not improve from 1.04342\n",
            "Epoch 311/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0419 - accuracy: 0.5390 - val_loss: 1.0634 - val_accuracy: 0.5372\n",
            "\n",
            "Epoch 00311: val_loss did not improve from 1.04342\n",
            "Epoch 312/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0307 - accuracy: 0.5383 - val_loss: 1.0542 - val_accuracy: 0.5436\n",
            "\n",
            "Epoch 00312: val_loss did not improve from 1.04342\n",
            "Epoch 313/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0518 - accuracy: 0.5384 - val_loss: 1.0564 - val_accuracy: 0.5436\n",
            "\n",
            "Epoch 00313: val_loss did not improve from 1.04342\n",
            "Epoch 314/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0524 - accuracy: 0.5373 - val_loss: 1.0662 - val_accuracy: 0.5346\n",
            "\n",
            "Epoch 00314: val_loss did not improve from 1.04342\n",
            "Epoch 315/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0522 - accuracy: 0.5446 - val_loss: 1.0634 - val_accuracy: 0.5295\n",
            "\n",
            "Epoch 00315: val_loss did not improve from 1.04342\n",
            "Epoch 316/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0326 - accuracy: 0.5402 - val_loss: 1.0628 - val_accuracy: 0.5365\n",
            "\n",
            "Epoch 00316: val_loss did not improve from 1.04342\n",
            "Epoch 317/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0347 - accuracy: 0.5488 - val_loss: 1.0597 - val_accuracy: 0.5372\n",
            "\n",
            "Epoch 00317: val_loss did not improve from 1.04342\n",
            "Epoch 318/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0332 - accuracy: 0.5400 - val_loss: 1.0513 - val_accuracy: 0.5481\n",
            "\n",
            "Epoch 00318: val_loss did not improve from 1.04342\n",
            "Epoch 319/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0348 - accuracy: 0.5455 - val_loss: 1.0684 - val_accuracy: 0.5308\n",
            "\n",
            "Epoch 00319: val_loss did not improve from 1.04342\n",
            "Epoch 320/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0603 - accuracy: 0.5506 - val_loss: 1.0699 - val_accuracy: 0.5327\n",
            "\n",
            "Epoch 00320: val_loss did not improve from 1.04342\n",
            "Epoch 321/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0479 - accuracy: 0.5426 - val_loss: 1.0626 - val_accuracy: 0.5321\n",
            "\n",
            "Epoch 00321: val_loss did not improve from 1.04342\n",
            "Epoch 322/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0501 - accuracy: 0.5382 - val_loss: 1.0559 - val_accuracy: 0.5340\n",
            "\n",
            "Epoch 00322: val_loss did not improve from 1.04342\n",
            "Epoch 323/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0415 - accuracy: 0.5445 - val_loss: 1.0524 - val_accuracy: 0.5423\n",
            "\n",
            "Epoch 00323: val_loss did not improve from 1.04342\n",
            "Epoch 324/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0429 - accuracy: 0.5403 - val_loss: 1.0508 - val_accuracy: 0.5455\n",
            "\n",
            "Epoch 00324: val_loss did not improve from 1.04342\n",
            "Epoch 325/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0199 - accuracy: 0.5523 - val_loss: 1.0670 - val_accuracy: 0.5314\n",
            "\n",
            "Epoch 00325: val_loss did not improve from 1.04342\n",
            "Epoch 326/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0441 - accuracy: 0.5520 - val_loss: 1.0503 - val_accuracy: 0.5397\n",
            "\n",
            "Epoch 00326: val_loss did not improve from 1.04342\n",
            "Epoch 327/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0366 - accuracy: 0.5638 - val_loss: 1.0483 - val_accuracy: 0.5417\n",
            "\n",
            "Epoch 00327: val_loss did not improve from 1.04342\n",
            "Epoch 328/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0362 - accuracy: 0.5540 - val_loss: 1.0524 - val_accuracy: 0.5423\n",
            "\n",
            "Epoch 00328: val_loss did not improve from 1.04342\n",
            "Epoch 329/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0356 - accuracy: 0.5484 - val_loss: 1.0755 - val_accuracy: 0.5244\n",
            "\n",
            "Epoch 00329: val_loss did not improve from 1.04342\n",
            "Epoch 330/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0346 - accuracy: 0.5578 - val_loss: 1.0560 - val_accuracy: 0.5410\n",
            "\n",
            "Epoch 00330: val_loss did not improve from 1.04342\n",
            "Epoch 331/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0633 - accuracy: 0.5397 - val_loss: 1.0625 - val_accuracy: 0.5346\n",
            "\n",
            "Epoch 00331: val_loss did not improve from 1.04342\n",
            "Epoch 332/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0370 - accuracy: 0.5408 - val_loss: 1.0612 - val_accuracy: 0.5462\n",
            "\n",
            "Epoch 00332: val_loss did not improve from 1.04342\n",
            "Epoch 333/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0250 - accuracy: 0.5633 - val_loss: 1.0529 - val_accuracy: 0.5372\n",
            "\n",
            "Epoch 00333: val_loss did not improve from 1.04342\n",
            "Epoch 334/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0484 - accuracy: 0.5450 - val_loss: 1.0693 - val_accuracy: 0.5404\n",
            "\n",
            "Epoch 00334: val_loss did not improve from 1.04342\n",
            "Epoch 335/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0348 - accuracy: 0.5609 - val_loss: 1.0610 - val_accuracy: 0.5327\n",
            "\n",
            "Epoch 00335: val_loss did not improve from 1.04342\n",
            "Epoch 336/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0432 - accuracy: 0.5596 - val_loss: 1.0725 - val_accuracy: 0.5372\n",
            "\n",
            "Epoch 00336: val_loss did not improve from 1.04342\n",
            "Epoch 337/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0276 - accuracy: 0.5547 - val_loss: 1.0584 - val_accuracy: 0.5404\n",
            "\n",
            "Epoch 00337: val_loss did not improve from 1.04342\n",
            "Epoch 338/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0538 - accuracy: 0.5421 - val_loss: 1.0685 - val_accuracy: 0.5327\n",
            "\n",
            "Epoch 00338: val_loss did not improve from 1.04342\n",
            "Epoch 339/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0310 - accuracy: 0.5468 - val_loss: 1.0640 - val_accuracy: 0.5372\n",
            "\n",
            "Epoch 00339: val_loss did not improve from 1.04342\n",
            "Epoch 340/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0111 - accuracy: 0.5494 - val_loss: 1.0642 - val_accuracy: 0.5346\n",
            "\n",
            "Epoch 00340: val_loss did not improve from 1.04342\n",
            "Epoch 341/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0277 - accuracy: 0.5641 - val_loss: 1.0759 - val_accuracy: 0.5224\n",
            "\n",
            "Epoch 00341: val_loss did not improve from 1.04342\n",
            "Epoch 342/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0560 - accuracy: 0.5355 - val_loss: 1.0613 - val_accuracy: 0.5404\n",
            "\n",
            "Epoch 00342: val_loss did not improve from 1.04342\n",
            "Epoch 343/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0467 - accuracy: 0.5421 - val_loss: 1.0604 - val_accuracy: 0.5410\n",
            "\n",
            "Epoch 00343: val_loss did not improve from 1.04342\n",
            "Epoch 344/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0232 - accuracy: 0.5695 - val_loss: 1.0553 - val_accuracy: 0.5391\n",
            "\n",
            "Epoch 00344: val_loss did not improve from 1.04342\n",
            "Epoch 345/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0305 - accuracy: 0.5529 - val_loss: 1.0889 - val_accuracy: 0.5179\n",
            "\n",
            "Epoch 00345: val_loss did not improve from 1.04342\n",
            "Epoch 346/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0463 - accuracy: 0.5321 - val_loss: 1.0711 - val_accuracy: 0.5288\n",
            "\n",
            "Epoch 00346: val_loss did not improve from 1.04342\n",
            "Epoch 347/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0283 - accuracy: 0.5681 - val_loss: 1.0545 - val_accuracy: 0.5455\n",
            "\n",
            "Epoch 00347: val_loss did not improve from 1.04342\n",
            "Epoch 348/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0289 - accuracy: 0.5563 - val_loss: 1.0642 - val_accuracy: 0.5327\n",
            "\n",
            "Epoch 00348: val_loss did not improve from 1.04342\n",
            "Epoch 349/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0469 - accuracy: 0.5570 - val_loss: 1.0906 - val_accuracy: 0.5231\n",
            "\n",
            "Epoch 00349: val_loss did not improve from 1.04342\n",
            "Epoch 350/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0483 - accuracy: 0.5481 - val_loss: 1.0763 - val_accuracy: 0.5295\n",
            "\n",
            "Epoch 00350: val_loss did not improve from 1.04342\n",
            "Epoch 351/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0472 - accuracy: 0.5416 - val_loss: 1.0746 - val_accuracy: 0.5250\n",
            "\n",
            "Epoch 00351: val_loss did not improve from 1.04342\n",
            "Epoch 352/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0186 - accuracy: 0.5679 - val_loss: 1.0784 - val_accuracy: 0.5340\n",
            "\n",
            "Epoch 00352: val_loss did not improve from 1.04342\n",
            "Epoch 353/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0489 - accuracy: 0.5462 - val_loss: 1.0570 - val_accuracy: 0.5321\n",
            "\n",
            "Epoch 00353: val_loss did not improve from 1.04342\n",
            "Epoch 354/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0424 - accuracy: 0.5539 - val_loss: 1.0728 - val_accuracy: 0.5314\n",
            "\n",
            "Epoch 00354: val_loss did not improve from 1.04342\n",
            "Epoch 355/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0422 - accuracy: 0.5428 - val_loss: 1.0629 - val_accuracy: 0.5442\n",
            "\n",
            "Epoch 00355: val_loss did not improve from 1.04342\n",
            "Epoch 356/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0473 - accuracy: 0.5461 - val_loss: 1.0529 - val_accuracy: 0.5462\n",
            "\n",
            "Epoch 00356: val_loss did not improve from 1.04342\n",
            "Epoch 357/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0387 - accuracy: 0.5474 - val_loss: 1.0751 - val_accuracy: 0.5468\n",
            "\n",
            "Epoch 00357: val_loss did not improve from 1.04342\n",
            "Epoch 358/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0373 - accuracy: 0.5457 - val_loss: 1.0581 - val_accuracy: 0.5442\n",
            "\n",
            "Epoch 00358: val_loss did not improve from 1.04342\n",
            "Epoch 359/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0230 - accuracy: 0.5601 - val_loss: 1.0716 - val_accuracy: 0.5218\n",
            "\n",
            "Epoch 00359: val_loss did not improve from 1.04342\n",
            "Epoch 360/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0301 - accuracy: 0.5613 - val_loss: 1.0681 - val_accuracy: 0.5301\n",
            "\n",
            "Epoch 00360: val_loss did not improve from 1.04342\n",
            "Epoch 361/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0393 - accuracy: 0.5459 - val_loss: 1.0562 - val_accuracy: 0.5436\n",
            "\n",
            "Epoch 00361: val_loss did not improve from 1.04342\n",
            "Epoch 362/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0303 - accuracy: 0.5639 - val_loss: 1.0560 - val_accuracy: 0.5468\n",
            "\n",
            "Epoch 00362: val_loss did not improve from 1.04342\n",
            "Epoch 363/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0668 - accuracy: 0.5541 - val_loss: 1.0511 - val_accuracy: 0.5494\n",
            "\n",
            "Epoch 00363: val_loss did not improve from 1.04342\n",
            "Epoch 364/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0518 - accuracy: 0.5544 - val_loss: 1.0562 - val_accuracy: 0.5417\n",
            "\n",
            "Epoch 00364: val_loss did not improve from 1.04342\n",
            "Epoch 365/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0367 - accuracy: 0.5538 - val_loss: 1.0669 - val_accuracy: 0.5340\n",
            "\n",
            "Epoch 00365: val_loss did not improve from 1.04342\n",
            "Epoch 366/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1.0560 - accuracy: 0.5430 - val_loss: 1.0574 - val_accuracy: 0.5417\n",
            "\n",
            "Epoch 00366: val_loss did not improve from 1.04342\n",
            "Epoch 367/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0370 - accuracy: 0.5576 - val_loss: 1.0606 - val_accuracy: 0.5378\n",
            "\n",
            "Epoch 00367: val_loss did not improve from 1.04342\n",
            "Epoch 368/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0178 - accuracy: 0.5604 - val_loss: 1.0897 - val_accuracy: 0.5256\n",
            "\n",
            "Epoch 00368: val_loss did not improve from 1.04342\n",
            "Epoch 369/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0557 - accuracy: 0.5337 - val_loss: 1.0640 - val_accuracy: 0.5410\n",
            "\n",
            "Epoch 00369: val_loss did not improve from 1.04342\n",
            "Epoch 370/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0244 - accuracy: 0.5494 - val_loss: 1.0551 - val_accuracy: 0.5321\n",
            "\n",
            "Epoch 00370: val_loss did not improve from 1.04342\n",
            "Epoch 371/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0480 - accuracy: 0.5390 - val_loss: 1.0689 - val_accuracy: 0.5327\n",
            "\n",
            "Epoch 00371: val_loss did not improve from 1.04342\n",
            "Epoch 372/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0248 - accuracy: 0.5495 - val_loss: 1.0762 - val_accuracy: 0.5269\n",
            "\n",
            "Epoch 00372: val_loss did not improve from 1.04342\n",
            "Epoch 373/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0392 - accuracy: 0.5501 - val_loss: 1.0648 - val_accuracy: 0.5321\n",
            "\n",
            "Epoch 00373: val_loss did not improve from 1.04342\n",
            "Epoch 374/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0570 - accuracy: 0.5476 - val_loss: 1.0652 - val_accuracy: 0.5404\n",
            "\n",
            "Epoch 00374: val_loss did not improve from 1.04342\n",
            "Epoch 375/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0222 - accuracy: 0.5479 - val_loss: 1.0691 - val_accuracy: 0.5385\n",
            "\n",
            "Epoch 00375: val_loss did not improve from 1.04342\n",
            "Epoch 376/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0445 - accuracy: 0.5480 - val_loss: 1.0711 - val_accuracy: 0.5314\n",
            "\n",
            "Epoch 00376: val_loss did not improve from 1.04342\n",
            "Epoch 377/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0443 - accuracy: 0.5507 - val_loss: 1.0643 - val_accuracy: 0.5474\n",
            "\n",
            "Epoch 00377: val_loss did not improve from 1.04342\n",
            "Epoch 378/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0253 - accuracy: 0.5572 - val_loss: 1.0785 - val_accuracy: 0.5269\n",
            "\n",
            "Epoch 00378: val_loss did not improve from 1.04342\n",
            "Epoch 379/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0359 - accuracy: 0.5439 - val_loss: 1.0613 - val_accuracy: 0.5449\n",
            "\n",
            "Epoch 00379: val_loss did not improve from 1.04342\n",
            "Epoch 380/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0323 - accuracy: 0.5582 - val_loss: 1.1082 - val_accuracy: 0.5026\n",
            "\n",
            "Epoch 00380: val_loss did not improve from 1.04342\n",
            "Epoch 381/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0185 - accuracy: 0.5532 - val_loss: 1.0729 - val_accuracy: 0.5372\n",
            "\n",
            "Epoch 00381: val_loss did not improve from 1.04342\n",
            "Epoch 382/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0504 - accuracy: 0.5383 - val_loss: 1.0661 - val_accuracy: 0.5333\n",
            "\n",
            "Epoch 00382: val_loss did not improve from 1.04342\n",
            "Epoch 383/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0300 - accuracy: 0.5614 - val_loss: 1.0615 - val_accuracy: 0.5455\n",
            "\n",
            "Epoch 00383: val_loss did not improve from 1.04342\n",
            "Epoch 384/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0454 - accuracy: 0.5439 - val_loss: 1.0636 - val_accuracy: 0.5429\n",
            "\n",
            "Epoch 00384: val_loss did not improve from 1.04342\n",
            "Epoch 385/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0361 - accuracy: 0.5561 - val_loss: 1.0718 - val_accuracy: 0.5314\n",
            "\n",
            "Epoch 00385: val_loss did not improve from 1.04342\n",
            "Epoch 386/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0402 - accuracy: 0.5360 - val_loss: 1.0675 - val_accuracy: 0.5314\n",
            "\n",
            "Epoch 00386: val_loss did not improve from 1.04342\n",
            "Epoch 387/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0498 - accuracy: 0.5507 - val_loss: 1.0598 - val_accuracy: 0.5474\n",
            "\n",
            "Epoch 00387: val_loss did not improve from 1.04342\n",
            "Epoch 388/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0341 - accuracy: 0.5586 - val_loss: 1.0711 - val_accuracy: 0.5391\n",
            "\n",
            "Epoch 00388: val_loss did not improve from 1.04342\n",
            "Epoch 389/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0150 - accuracy: 0.5656 - val_loss: 1.0615 - val_accuracy: 0.5353\n",
            "\n",
            "Epoch 00389: val_loss did not improve from 1.04342\n",
            "Epoch 390/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0320 - accuracy: 0.5437 - val_loss: 1.0772 - val_accuracy: 0.5321\n",
            "\n",
            "Epoch 00390: val_loss did not improve from 1.04342\n",
            "Epoch 391/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0304 - accuracy: 0.5456 - val_loss: 1.0937 - val_accuracy: 0.5160\n",
            "\n",
            "Epoch 00391: val_loss did not improve from 1.04342\n",
            "Epoch 392/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0432 - accuracy: 0.5394 - val_loss: 1.0703 - val_accuracy: 0.5321\n",
            "\n",
            "Epoch 00392: val_loss did not improve from 1.04342\n",
            "Epoch 393/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0375 - accuracy: 0.5547 - val_loss: 1.0670 - val_accuracy: 0.5314\n",
            "\n",
            "Epoch 00393: val_loss did not improve from 1.04342\n",
            "Epoch 394/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0201 - accuracy: 0.5529 - val_loss: 1.1032 - val_accuracy: 0.5141\n",
            "\n",
            "Epoch 00394: val_loss did not improve from 1.04342\n",
            "Epoch 395/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0536 - accuracy: 0.5326 - val_loss: 1.0989 - val_accuracy: 0.5321\n",
            "\n",
            "Epoch 00395: val_loss did not improve from 1.04342\n",
            "Epoch 396/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0431 - accuracy: 0.5544 - val_loss: 1.0608 - val_accuracy: 0.5391\n",
            "\n",
            "Epoch 00396: val_loss did not improve from 1.04342\n",
            "Epoch 397/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0501 - accuracy: 0.5433 - val_loss: 1.0704 - val_accuracy: 0.5282\n",
            "\n",
            "Epoch 00397: val_loss did not improve from 1.04342\n",
            "Epoch 398/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0295 - accuracy: 0.5539 - val_loss: 1.0674 - val_accuracy: 0.5417\n",
            "\n",
            "Epoch 00398: val_loss did not improve from 1.04342\n",
            "Epoch 399/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0484 - accuracy: 0.5500 - val_loss: 1.0687 - val_accuracy: 0.5359\n",
            "\n",
            "Epoch 00399: val_loss did not improve from 1.04342\n",
            "Epoch 400/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9999 - accuracy: 0.5678 - val_loss: 1.0608 - val_accuracy: 0.5365\n",
            "\n",
            "Epoch 00400: val_loss did not improve from 1.04342\n",
            "Epoch 401/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0355 - accuracy: 0.5518 - val_loss: 1.0632 - val_accuracy: 0.5397\n",
            "\n",
            "Epoch 00401: val_loss did not improve from 1.04342\n",
            "Epoch 402/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0199 - accuracy: 0.5646 - val_loss: 1.0621 - val_accuracy: 0.5481\n",
            "\n",
            "Epoch 00402: val_loss did not improve from 1.04342\n",
            "Epoch 403/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0384 - accuracy: 0.5499 - val_loss: 1.0607 - val_accuracy: 0.5468\n",
            "\n",
            "Epoch 00403: val_loss did not improve from 1.04342\n",
            "Epoch 404/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0098 - accuracy: 0.5665 - val_loss: 1.0709 - val_accuracy: 0.5397\n",
            "\n",
            "Epoch 00404: val_loss did not improve from 1.04342\n",
            "Epoch 405/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0010 - accuracy: 0.5684 - val_loss: 1.0857 - val_accuracy: 0.5244\n",
            "\n",
            "Epoch 00405: val_loss did not improve from 1.04342\n",
            "Epoch 406/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0523 - accuracy: 0.5455 - val_loss: 1.0919 - val_accuracy: 0.5333\n",
            "\n",
            "Epoch 00406: val_loss did not improve from 1.04342\n",
            "Epoch 407/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0121 - accuracy: 0.5758 - val_loss: 1.0658 - val_accuracy: 0.5365\n",
            "\n",
            "Epoch 00407: val_loss did not improve from 1.04342\n",
            "Epoch 408/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0334 - accuracy: 0.5452 - val_loss: 1.0652 - val_accuracy: 0.5410\n",
            "\n",
            "Epoch 00408: val_loss did not improve from 1.04342\n",
            "Epoch 409/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0538 - accuracy: 0.5400 - val_loss: 1.0672 - val_accuracy: 0.5404\n",
            "\n",
            "Epoch 00409: val_loss did not improve from 1.04342\n",
            "Epoch 410/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0242 - accuracy: 0.5541 - val_loss: 1.0609 - val_accuracy: 0.5429\n",
            "\n",
            "Epoch 00410: val_loss did not improve from 1.04342\n",
            "Epoch 411/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0100 - accuracy: 0.5645 - val_loss: 1.0795 - val_accuracy: 0.5282\n",
            "\n",
            "Epoch 00411: val_loss did not improve from 1.04342\n",
            "Epoch 412/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0239 - accuracy: 0.5509 - val_loss: 1.0621 - val_accuracy: 0.5397\n",
            "\n",
            "Epoch 00412: val_loss did not improve from 1.04342\n",
            "Epoch 413/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0602 - accuracy: 0.5383 - val_loss: 1.0608 - val_accuracy: 0.5385\n",
            "\n",
            "Epoch 00413: val_loss did not improve from 1.04342\n",
            "Epoch 414/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0069 - accuracy: 0.5704 - val_loss: 1.0593 - val_accuracy: 0.5442\n",
            "\n",
            "Epoch 00414: val_loss did not improve from 1.04342\n",
            "Epoch 415/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0451 - accuracy: 0.5511 - val_loss: 1.0580 - val_accuracy: 0.5385\n",
            "\n",
            "Epoch 00415: val_loss did not improve from 1.04342\n",
            "Epoch 416/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0470 - accuracy: 0.5323 - val_loss: 1.0670 - val_accuracy: 0.5410\n",
            "\n",
            "Epoch 00416: val_loss did not improve from 1.04342\n",
            "Epoch 417/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0136 - accuracy: 0.5488 - val_loss: 1.0628 - val_accuracy: 0.5404\n",
            "\n",
            "Epoch 00417: val_loss did not improve from 1.04342\n",
            "Epoch 418/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0440 - accuracy: 0.5340 - val_loss: 1.0632 - val_accuracy: 0.5436\n",
            "\n",
            "Epoch 00418: val_loss did not improve from 1.04342\n",
            "Epoch 419/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0120 - accuracy: 0.5571 - val_loss: 1.0595 - val_accuracy: 0.5391\n",
            "\n",
            "Epoch 00419: val_loss did not improve from 1.04342\n",
            "Epoch 420/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0278 - accuracy: 0.5615 - val_loss: 1.0621 - val_accuracy: 0.5385\n",
            "\n",
            "Epoch 00420: val_loss did not improve from 1.04342\n",
            "Epoch 421/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0291 - accuracy: 0.5600 - val_loss: 1.0804 - val_accuracy: 0.5263\n",
            "\n",
            "Epoch 00421: val_loss did not improve from 1.04342\n",
            "Epoch 422/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0365 - accuracy: 0.5478 - val_loss: 1.0664 - val_accuracy: 0.5365\n",
            "\n",
            "Epoch 00422: val_loss did not improve from 1.04342\n",
            "Epoch 423/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0439 - accuracy: 0.5562 - val_loss: 1.0770 - val_accuracy: 0.5192\n",
            "\n",
            "Epoch 00423: val_loss did not improve from 1.04342\n",
            "Epoch 424/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0567 - accuracy: 0.5479 - val_loss: 1.0616 - val_accuracy: 0.5417\n",
            "\n",
            "Epoch 00424: val_loss did not improve from 1.04342\n",
            "Epoch 425/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0211 - accuracy: 0.5490 - val_loss: 1.0776 - val_accuracy: 0.5353\n",
            "\n",
            "Epoch 00425: val_loss did not improve from 1.04342\n",
            "Epoch 426/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0407 - accuracy: 0.5610 - val_loss: 1.0635 - val_accuracy: 0.5417\n",
            "\n",
            "Epoch 00426: val_loss did not improve from 1.04342\n",
            "Epoch 427/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0302 - accuracy: 0.5519 - val_loss: 1.0602 - val_accuracy: 0.5417\n",
            "\n",
            "Epoch 00427: val_loss did not improve from 1.04342\n",
            "Epoch 428/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0167 - accuracy: 0.5599 - val_loss: 1.0646 - val_accuracy: 0.5429\n",
            "\n",
            "Epoch 00428: val_loss did not improve from 1.04342\n",
            "Epoch 429/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0324 - accuracy: 0.5460 - val_loss: 1.0620 - val_accuracy: 0.5397\n",
            "\n",
            "Epoch 00429: val_loss did not improve from 1.04342\n",
            "Epoch 430/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0407 - accuracy: 0.5459 - val_loss: 1.0564 - val_accuracy: 0.5474\n",
            "\n",
            "Epoch 00430: val_loss did not improve from 1.04342\n",
            "Epoch 431/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0499 - accuracy: 0.5484 - val_loss: 1.0864 - val_accuracy: 0.5263\n",
            "\n",
            "Epoch 00431: val_loss did not improve from 1.04342\n",
            "Epoch 432/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0320 - accuracy: 0.5591 - val_loss: 1.0935 - val_accuracy: 0.5237\n",
            "\n",
            "Epoch 00432: val_loss did not improve from 1.04342\n",
            "Epoch 433/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0228 - accuracy: 0.5686 - val_loss: 1.0720 - val_accuracy: 0.5333\n",
            "\n",
            "Epoch 00433: val_loss did not improve from 1.04342\n",
            "Epoch 434/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0337 - accuracy: 0.5552 - val_loss: 1.0621 - val_accuracy: 0.5417\n",
            "\n",
            "Epoch 00434: val_loss did not improve from 1.04342\n",
            "Epoch 435/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0358 - accuracy: 0.5532 - val_loss: 1.0721 - val_accuracy: 0.5321\n",
            "\n",
            "Epoch 00435: val_loss did not improve from 1.04342\n",
            "Epoch 436/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0285 - accuracy: 0.5472 - val_loss: 1.1094 - val_accuracy: 0.5237\n",
            "\n",
            "Epoch 00436: val_loss did not improve from 1.04342\n",
            "Epoch 437/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0306 - accuracy: 0.5559 - val_loss: 1.0628 - val_accuracy: 0.5359\n",
            "\n",
            "Epoch 00437: val_loss did not improve from 1.04342\n",
            "Epoch 438/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0111 - accuracy: 0.5683 - val_loss: 1.0573 - val_accuracy: 0.5250\n",
            "\n",
            "Epoch 00438: val_loss did not improve from 1.04342\n",
            "Epoch 439/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0352 - accuracy: 0.5464 - val_loss: 1.0694 - val_accuracy: 0.5365\n",
            "\n",
            "Epoch 00439: val_loss did not improve from 1.04342\n",
            "Epoch 440/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0384 - accuracy: 0.5519 - val_loss: 1.0854 - val_accuracy: 0.5288\n",
            "\n",
            "Epoch 00440: val_loss did not improve from 1.04342\n",
            "Epoch 441/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0409 - accuracy: 0.5493 - val_loss: 1.0595 - val_accuracy: 0.5353\n",
            "\n",
            "Epoch 00441: val_loss did not improve from 1.04342\n",
            "Epoch 442/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0210 - accuracy: 0.5571 - val_loss: 1.0744 - val_accuracy: 0.5301\n",
            "\n",
            "Epoch 00442: val_loss did not improve from 1.04342\n",
            "Epoch 443/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0275 - accuracy: 0.5550 - val_loss: 1.0804 - val_accuracy: 0.5327\n",
            "\n",
            "Epoch 00443: val_loss did not improve from 1.04342\n",
            "Epoch 444/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0297 - accuracy: 0.5469 - val_loss: 1.0787 - val_accuracy: 0.5429\n",
            "\n",
            "Epoch 00444: val_loss did not improve from 1.04342\n",
            "Epoch 445/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0233 - accuracy: 0.5388 - val_loss: 1.0742 - val_accuracy: 0.5359\n",
            "\n",
            "Epoch 00445: val_loss did not improve from 1.04342\n",
            "Epoch 446/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0388 - accuracy: 0.5652 - val_loss: 1.0682 - val_accuracy: 0.5449\n",
            "\n",
            "Epoch 00446: val_loss did not improve from 1.04342\n",
            "Epoch 447/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0263 - accuracy: 0.5629 - val_loss: 1.0516 - val_accuracy: 0.5359\n",
            "\n",
            "Epoch 00447: val_loss did not improve from 1.04342\n",
            "Epoch 448/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1.0213 - accuracy: 0.5519 - val_loss: 1.0624 - val_accuracy: 0.5526\n",
            "\n",
            "Epoch 00448: val_loss did not improve from 1.04342\n",
            "Epoch 449/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0150 - accuracy: 0.5630 - val_loss: 1.0767 - val_accuracy: 0.5314\n",
            "\n",
            "Epoch 00449: val_loss did not improve from 1.04342\n",
            "Epoch 450/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0609 - accuracy: 0.5486 - val_loss: 1.0638 - val_accuracy: 0.5410\n",
            "\n",
            "Epoch 00450: val_loss did not improve from 1.04342\n",
            "Epoch 451/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0121 - accuracy: 0.5650 - val_loss: 1.0652 - val_accuracy: 0.5487\n",
            "\n",
            "Epoch 00451: val_loss did not improve from 1.04342\n",
            "Epoch 452/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0263 - accuracy: 0.5535 - val_loss: 1.0601 - val_accuracy: 0.5372\n",
            "\n",
            "Epoch 00452: val_loss did not improve from 1.04342\n",
            "Epoch 453/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0128 - accuracy: 0.5692 - val_loss: 1.0800 - val_accuracy: 0.5346\n",
            "\n",
            "Epoch 00453: val_loss did not improve from 1.04342\n",
            "Epoch 454/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0410 - accuracy: 0.5489 - val_loss: 1.0805 - val_accuracy: 0.5154\n",
            "\n",
            "Epoch 00454: val_loss did not improve from 1.04342\n",
            "Epoch 455/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0123 - accuracy: 0.5696 - val_loss: 1.0768 - val_accuracy: 0.5269\n",
            "\n",
            "Epoch 00455: val_loss did not improve from 1.04342\n",
            "Epoch 456/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0286 - accuracy: 0.5485 - val_loss: 1.0767 - val_accuracy: 0.5372\n",
            "\n",
            "Epoch 00456: val_loss did not improve from 1.04342\n",
            "Epoch 457/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0367 - accuracy: 0.5563 - val_loss: 1.0705 - val_accuracy: 0.5404\n",
            "\n",
            "Epoch 00457: val_loss did not improve from 1.04342\n",
            "Epoch 458/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0335 - accuracy: 0.5628 - val_loss: 1.0676 - val_accuracy: 0.5404\n",
            "\n",
            "Epoch 00458: val_loss did not improve from 1.04342\n",
            "Epoch 459/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0109 - accuracy: 0.5717 - val_loss: 1.0754 - val_accuracy: 0.5327\n",
            "\n",
            "Epoch 00459: val_loss did not improve from 1.04342\n",
            "Epoch 460/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0227 - accuracy: 0.5557 - val_loss: 1.0737 - val_accuracy: 0.5359\n",
            "\n",
            "Epoch 00460: val_loss did not improve from 1.04342\n",
            "Epoch 461/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0311 - accuracy: 0.5596 - val_loss: 1.0555 - val_accuracy: 0.5365\n",
            "\n",
            "Epoch 00461: val_loss did not improve from 1.04342\n",
            "Epoch 462/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0158 - accuracy: 0.5612 - val_loss: 1.0643 - val_accuracy: 0.5365\n",
            "\n",
            "Epoch 00462: val_loss did not improve from 1.04342\n",
            "Epoch 463/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0267 - accuracy: 0.5646 - val_loss: 1.0613 - val_accuracy: 0.5372\n",
            "\n",
            "Epoch 00463: val_loss did not improve from 1.04342\n",
            "Epoch 464/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0192 - accuracy: 0.5517 - val_loss: 1.0697 - val_accuracy: 0.5468\n",
            "\n",
            "Epoch 00464: val_loss did not improve from 1.04342\n",
            "Epoch 465/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9975 - accuracy: 0.5706 - val_loss: 1.0738 - val_accuracy: 0.5333\n",
            "\n",
            "Epoch 00465: val_loss did not improve from 1.04342\n",
            "Epoch 466/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0446 - accuracy: 0.5536 - val_loss: 1.0643 - val_accuracy: 0.5423\n",
            "\n",
            "Epoch 00466: val_loss did not improve from 1.04342\n",
            "Epoch 467/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1.0154 - accuracy: 0.5541 - val_loss: 1.0733 - val_accuracy: 0.5397\n",
            "\n",
            "Epoch 00467: val_loss did not improve from 1.04342\n",
            "Epoch 468/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0139 - accuracy: 0.5625 - val_loss: 1.0617 - val_accuracy: 0.5385\n",
            "\n",
            "Epoch 00468: val_loss did not improve from 1.04342\n",
            "Epoch 469/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0037 - accuracy: 0.5760 - val_loss: 1.0698 - val_accuracy: 0.5353\n",
            "\n",
            "Epoch 00469: val_loss did not improve from 1.04342\n",
            "Epoch 470/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0280 - accuracy: 0.5628 - val_loss: 1.0963 - val_accuracy: 0.5250\n",
            "\n",
            "Epoch 00470: val_loss did not improve from 1.04342\n",
            "Epoch 471/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0189 - accuracy: 0.5663 - val_loss: 1.0629 - val_accuracy: 0.5410\n",
            "\n",
            "Epoch 00471: val_loss did not improve from 1.04342\n",
            "Epoch 472/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0396 - accuracy: 0.5506 - val_loss: 1.0644 - val_accuracy: 0.5404\n",
            "\n",
            "Epoch 00472: val_loss did not improve from 1.04342\n",
            "Epoch 473/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0218 - accuracy: 0.5585 - val_loss: 1.0611 - val_accuracy: 0.5442\n",
            "\n",
            "Epoch 00473: val_loss did not improve from 1.04342\n",
            "Epoch 474/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0081 - accuracy: 0.5698 - val_loss: 1.0916 - val_accuracy: 0.5263\n",
            "\n",
            "Epoch 00474: val_loss did not improve from 1.04342\n",
            "Epoch 475/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0436 - accuracy: 0.5472 - val_loss: 1.0607 - val_accuracy: 0.5423\n",
            "\n",
            "Epoch 00475: val_loss did not improve from 1.04342\n",
            "Epoch 476/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0290 - accuracy: 0.5428 - val_loss: 1.0635 - val_accuracy: 0.5442\n",
            "\n",
            "Epoch 00476: val_loss did not improve from 1.04342\n",
            "Epoch 477/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0376 - accuracy: 0.5432 - val_loss: 1.0706 - val_accuracy: 0.5314\n",
            "\n",
            "Epoch 00477: val_loss did not improve from 1.04342\n",
            "Epoch 478/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1.0378 - accuracy: 0.5471 - val_loss: 1.1013 - val_accuracy: 0.5090\n",
            "\n",
            "Epoch 00478: val_loss did not improve from 1.04342\n",
            "Epoch 479/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0131 - accuracy: 0.5664 - val_loss: 1.0677 - val_accuracy: 0.5404\n",
            "\n",
            "Epoch 00479: val_loss did not improve from 1.04342\n",
            "Epoch 480/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0261 - accuracy: 0.5568 - val_loss: 1.0613 - val_accuracy: 0.5333\n",
            "\n",
            "Epoch 00480: val_loss did not improve from 1.04342\n",
            "Epoch 481/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1.0238 - accuracy: 0.5495 - val_loss: 1.0640 - val_accuracy: 0.5391\n",
            "\n",
            "Epoch 00481: val_loss did not improve from 1.04342\n",
            "Epoch 482/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0114 - accuracy: 0.5547 - val_loss: 1.0624 - val_accuracy: 0.5481\n",
            "\n",
            "Epoch 00482: val_loss did not improve from 1.04342\n",
            "Epoch 483/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0249 - accuracy: 0.5548 - val_loss: 1.0708 - val_accuracy: 0.5417\n",
            "\n",
            "Epoch 00483: val_loss did not improve from 1.04342\n",
            "Epoch 484/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0305 - accuracy: 0.5537 - val_loss: 1.0581 - val_accuracy: 0.5442\n",
            "\n",
            "Epoch 00484: val_loss did not improve from 1.04342\n",
            "Epoch 485/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0302 - accuracy: 0.5504 - val_loss: 1.0889 - val_accuracy: 0.5263\n",
            "\n",
            "Epoch 00485: val_loss did not improve from 1.04342\n",
            "Epoch 486/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0211 - accuracy: 0.5629 - val_loss: 1.0862 - val_accuracy: 0.5301\n",
            "\n",
            "Epoch 00486: val_loss did not improve from 1.04342\n",
            "Epoch 487/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0327 - accuracy: 0.5635 - val_loss: 1.1023 - val_accuracy: 0.5173\n",
            "\n",
            "Epoch 00487: val_loss did not improve from 1.04342\n",
            "Epoch 488/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0182 - accuracy: 0.5640 - val_loss: 1.0945 - val_accuracy: 0.5186\n",
            "\n",
            "Epoch 00488: val_loss did not improve from 1.04342\n",
            "Epoch 489/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0150 - accuracy: 0.5623 - val_loss: 1.0645 - val_accuracy: 0.5417\n",
            "\n",
            "Epoch 00489: val_loss did not improve from 1.04342\n",
            "Epoch 490/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0199 - accuracy: 0.5732 - val_loss: 1.0625 - val_accuracy: 0.5462\n",
            "\n",
            "Epoch 00490: val_loss did not improve from 1.04342\n",
            "Epoch 491/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0426 - accuracy: 0.5436 - val_loss: 1.0815 - val_accuracy: 0.5301\n",
            "\n",
            "Epoch 00491: val_loss did not improve from 1.04342\n",
            "Epoch 492/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0272 - accuracy: 0.5560 - val_loss: 1.0684 - val_accuracy: 0.5314\n",
            "\n",
            "Epoch 00492: val_loss did not improve from 1.04342\n",
            "Epoch 493/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0182 - accuracy: 0.5632 - val_loss: 1.0647 - val_accuracy: 0.5449\n",
            "\n",
            "Epoch 00493: val_loss did not improve from 1.04342\n",
            "Epoch 494/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0092 - accuracy: 0.5677 - val_loss: 1.0689 - val_accuracy: 0.5449\n",
            "\n",
            "Epoch 00494: val_loss did not improve from 1.04342\n",
            "Epoch 495/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0063 - accuracy: 0.5662 - val_loss: 1.0741 - val_accuracy: 0.5455\n",
            "\n",
            "Epoch 00495: val_loss did not improve from 1.04342\n",
            "Epoch 496/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0325 - accuracy: 0.5520 - val_loss: 1.0576 - val_accuracy: 0.5481\n",
            "\n",
            "Epoch 00496: val_loss did not improve from 1.04342\n",
            "Epoch 497/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0346 - accuracy: 0.5655 - val_loss: 1.0587 - val_accuracy: 0.5487\n",
            "\n",
            "Epoch 00497: val_loss did not improve from 1.04342\n",
            "Epoch 498/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0045 - accuracy: 0.5625 - val_loss: 1.0819 - val_accuracy: 0.5192\n",
            "\n",
            "Epoch 00498: val_loss did not improve from 1.04342\n",
            "Epoch 499/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0550 - accuracy: 0.5439 - val_loss: 1.0645 - val_accuracy: 0.5513\n",
            "\n",
            "Epoch 00499: val_loss did not improve from 1.04342\n",
            "Epoch 500/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0312 - accuracy: 0.5545 - val_loss: 1.0717 - val_accuracy: 0.5410\n",
            "\n",
            "Epoch 00500: val_loss did not improve from 1.04342\n",
            "Epoch 501/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0419 - accuracy: 0.5454 - val_loss: 1.0939 - val_accuracy: 0.5083\n",
            "\n",
            "Epoch 00501: val_loss did not improve from 1.04342\n",
            "Epoch 502/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0545 - accuracy: 0.5355 - val_loss: 1.0704 - val_accuracy: 0.5282\n",
            "\n",
            "Epoch 00502: val_loss did not improve from 1.04342\n",
            "Epoch 503/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0244 - accuracy: 0.5504 - val_loss: 1.0629 - val_accuracy: 0.5385\n",
            "\n",
            "Epoch 00503: val_loss did not improve from 1.04342\n",
            "Epoch 504/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0366 - accuracy: 0.5640 - val_loss: 1.0581 - val_accuracy: 0.5519\n",
            "\n",
            "Epoch 00504: val_loss did not improve from 1.04342\n",
            "Epoch 505/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.9875 - accuracy: 0.5744 - val_loss: 1.1018 - val_accuracy: 0.5295\n",
            "\n",
            "Epoch 00505: val_loss did not improve from 1.04342\n",
            "Epoch 506/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0262 - accuracy: 0.5622 - val_loss: 1.0788 - val_accuracy: 0.5301\n",
            "\n",
            "Epoch 00506: val_loss did not improve from 1.04342\n",
            "Epoch 507/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0027 - accuracy: 0.5762 - val_loss: 1.0625 - val_accuracy: 0.5436\n",
            "\n",
            "Epoch 00507: val_loss did not improve from 1.04342\n",
            "Epoch 508/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0054 - accuracy: 0.5535 - val_loss: 1.0668 - val_accuracy: 0.5404\n",
            "\n",
            "Epoch 00508: val_loss did not improve from 1.04342\n",
            "Epoch 509/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0189 - accuracy: 0.5717 - val_loss: 1.0654 - val_accuracy: 0.5468\n",
            "\n",
            "Epoch 00509: val_loss did not improve from 1.04342\n",
            "Epoch 510/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9887 - accuracy: 0.5765 - val_loss: 1.0733 - val_accuracy: 0.5346\n",
            "\n",
            "Epoch 00510: val_loss did not improve from 1.04342\n",
            "Epoch 511/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0115 - accuracy: 0.5786 - val_loss: 1.0646 - val_accuracy: 0.5436\n",
            "\n",
            "Epoch 00511: val_loss did not improve from 1.04342\n",
            "Epoch 512/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0077 - accuracy: 0.5621 - val_loss: 1.0785 - val_accuracy: 0.5391\n",
            "\n",
            "Epoch 00512: val_loss did not improve from 1.04342\n",
            "Epoch 513/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0142 - accuracy: 0.5542 - val_loss: 1.0745 - val_accuracy: 0.5391\n",
            "\n",
            "Epoch 00513: val_loss did not improve from 1.04342\n",
            "Epoch 514/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0312 - accuracy: 0.5620 - val_loss: 1.0659 - val_accuracy: 0.5436\n",
            "\n",
            "Epoch 00514: val_loss did not improve from 1.04342\n",
            "Epoch 515/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0170 - accuracy: 0.5568 - val_loss: 1.1193 - val_accuracy: 0.5083\n",
            "\n",
            "Epoch 00515: val_loss did not improve from 1.04342\n",
            "Epoch 516/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0335 - accuracy: 0.5529 - val_loss: 1.0646 - val_accuracy: 0.5410\n",
            "\n",
            "Epoch 00516: val_loss did not improve from 1.04342\n",
            "Epoch 517/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0052 - accuracy: 0.5650 - val_loss: 1.0720 - val_accuracy: 0.5314\n",
            "\n",
            "Epoch 00517: val_loss did not improve from 1.04342\n",
            "Epoch 518/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0046 - accuracy: 0.5652 - val_loss: 1.0632 - val_accuracy: 0.5423\n",
            "\n",
            "Epoch 00518: val_loss did not improve from 1.04342\n",
            "Epoch 519/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0089 - accuracy: 0.5534 - val_loss: 1.0685 - val_accuracy: 0.5462\n",
            "\n",
            "Epoch 00519: val_loss did not improve from 1.04342\n",
            "Epoch 520/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0094 - accuracy: 0.5523 - val_loss: 1.0689 - val_accuracy: 0.5385\n",
            "\n",
            "Epoch 00520: val_loss did not improve from 1.04342\n",
            "Epoch 521/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0166 - accuracy: 0.5573 - val_loss: 1.0685 - val_accuracy: 0.5346\n",
            "\n",
            "Epoch 00521: val_loss did not improve from 1.04342\n",
            "Epoch 522/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0220 - accuracy: 0.5612 - val_loss: 1.1393 - val_accuracy: 0.4955\n",
            "\n",
            "Epoch 00522: val_loss did not improve from 1.04342\n",
            "Epoch 523/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0351 - accuracy: 0.5513 - val_loss: 1.0801 - val_accuracy: 0.5288\n",
            "\n",
            "Epoch 00523: val_loss did not improve from 1.04342\n",
            "Epoch 524/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0062 - accuracy: 0.5601 - val_loss: 1.0747 - val_accuracy: 0.5340\n",
            "\n",
            "Epoch 00524: val_loss did not improve from 1.04342\n",
            "Epoch 525/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0037 - accuracy: 0.5618 - val_loss: 1.0735 - val_accuracy: 0.5410\n",
            "\n",
            "Epoch 00525: val_loss did not improve from 1.04342\n",
            "Epoch 526/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0281 - accuracy: 0.5612 - val_loss: 1.0797 - val_accuracy: 0.5308\n",
            "\n",
            "Epoch 00526: val_loss did not improve from 1.04342\n",
            "Epoch 527/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9961 - accuracy: 0.5751 - val_loss: 1.0568 - val_accuracy: 0.5462\n",
            "\n",
            "Epoch 00527: val_loss did not improve from 1.04342\n",
            "Epoch 528/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0294 - accuracy: 0.5529 - val_loss: 1.0611 - val_accuracy: 0.5506\n",
            "\n",
            "Epoch 00528: val_loss did not improve from 1.04342\n",
            "Epoch 529/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1.0313 - accuracy: 0.5495 - val_loss: 1.0930 - val_accuracy: 0.5192\n",
            "\n",
            "Epoch 00529: val_loss did not improve from 1.04342\n",
            "Epoch 530/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1.0157 - accuracy: 0.5635 - val_loss: 1.0684 - val_accuracy: 0.5487\n",
            "\n",
            "Epoch 00530: val_loss did not improve from 1.04342\n",
            "Epoch 531/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0071 - accuracy: 0.5573 - val_loss: 1.0603 - val_accuracy: 0.5506\n",
            "\n",
            "Epoch 00531: val_loss did not improve from 1.04342\n",
            "Epoch 532/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0371 - accuracy: 0.5668 - val_loss: 1.0632 - val_accuracy: 0.5500\n",
            "\n",
            "Epoch 00532: val_loss did not improve from 1.04342\n",
            "Epoch 533/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0352 - accuracy: 0.5567 - val_loss: 1.0687 - val_accuracy: 0.5372\n",
            "\n",
            "Epoch 00533: val_loss did not improve from 1.04342\n",
            "Epoch 534/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9997 - accuracy: 0.5723 - val_loss: 1.0798 - val_accuracy: 0.5378\n",
            "\n",
            "Epoch 00534: val_loss did not improve from 1.04342\n",
            "Epoch 535/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0169 - accuracy: 0.5501 - val_loss: 1.0648 - val_accuracy: 0.5526\n",
            "\n",
            "Epoch 00535: val_loss did not improve from 1.04342\n",
            "Epoch 536/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0309 - accuracy: 0.5513 - val_loss: 1.0702 - val_accuracy: 0.5327\n",
            "\n",
            "Epoch 00536: val_loss did not improve from 1.04342\n",
            "Epoch 537/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0017 - accuracy: 0.5610 - val_loss: 1.0879 - val_accuracy: 0.5192\n",
            "\n",
            "Epoch 00537: val_loss did not improve from 1.04342\n",
            "Epoch 538/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0154 - accuracy: 0.5532 - val_loss: 1.0631 - val_accuracy: 0.5423\n",
            "\n",
            "Epoch 00538: val_loss did not improve from 1.04342\n",
            "Epoch 539/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0099 - accuracy: 0.5609 - val_loss: 1.0597 - val_accuracy: 0.5487\n",
            "\n",
            "Epoch 00539: val_loss did not improve from 1.04342\n",
            "Epoch 540/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1.0148 - accuracy: 0.5570 - val_loss: 1.0662 - val_accuracy: 0.5333\n",
            "\n",
            "Epoch 00540: val_loss did not improve from 1.04342\n",
            "Epoch 541/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0001 - accuracy: 0.5690 - val_loss: 1.0872 - val_accuracy: 0.5269\n",
            "\n",
            "Epoch 00541: val_loss did not improve from 1.04342\n",
            "Epoch 542/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0216 - accuracy: 0.5638 - val_loss: 1.0816 - val_accuracy: 0.5263\n",
            "\n",
            "Epoch 00542: val_loss did not improve from 1.04342\n",
            "Epoch 543/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0238 - accuracy: 0.5546 - val_loss: 1.0611 - val_accuracy: 0.5442\n",
            "\n",
            "Epoch 00543: val_loss did not improve from 1.04342\n",
            "Epoch 544/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0351 - accuracy: 0.5453 - val_loss: 1.0912 - val_accuracy: 0.5308\n",
            "\n",
            "Epoch 00544: val_loss did not improve from 1.04342\n",
            "Epoch 545/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9985 - accuracy: 0.5702 - val_loss: 1.0714 - val_accuracy: 0.5397\n",
            "\n",
            "Epoch 00545: val_loss did not improve from 1.04342\n",
            "Epoch 546/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1.0068 - accuracy: 0.5709 - val_loss: 1.0690 - val_accuracy: 0.5526\n",
            "\n",
            "Epoch 00546: val_loss did not improve from 1.04342\n",
            "Epoch 547/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0020 - accuracy: 0.5739 - val_loss: 1.0693 - val_accuracy: 0.5462\n",
            "\n",
            "Epoch 00547: val_loss did not improve from 1.04342\n",
            "Epoch 548/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0056 - accuracy: 0.5624 - val_loss: 1.0803 - val_accuracy: 0.5314\n",
            "\n",
            "Epoch 00548: val_loss did not improve from 1.04342\n",
            "Epoch 549/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0072 - accuracy: 0.5647 - val_loss: 1.0660 - val_accuracy: 0.5404\n",
            "\n",
            "Epoch 00549: val_loss did not improve from 1.04342\n",
            "Epoch 550/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0185 - accuracy: 0.5563 - val_loss: 1.0657 - val_accuracy: 0.5506\n",
            "\n",
            "Epoch 00550: val_loss did not improve from 1.04342\n",
            "Epoch 551/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0172 - accuracy: 0.5557 - val_loss: 1.0768 - val_accuracy: 0.5449\n",
            "\n",
            "Epoch 00551: val_loss did not improve from 1.04342\n",
            "Epoch 552/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0197 - accuracy: 0.5636 - val_loss: 1.0785 - val_accuracy: 0.5487\n",
            "\n",
            "Epoch 00552: val_loss did not improve from 1.04342\n",
            "Epoch 553/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1.0325 - accuracy: 0.5577 - val_loss: 1.0689 - val_accuracy: 0.5500\n",
            "\n",
            "Epoch 00553: val_loss did not improve from 1.04342\n",
            "Epoch 554/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0000 - accuracy: 0.5691 - val_loss: 1.0853 - val_accuracy: 0.5378\n",
            "\n",
            "Epoch 00554: val_loss did not improve from 1.04342\n",
            "Epoch 555/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0042 - accuracy: 0.5611 - val_loss: 1.0870 - val_accuracy: 0.5378\n",
            "\n",
            "Epoch 00555: val_loss did not improve from 1.04342\n",
            "Epoch 556/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0112 - accuracy: 0.5441 - val_loss: 1.1081 - val_accuracy: 0.5244\n",
            "\n",
            "Epoch 00556: val_loss did not improve from 1.04342\n",
            "Epoch 557/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0306 - accuracy: 0.5573 - val_loss: 1.0717 - val_accuracy: 0.5462\n",
            "\n",
            "Epoch 00557: val_loss did not improve from 1.04342\n",
            "Epoch 558/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.9979 - accuracy: 0.5736 - val_loss: 1.0700 - val_accuracy: 0.5455\n",
            "\n",
            "Epoch 00558: val_loss did not improve from 1.04342\n",
            "Epoch 559/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1.0151 - accuracy: 0.5538 - val_loss: 1.0655 - val_accuracy: 0.5442\n",
            "\n",
            "Epoch 00559: val_loss did not improve from 1.04342\n",
            "Epoch 560/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0330 - accuracy: 0.5713 - val_loss: 1.0801 - val_accuracy: 0.5372\n",
            "\n",
            "Epoch 00560: val_loss did not improve from 1.04342\n",
            "Epoch 561/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0143 - accuracy: 0.5620 - val_loss: 1.0750 - val_accuracy: 0.5353\n",
            "\n",
            "Epoch 00561: val_loss did not improve from 1.04342\n",
            "Epoch 562/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0208 - accuracy: 0.5664 - val_loss: 1.0785 - val_accuracy: 0.5429\n",
            "\n",
            "Epoch 00562: val_loss did not improve from 1.04342\n",
            "Epoch 563/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0494 - accuracy: 0.5323 - val_loss: 1.1223 - val_accuracy: 0.5058\n",
            "\n",
            "Epoch 00563: val_loss did not improve from 1.04342\n",
            "Epoch 564/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0390 - accuracy: 0.5572 - val_loss: 1.0647 - val_accuracy: 0.5468\n",
            "\n",
            "Epoch 00564: val_loss did not improve from 1.04342\n",
            "Epoch 565/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9998 - accuracy: 0.5759 - val_loss: 1.0777 - val_accuracy: 0.5410\n",
            "\n",
            "Epoch 00565: val_loss did not improve from 1.04342\n",
            "Epoch 566/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9913 - accuracy: 0.5825 - val_loss: 1.0840 - val_accuracy: 0.5263\n",
            "\n",
            "Epoch 00566: val_loss did not improve from 1.04342\n",
            "Epoch 567/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1.0252 - accuracy: 0.5783 - val_loss: 1.0730 - val_accuracy: 0.5500\n",
            "\n",
            "Epoch 00567: val_loss did not improve from 1.04342\n",
            "Epoch 568/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1.0290 - accuracy: 0.5540 - val_loss: 1.0780 - val_accuracy: 0.5442\n",
            "\n",
            "Epoch 00568: val_loss did not improve from 1.04342\n",
            "Epoch 569/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 1.0018 - accuracy: 0.5575 - val_loss: 1.0842 - val_accuracy: 0.5250\n",
            "\n",
            "Epoch 00569: val_loss did not improve from 1.04342\n",
            "Epoch 570/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1.0172 - accuracy: 0.5684 - val_loss: 1.1122 - val_accuracy: 0.5295\n",
            "\n",
            "Epoch 00570: val_loss did not improve from 1.04342\n",
            "Epoch 571/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0270 - accuracy: 0.5591 - val_loss: 1.0708 - val_accuracy: 0.5506\n",
            "\n",
            "Epoch 00571: val_loss did not improve from 1.04342\n",
            "Epoch 572/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0000 - accuracy: 0.5650 - val_loss: 1.0781 - val_accuracy: 0.5429\n",
            "\n",
            "Epoch 00572: val_loss did not improve from 1.04342\n",
            "Epoch 573/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0061 - accuracy: 0.5705 - val_loss: 1.0712 - val_accuracy: 0.5455\n",
            "\n",
            "Epoch 00573: val_loss did not improve from 1.04342\n",
            "Epoch 574/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0041 - accuracy: 0.5556 - val_loss: 1.0632 - val_accuracy: 0.5487\n",
            "\n",
            "Epoch 00574: val_loss did not improve from 1.04342\n",
            "Epoch 575/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0118 - accuracy: 0.5675 - val_loss: 1.0683 - val_accuracy: 0.5468\n",
            "\n",
            "Epoch 00575: val_loss did not improve from 1.04342\n",
            "Epoch 576/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9965 - accuracy: 0.5787 - val_loss: 1.0642 - val_accuracy: 0.5513\n",
            "\n",
            "Epoch 00576: val_loss did not improve from 1.04342\n",
            "Epoch 577/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1.0134 - accuracy: 0.5532 - val_loss: 1.0725 - val_accuracy: 0.5474\n",
            "\n",
            "Epoch 00577: val_loss did not improve from 1.04342\n",
            "Epoch 578/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1.0099 - accuracy: 0.5673 - val_loss: 1.0646 - val_accuracy: 0.5519\n",
            "\n",
            "Epoch 00578: val_loss did not improve from 1.04342\n",
            "Epoch 579/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0220 - accuracy: 0.5520 - val_loss: 1.0602 - val_accuracy: 0.5538\n",
            "\n",
            "Epoch 00579: val_loss did not improve from 1.04342\n",
            "Epoch 580/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9973 - accuracy: 0.5761 - val_loss: 1.0681 - val_accuracy: 0.5410\n",
            "\n",
            "Epoch 00580: val_loss did not improve from 1.04342\n",
            "Epoch 581/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9955 - accuracy: 0.5787 - val_loss: 1.0681 - val_accuracy: 0.5442\n",
            "\n",
            "Epoch 00581: val_loss did not improve from 1.04342\n",
            "Epoch 582/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0259 - accuracy: 0.5541 - val_loss: 1.0759 - val_accuracy: 0.5372\n",
            "\n",
            "Epoch 00582: val_loss did not improve from 1.04342\n",
            "Epoch 583/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0203 - accuracy: 0.5707 - val_loss: 1.0795 - val_accuracy: 0.5474\n",
            "\n",
            "Epoch 00583: val_loss did not improve from 1.04342\n",
            "Epoch 584/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9847 - accuracy: 0.5754 - val_loss: 1.0772 - val_accuracy: 0.5353\n",
            "\n",
            "Epoch 00584: val_loss did not improve from 1.04342\n",
            "Epoch 585/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0077 - accuracy: 0.5568 - val_loss: 1.0737 - val_accuracy: 0.5462\n",
            "\n",
            "Epoch 00585: val_loss did not improve from 1.04342\n",
            "Epoch 586/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0100 - accuracy: 0.5644 - val_loss: 1.0742 - val_accuracy: 0.5417\n",
            "\n",
            "Epoch 00586: val_loss did not improve from 1.04342\n",
            "Epoch 587/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0392 - accuracy: 0.5467 - val_loss: 1.0667 - val_accuracy: 0.5506\n",
            "\n",
            "Epoch 00587: val_loss did not improve from 1.04342\n",
            "Epoch 588/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9984 - accuracy: 0.5711 - val_loss: 1.0878 - val_accuracy: 0.5321\n",
            "\n",
            "Epoch 00588: val_loss did not improve from 1.04342\n",
            "Epoch 589/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0267 - accuracy: 0.5513 - val_loss: 1.0688 - val_accuracy: 0.5397\n",
            "\n",
            "Epoch 00589: val_loss did not improve from 1.04342\n",
            "Epoch 590/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0041 - accuracy: 0.5552 - val_loss: 1.0779 - val_accuracy: 0.5346\n",
            "\n",
            "Epoch 00590: val_loss did not improve from 1.04342\n",
            "Epoch 591/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1.0051 - accuracy: 0.5842 - val_loss: 1.0827 - val_accuracy: 0.5237\n",
            "\n",
            "Epoch 00591: val_loss did not improve from 1.04342\n",
            "Epoch 592/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0408 - accuracy: 0.5503 - val_loss: 1.0722 - val_accuracy: 0.5410\n",
            "\n",
            "Epoch 00592: val_loss did not improve from 1.04342\n",
            "Epoch 593/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0135 - accuracy: 0.5723 - val_loss: 1.0757 - val_accuracy: 0.5442\n",
            "\n",
            "Epoch 00593: val_loss did not improve from 1.04342\n",
            "Epoch 594/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0052 - accuracy: 0.5641 - val_loss: 1.0986 - val_accuracy: 0.5353\n",
            "\n",
            "Epoch 00594: val_loss did not improve from 1.04342\n",
            "Epoch 595/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0160 - accuracy: 0.5611 - val_loss: 1.0659 - val_accuracy: 0.5397\n",
            "\n",
            "Epoch 00595: val_loss did not improve from 1.04342\n",
            "Epoch 596/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0338 - accuracy: 0.5646 - val_loss: 1.0678 - val_accuracy: 0.5436\n",
            "\n",
            "Epoch 00596: val_loss did not improve from 1.04342\n",
            "Epoch 597/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9935 - accuracy: 0.5698 - val_loss: 1.0777 - val_accuracy: 0.5333\n",
            "\n",
            "Epoch 00597: val_loss did not improve from 1.04342\n",
            "Epoch 598/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0154 - accuracy: 0.5601 - val_loss: 1.0766 - val_accuracy: 0.5468\n",
            "\n",
            "Epoch 00598: val_loss did not improve from 1.04342\n",
            "Epoch 599/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0151 - accuracy: 0.5523 - val_loss: 1.0706 - val_accuracy: 0.5417\n",
            "\n",
            "Epoch 00599: val_loss did not improve from 1.04342\n",
            "Epoch 600/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0031 - accuracy: 0.5683 - val_loss: 1.0772 - val_accuracy: 0.5494\n",
            "\n",
            "Epoch 00600: val_loss did not improve from 1.04342\n",
            "Epoch 601/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1.0017 - accuracy: 0.5744 - val_loss: 1.0706 - val_accuracy: 0.5391\n",
            "\n",
            "Epoch 00601: val_loss did not improve from 1.04342\n",
            "Epoch 602/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.9990 - accuracy: 0.5728 - val_loss: 1.0646 - val_accuracy: 0.5481\n",
            "\n",
            "Epoch 00602: val_loss did not improve from 1.04342\n",
            "Epoch 603/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0359 - accuracy: 0.5499 - val_loss: 1.0813 - val_accuracy: 0.5423\n",
            "\n",
            "Epoch 00603: val_loss did not improve from 1.04342\n",
            "Epoch 604/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0245 - accuracy: 0.5505 - val_loss: 1.0959 - val_accuracy: 0.5353\n",
            "\n",
            "Epoch 00604: val_loss did not improve from 1.04342\n",
            "Epoch 605/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9843 - accuracy: 0.5798 - val_loss: 1.0736 - val_accuracy: 0.5481\n",
            "\n",
            "Epoch 00605: val_loss did not improve from 1.04342\n",
            "Epoch 606/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0050 - accuracy: 0.5636 - val_loss: 1.0776 - val_accuracy: 0.5321\n",
            "\n",
            "Epoch 00606: val_loss did not improve from 1.04342\n",
            "Epoch 607/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0268 - accuracy: 0.5504 - val_loss: 1.0797 - val_accuracy: 0.5378\n",
            "\n",
            "Epoch 00607: val_loss did not improve from 1.04342\n",
            "Epoch 608/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0232 - accuracy: 0.5496 - val_loss: 1.1411 - val_accuracy: 0.4929\n",
            "\n",
            "Epoch 00608: val_loss did not improve from 1.04342\n",
            "Epoch 609/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0239 - accuracy: 0.5638 - val_loss: 1.0763 - val_accuracy: 0.5429\n",
            "\n",
            "Epoch 00609: val_loss did not improve from 1.04342\n",
            "Epoch 610/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9775 - accuracy: 0.5912 - val_loss: 1.0700 - val_accuracy: 0.5410\n",
            "\n",
            "Epoch 00610: val_loss did not improve from 1.04342\n",
            "Epoch 611/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0098 - accuracy: 0.5633 - val_loss: 1.0709 - val_accuracy: 0.5410\n",
            "\n",
            "Epoch 00611: val_loss did not improve from 1.04342\n",
            "Epoch 612/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0003 - accuracy: 0.5620 - val_loss: 1.0632 - val_accuracy: 0.5410\n",
            "\n",
            "Epoch 00612: val_loss did not improve from 1.04342\n",
            "Epoch 613/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0229 - accuracy: 0.5525 - val_loss: 1.0635 - val_accuracy: 0.5506\n",
            "\n",
            "Epoch 00613: val_loss did not improve from 1.04342\n",
            "Epoch 614/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9912 - accuracy: 0.5660 - val_loss: 1.0668 - val_accuracy: 0.5500\n",
            "\n",
            "Epoch 00614: val_loss did not improve from 1.04342\n",
            "Epoch 615/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0346 - accuracy: 0.5557 - val_loss: 1.0900 - val_accuracy: 0.5365\n",
            "\n",
            "Epoch 00615: val_loss did not improve from 1.04342\n",
            "Epoch 616/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0091 - accuracy: 0.5586 - val_loss: 1.0810 - val_accuracy: 0.5442\n",
            "\n",
            "Epoch 00616: val_loss did not improve from 1.04342\n",
            "Epoch 617/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9916 - accuracy: 0.5847 - val_loss: 1.0795 - val_accuracy: 0.5462\n",
            "\n",
            "Epoch 00617: val_loss did not improve from 1.04342\n",
            "Epoch 618/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0096 - accuracy: 0.5640 - val_loss: 1.0672 - val_accuracy: 0.5468\n",
            "\n",
            "Epoch 00618: val_loss did not improve from 1.04342\n",
            "Epoch 619/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9819 - accuracy: 0.5694 - val_loss: 1.0717 - val_accuracy: 0.5449\n",
            "\n",
            "Epoch 00619: val_loss did not improve from 1.04342\n",
            "Epoch 620/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0000 - accuracy: 0.5660 - val_loss: 1.0645 - val_accuracy: 0.5385\n",
            "\n",
            "Epoch 00620: val_loss did not improve from 1.04342\n",
            "Epoch 621/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0347 - accuracy: 0.5406 - val_loss: 1.0752 - val_accuracy: 0.5519\n",
            "\n",
            "Epoch 00621: val_loss did not improve from 1.04342\n",
            "Epoch 622/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0137 - accuracy: 0.5637 - val_loss: 1.0669 - val_accuracy: 0.5487\n",
            "\n",
            "Epoch 00622: val_loss did not improve from 1.04342\n",
            "Epoch 623/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9973 - accuracy: 0.5738 - val_loss: 1.0767 - val_accuracy: 0.5404\n",
            "\n",
            "Epoch 00623: val_loss did not improve from 1.04342\n",
            "Epoch 624/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9927 - accuracy: 0.5654 - val_loss: 1.0724 - val_accuracy: 0.5385\n",
            "\n",
            "Epoch 00624: val_loss did not improve from 1.04342\n",
            "Epoch 625/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0061 - accuracy: 0.5676 - val_loss: 1.0732 - val_accuracy: 0.5397\n",
            "\n",
            "Epoch 00625: val_loss did not improve from 1.04342\n",
            "Epoch 626/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9873 - accuracy: 0.5783 - val_loss: 1.0890 - val_accuracy: 0.5391\n",
            "\n",
            "Epoch 00626: val_loss did not improve from 1.04342\n",
            "Epoch 627/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0140 - accuracy: 0.5494 - val_loss: 1.1014 - val_accuracy: 0.5212\n",
            "\n",
            "Epoch 00627: val_loss did not improve from 1.04342\n",
            "Epoch 628/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0275 - accuracy: 0.5439 - val_loss: 1.0717 - val_accuracy: 0.5429\n",
            "\n",
            "Epoch 00628: val_loss did not improve from 1.04342\n",
            "Epoch 629/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0365 - accuracy: 0.5632 - val_loss: 1.0755 - val_accuracy: 0.5244\n",
            "\n",
            "Epoch 00629: val_loss did not improve from 1.04342\n",
            "Epoch 630/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0226 - accuracy: 0.5746 - val_loss: 1.1022 - val_accuracy: 0.5314\n",
            "\n",
            "Epoch 00630: val_loss did not improve from 1.04342\n",
            "Epoch 631/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0234 - accuracy: 0.5526 - val_loss: 1.1057 - val_accuracy: 0.5333\n",
            "\n",
            "Epoch 00631: val_loss did not improve from 1.04342\n",
            "Epoch 632/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0244 - accuracy: 0.5546 - val_loss: 1.0871 - val_accuracy: 0.5481\n",
            "\n",
            "Epoch 00632: val_loss did not improve from 1.04342\n",
            "Epoch 633/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0023 - accuracy: 0.5696 - val_loss: 1.0871 - val_accuracy: 0.5423\n",
            "\n",
            "Epoch 00633: val_loss did not improve from 1.04342\n",
            "Epoch 634/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0041 - accuracy: 0.5594 - val_loss: 1.0691 - val_accuracy: 0.5506\n",
            "\n",
            "Epoch 00634: val_loss did not improve from 1.04342\n",
            "Epoch 635/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1.0175 - accuracy: 0.5662 - val_loss: 1.0733 - val_accuracy: 0.5442\n",
            "\n",
            "Epoch 00635: val_loss did not improve from 1.04342\n",
            "Epoch 636/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0418 - accuracy: 0.5455 - val_loss: 1.0686 - val_accuracy: 0.5429\n",
            "\n",
            "Epoch 00636: val_loss did not improve from 1.04342\n",
            "Epoch 637/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0138 - accuracy: 0.5525 - val_loss: 1.0753 - val_accuracy: 0.5481\n",
            "\n",
            "Epoch 00637: val_loss did not improve from 1.04342\n",
            "Epoch 638/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.9861 - accuracy: 0.5760 - val_loss: 1.0745 - val_accuracy: 0.5442\n",
            "\n",
            "Epoch 00638: val_loss did not improve from 1.04342\n",
            "Epoch 639/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9995 - accuracy: 0.5674 - val_loss: 1.0786 - val_accuracy: 0.5545\n",
            "\n",
            "Epoch 00639: val_loss did not improve from 1.04342\n",
            "Epoch 640/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0073 - accuracy: 0.5622 - val_loss: 1.0843 - val_accuracy: 0.5378\n",
            "\n",
            "Epoch 00640: val_loss did not improve from 1.04342\n",
            "Epoch 641/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0056 - accuracy: 0.5688 - val_loss: 1.0915 - val_accuracy: 0.5333\n",
            "\n",
            "Epoch 00641: val_loss did not improve from 1.04342\n",
            "Epoch 642/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0000 - accuracy: 0.5453 - val_loss: 1.0835 - val_accuracy: 0.5429\n",
            "\n",
            "Epoch 00642: val_loss did not improve from 1.04342\n",
            "Epoch 643/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0056 - accuracy: 0.5594 - val_loss: 1.0654 - val_accuracy: 0.5436\n",
            "\n",
            "Epoch 00643: val_loss did not improve from 1.04342\n",
            "Epoch 644/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1.0015 - accuracy: 0.5629 - val_loss: 1.0716 - val_accuracy: 0.5423\n",
            "\n",
            "Epoch 00644: val_loss did not improve from 1.04342\n",
            "Epoch 645/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0064 - accuracy: 0.5700 - val_loss: 1.0865 - val_accuracy: 0.5378\n",
            "\n",
            "Epoch 00645: val_loss did not improve from 1.04342\n",
            "Epoch 646/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0081 - accuracy: 0.5602 - val_loss: 1.0701 - val_accuracy: 0.5442\n",
            "\n",
            "Epoch 00646: val_loss did not improve from 1.04342\n",
            "Epoch 647/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0197 - accuracy: 0.5656 - val_loss: 1.0810 - val_accuracy: 0.5449\n",
            "\n",
            "Epoch 00647: val_loss did not improve from 1.04342\n",
            "Epoch 648/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0125 - accuracy: 0.5531 - val_loss: 1.0738 - val_accuracy: 0.5494\n",
            "\n",
            "Epoch 00648: val_loss did not improve from 1.04342\n",
            "Epoch 649/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9975 - accuracy: 0.5667 - val_loss: 1.0633 - val_accuracy: 0.5410\n",
            "\n",
            "Epoch 00649: val_loss did not improve from 1.04342\n",
            "Epoch 650/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0512 - accuracy: 0.5389 - val_loss: 1.0649 - val_accuracy: 0.5551\n",
            "\n",
            "Epoch 00650: val_loss did not improve from 1.04342\n",
            "Epoch 651/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0067 - accuracy: 0.5633 - val_loss: 1.0691 - val_accuracy: 0.5391\n",
            "\n",
            "Epoch 00651: val_loss did not improve from 1.04342\n",
            "Epoch 652/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0032 - accuracy: 0.5570 - val_loss: 1.1140 - val_accuracy: 0.5250\n",
            "\n",
            "Epoch 00652: val_loss did not improve from 1.04342\n",
            "Epoch 653/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1.0086 - accuracy: 0.5675 - val_loss: 1.0969 - val_accuracy: 0.5314\n",
            "\n",
            "Epoch 00653: val_loss did not improve from 1.04342\n",
            "Epoch 654/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9915 - accuracy: 0.5639 - val_loss: 1.0772 - val_accuracy: 0.5417\n",
            "\n",
            "Epoch 00654: val_loss did not improve from 1.04342\n",
            "Epoch 655/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0197 - accuracy: 0.5609 - val_loss: 1.1113 - val_accuracy: 0.5250\n",
            "\n",
            "Epoch 00655: val_loss did not improve from 1.04342\n",
            "Epoch 656/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0128 - accuracy: 0.5554 - val_loss: 1.1282 - val_accuracy: 0.5173\n",
            "\n",
            "Epoch 00656: val_loss did not improve from 1.04342\n",
            "Epoch 657/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0128 - accuracy: 0.5641 - val_loss: 1.0755 - val_accuracy: 0.5442\n",
            "\n",
            "Epoch 00657: val_loss did not improve from 1.04342\n",
            "Epoch 658/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0163 - accuracy: 0.5525 - val_loss: 1.0834 - val_accuracy: 0.5321\n",
            "\n",
            "Epoch 00658: val_loss did not improve from 1.04342\n",
            "Epoch 659/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0190 - accuracy: 0.5456 - val_loss: 1.0713 - val_accuracy: 0.5385\n",
            "\n",
            "Epoch 00659: val_loss did not improve from 1.04342\n",
            "Epoch 660/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0148 - accuracy: 0.5578 - val_loss: 1.0667 - val_accuracy: 0.5462\n",
            "\n",
            "Epoch 00660: val_loss did not improve from 1.04342\n",
            "Epoch 661/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9932 - accuracy: 0.5705 - val_loss: 1.0751 - val_accuracy: 0.5449\n",
            "\n",
            "Epoch 00661: val_loss did not improve from 1.04342\n",
            "Epoch 662/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0153 - accuracy: 0.5622 - val_loss: 1.0675 - val_accuracy: 0.5455\n",
            "\n",
            "Epoch 00662: val_loss did not improve from 1.04342\n",
            "Epoch 663/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9880 - accuracy: 0.5735 - val_loss: 1.0782 - val_accuracy: 0.5513\n",
            "\n",
            "Epoch 00663: val_loss did not improve from 1.04342\n",
            "Epoch 664/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9971 - accuracy: 0.5677 - val_loss: 1.0888 - val_accuracy: 0.5321\n",
            "\n",
            "Epoch 00664: val_loss did not improve from 1.04342\n",
            "Epoch 665/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0073 - accuracy: 0.5582 - val_loss: 1.0757 - val_accuracy: 0.5468\n",
            "\n",
            "Epoch 00665: val_loss did not improve from 1.04342\n",
            "Epoch 666/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9885 - accuracy: 0.5746 - val_loss: 1.0738 - val_accuracy: 0.5513\n",
            "\n",
            "Epoch 00666: val_loss did not improve from 1.04342\n",
            "Epoch 667/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0076 - accuracy: 0.5754 - val_loss: 1.0843 - val_accuracy: 0.5455\n",
            "\n",
            "Epoch 00667: val_loss did not improve from 1.04342\n",
            "Epoch 668/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1.0101 - accuracy: 0.5732 - val_loss: 1.0747 - val_accuracy: 0.5436\n",
            "\n",
            "Epoch 00668: val_loss did not improve from 1.04342\n",
            "Epoch 669/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0195 - accuracy: 0.5445 - val_loss: 1.0784 - val_accuracy: 0.5506\n",
            "\n",
            "Epoch 00669: val_loss did not improve from 1.04342\n",
            "Epoch 670/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0053 - accuracy: 0.5591 - val_loss: 1.0812 - val_accuracy: 0.5404\n",
            "\n",
            "Epoch 00670: val_loss did not improve from 1.04342\n",
            "Epoch 671/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0286 - accuracy: 0.5506 - val_loss: 1.0667 - val_accuracy: 0.5481\n",
            "\n",
            "Epoch 00671: val_loss did not improve from 1.04342\n",
            "Epoch 672/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0098 - accuracy: 0.5767 - val_loss: 1.0958 - val_accuracy: 0.5231\n",
            "\n",
            "Epoch 00672: val_loss did not improve from 1.04342\n",
            "Epoch 673/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0163 - accuracy: 0.5521 - val_loss: 1.0814 - val_accuracy: 0.5365\n",
            "\n",
            "Epoch 00673: val_loss did not improve from 1.04342\n",
            "Epoch 674/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9894 - accuracy: 0.5566 - val_loss: 1.0734 - val_accuracy: 0.5513\n",
            "\n",
            "Epoch 00674: val_loss did not improve from 1.04342\n",
            "Epoch 675/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9822 - accuracy: 0.5791 - val_loss: 1.0872 - val_accuracy: 0.5449\n",
            "\n",
            "Epoch 00675: val_loss did not improve from 1.04342\n",
            "Epoch 676/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1.0271 - accuracy: 0.5507 - val_loss: 1.0718 - val_accuracy: 0.5442\n",
            "\n",
            "Epoch 00676: val_loss did not improve from 1.04342\n",
            "Epoch 677/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0136 - accuracy: 0.5595 - val_loss: 1.0821 - val_accuracy: 0.5494\n",
            "\n",
            "Epoch 00677: val_loss did not improve from 1.04342\n",
            "Epoch 678/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0230 - accuracy: 0.5658 - val_loss: 1.1251 - val_accuracy: 0.5147\n",
            "\n",
            "Epoch 00678: val_loss did not improve from 1.04342\n",
            "Epoch 679/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0156 - accuracy: 0.5624 - val_loss: 1.1114 - val_accuracy: 0.5122\n",
            "\n",
            "Epoch 00679: val_loss did not improve from 1.04342\n",
            "Epoch 680/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9930 - accuracy: 0.5592 - val_loss: 1.1370 - val_accuracy: 0.4974\n",
            "\n",
            "Epoch 00680: val_loss did not improve from 1.04342\n",
            "Epoch 681/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0129 - accuracy: 0.5608 - val_loss: 1.0667 - val_accuracy: 0.5494\n",
            "\n",
            "Epoch 00681: val_loss did not improve from 1.04342\n",
            "Epoch 682/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0045 - accuracy: 0.5576 - val_loss: 1.0960 - val_accuracy: 0.5494\n",
            "\n",
            "Epoch 00682: val_loss did not improve from 1.04342\n",
            "Epoch 683/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0013 - accuracy: 0.5773 - val_loss: 1.1070 - val_accuracy: 0.5404\n",
            "\n",
            "Epoch 00683: val_loss did not improve from 1.04342\n",
            "Epoch 684/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0077 - accuracy: 0.5765 - val_loss: 1.0889 - val_accuracy: 0.5378\n",
            "\n",
            "Epoch 00684: val_loss did not improve from 1.04342\n",
            "Epoch 685/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9939 - accuracy: 0.5717 - val_loss: 1.0796 - val_accuracy: 0.5391\n",
            "\n",
            "Epoch 00685: val_loss did not improve from 1.04342\n",
            "Epoch 686/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0412 - accuracy: 0.5503 - val_loss: 1.0693 - val_accuracy: 0.5481\n",
            "\n",
            "Epoch 00686: val_loss did not improve from 1.04342\n",
            "Epoch 687/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9992 - accuracy: 0.5698 - val_loss: 1.0801 - val_accuracy: 0.5468\n",
            "\n",
            "Epoch 00687: val_loss did not improve from 1.04342\n",
            "Epoch 688/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.9896 - accuracy: 0.5777 - val_loss: 1.0684 - val_accuracy: 0.5378\n",
            "\n",
            "Epoch 00688: val_loss did not improve from 1.04342\n",
            "Epoch 689/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0250 - accuracy: 0.5524 - val_loss: 1.0705 - val_accuracy: 0.5558\n",
            "\n",
            "Epoch 00689: val_loss did not improve from 1.04342\n",
            "Epoch 690/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0038 - accuracy: 0.5687 - val_loss: 1.0667 - val_accuracy: 0.5481\n",
            "\n",
            "Epoch 00690: val_loss did not improve from 1.04342\n",
            "Epoch 691/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9942 - accuracy: 0.5688 - val_loss: 1.0909 - val_accuracy: 0.5391\n",
            "\n",
            "Epoch 00691: val_loss did not improve from 1.04342\n",
            "Epoch 692/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9983 - accuracy: 0.5663 - val_loss: 1.0832 - val_accuracy: 0.5244\n",
            "\n",
            "Epoch 00692: val_loss did not improve from 1.04342\n",
            "Epoch 693/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0009 - accuracy: 0.5615 - val_loss: 1.0687 - val_accuracy: 0.5429\n",
            "\n",
            "Epoch 00693: val_loss did not improve from 1.04342\n",
            "Epoch 694/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9988 - accuracy: 0.5718 - val_loss: 1.0779 - val_accuracy: 0.5474\n",
            "\n",
            "Epoch 00694: val_loss did not improve from 1.04342\n",
            "Epoch 695/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9951 - accuracy: 0.5809 - val_loss: 1.0758 - val_accuracy: 0.5410\n",
            "\n",
            "Epoch 00695: val_loss did not improve from 1.04342\n",
            "Epoch 696/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9966 - accuracy: 0.5755 - val_loss: 1.0752 - val_accuracy: 0.5449\n",
            "\n",
            "Epoch 00696: val_loss did not improve from 1.04342\n",
            "Epoch 697/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9897 - accuracy: 0.5696 - val_loss: 1.1043 - val_accuracy: 0.5301\n",
            "\n",
            "Epoch 00697: val_loss did not improve from 1.04342\n",
            "Epoch 698/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 1.0145 - accuracy: 0.5612 - val_loss: 1.0793 - val_accuracy: 0.5397\n",
            "\n",
            "Epoch 00698: val_loss did not improve from 1.04342\n",
            "Epoch 699/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.9923 - accuracy: 0.5709 - val_loss: 1.1184 - val_accuracy: 0.5103\n",
            "\n",
            "Epoch 00699: val_loss did not improve from 1.04342\n",
            "Epoch 700/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0148 - accuracy: 0.5353 - val_loss: 1.0710 - val_accuracy: 0.5481\n",
            "\n",
            "Epoch 00700: val_loss did not improve from 1.04342\n",
            "Epoch 701/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0003 - accuracy: 0.5612 - val_loss: 1.0784 - val_accuracy: 0.5500\n",
            "\n",
            "Epoch 00701: val_loss did not improve from 1.04342\n",
            "Epoch 702/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0051 - accuracy: 0.5661 - val_loss: 1.0680 - val_accuracy: 0.5417\n",
            "\n",
            "Epoch 00702: val_loss did not improve from 1.04342\n",
            "Epoch 703/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9975 - accuracy: 0.5696 - val_loss: 1.0857 - val_accuracy: 0.5429\n",
            "\n",
            "Epoch 00703: val_loss did not improve from 1.04342\n",
            "Epoch 704/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0137 - accuracy: 0.5586 - val_loss: 1.0808 - val_accuracy: 0.5519\n",
            "\n",
            "Epoch 00704: val_loss did not improve from 1.04342\n",
            "Epoch 705/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0020 - accuracy: 0.5635 - val_loss: 1.0713 - val_accuracy: 0.5436\n",
            "\n",
            "Epoch 00705: val_loss did not improve from 1.04342\n",
            "Epoch 706/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9961 - accuracy: 0.5802 - val_loss: 1.0835 - val_accuracy: 0.5455\n",
            "\n",
            "Epoch 00706: val_loss did not improve from 1.04342\n",
            "Epoch 707/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1.0070 - accuracy: 0.5701 - val_loss: 1.0842 - val_accuracy: 0.5500\n",
            "\n",
            "Epoch 00707: val_loss did not improve from 1.04342\n",
            "Epoch 708/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0086 - accuracy: 0.5578 - val_loss: 1.0839 - val_accuracy: 0.5417\n",
            "\n",
            "Epoch 00708: val_loss did not improve from 1.04342\n",
            "Epoch 709/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9943 - accuracy: 0.5740 - val_loss: 1.0733 - val_accuracy: 0.5545\n",
            "\n",
            "Epoch 00709: val_loss did not improve from 1.04342\n",
            "Epoch 710/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9972 - accuracy: 0.5717 - val_loss: 1.0741 - val_accuracy: 0.5564\n",
            "\n",
            "Epoch 00710: val_loss did not improve from 1.04342\n",
            "Epoch 711/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.9916 - accuracy: 0.5723 - val_loss: 1.0798 - val_accuracy: 0.5423\n",
            "\n",
            "Epoch 00711: val_loss did not improve from 1.04342\n",
            "Epoch 712/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0094 - accuracy: 0.5695 - val_loss: 1.0836 - val_accuracy: 0.5417\n",
            "\n",
            "Epoch 00712: val_loss did not improve from 1.04342\n",
            "Epoch 713/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0028 - accuracy: 0.5602 - val_loss: 1.0939 - val_accuracy: 0.5423\n",
            "\n",
            "Epoch 00713: val_loss did not improve from 1.04342\n",
            "Epoch 714/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0066 - accuracy: 0.5528 - val_loss: 1.0829 - val_accuracy: 0.5519\n",
            "\n",
            "Epoch 00714: val_loss did not improve from 1.04342\n",
            "Epoch 715/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9785 - accuracy: 0.5627 - val_loss: 1.0787 - val_accuracy: 0.5487\n",
            "\n",
            "Epoch 00715: val_loss did not improve from 1.04342\n",
            "Epoch 716/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0338 - accuracy: 0.5468 - val_loss: 1.0899 - val_accuracy: 0.5455\n",
            "\n",
            "Epoch 00716: val_loss did not improve from 1.04342\n",
            "Epoch 717/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0112 - accuracy: 0.5627 - val_loss: 1.0780 - val_accuracy: 0.5372\n",
            "\n",
            "Epoch 00717: val_loss did not improve from 1.04342\n",
            "Epoch 718/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9656 - accuracy: 0.5860 - val_loss: 1.0881 - val_accuracy: 0.5564\n",
            "\n",
            "Epoch 00718: val_loss did not improve from 1.04342\n",
            "Epoch 719/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9879 - accuracy: 0.5675 - val_loss: 1.0685 - val_accuracy: 0.5391\n",
            "\n",
            "Epoch 00719: val_loss did not improve from 1.04342\n",
            "Epoch 720/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0101 - accuracy: 0.5662 - val_loss: 1.0775 - val_accuracy: 0.5538\n",
            "\n",
            "Epoch 00720: val_loss did not improve from 1.04342\n",
            "Epoch 721/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9807 - accuracy: 0.5738 - val_loss: 1.0776 - val_accuracy: 0.5538\n",
            "\n",
            "Epoch 00721: val_loss did not improve from 1.04342\n",
            "Epoch 722/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1.0170 - accuracy: 0.5631 - val_loss: 1.0647 - val_accuracy: 0.5603\n",
            "\n",
            "Epoch 00722: val_loss did not improve from 1.04342\n",
            "Epoch 723/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0269 - accuracy: 0.5483 - val_loss: 1.0784 - val_accuracy: 0.5481\n",
            "\n",
            "Epoch 00723: val_loss did not improve from 1.04342\n",
            "Epoch 724/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0236 - accuracy: 0.5682 - val_loss: 1.0762 - val_accuracy: 0.5455\n",
            "\n",
            "Epoch 00724: val_loss did not improve from 1.04342\n",
            "Epoch 725/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9813 - accuracy: 0.5920 - val_loss: 1.1068 - val_accuracy: 0.5333\n",
            "\n",
            "Epoch 00725: val_loss did not improve from 1.04342\n",
            "Epoch 726/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0088 - accuracy: 0.5625 - val_loss: 1.1004 - val_accuracy: 0.5359\n",
            "\n",
            "Epoch 00726: val_loss did not improve from 1.04342\n",
            "Epoch 727/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0461 - accuracy: 0.5500 - val_loss: 1.0729 - val_accuracy: 0.5506\n",
            "\n",
            "Epoch 00727: val_loss did not improve from 1.04342\n",
            "Epoch 728/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.9954 - accuracy: 0.5706 - val_loss: 1.0767 - val_accuracy: 0.5442\n",
            "\n",
            "Epoch 00728: val_loss did not improve from 1.04342\n",
            "Epoch 729/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9803 - accuracy: 0.5764 - val_loss: 1.0755 - val_accuracy: 0.5423\n",
            "\n",
            "Epoch 00729: val_loss did not improve from 1.04342\n",
            "Epoch 730/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.9943 - accuracy: 0.5616 - val_loss: 1.0760 - val_accuracy: 0.5494\n",
            "\n",
            "Epoch 00730: val_loss did not improve from 1.04342\n",
            "Epoch 731/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9926 - accuracy: 0.5615 - val_loss: 1.0993 - val_accuracy: 0.5468\n",
            "\n",
            "Epoch 00731: val_loss did not improve from 1.04342\n",
            "Epoch 732/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0039 - accuracy: 0.5679 - val_loss: 1.0935 - val_accuracy: 0.5385\n",
            "\n",
            "Epoch 00732: val_loss did not improve from 1.04342\n",
            "Epoch 733/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9997 - accuracy: 0.5636 - val_loss: 1.0865 - val_accuracy: 0.5455\n",
            "\n",
            "Epoch 00733: val_loss did not improve from 1.04342\n",
            "Epoch 734/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9919 - accuracy: 0.5709 - val_loss: 1.0783 - val_accuracy: 0.5404\n",
            "\n",
            "Epoch 00734: val_loss did not improve from 1.04342\n",
            "Epoch 735/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.9920 - accuracy: 0.5726 - val_loss: 1.0689 - val_accuracy: 0.5449\n",
            "\n",
            "Epoch 00735: val_loss did not improve from 1.04342\n",
            "Epoch 736/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9906 - accuracy: 0.5703 - val_loss: 1.1047 - val_accuracy: 0.5256\n",
            "\n",
            "Epoch 00736: val_loss did not improve from 1.04342\n",
            "Epoch 737/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9933 - accuracy: 0.5630 - val_loss: 1.0951 - val_accuracy: 0.5244\n",
            "\n",
            "Epoch 00737: val_loss did not improve from 1.04342\n",
            "Epoch 738/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1.0122 - accuracy: 0.5488 - val_loss: 1.0858 - val_accuracy: 0.5494\n",
            "\n",
            "Epoch 00738: val_loss did not improve from 1.04342\n",
            "Epoch 739/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 1.0081 - accuracy: 0.5572 - val_loss: 1.0682 - val_accuracy: 0.5442\n",
            "\n",
            "Epoch 00739: val_loss did not improve from 1.04342\n",
            "Epoch 740/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1.0192 - accuracy: 0.5523 - val_loss: 1.1201 - val_accuracy: 0.5256\n",
            "\n",
            "Epoch 00740: val_loss did not improve from 1.04342\n",
            "Epoch 741/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9991 - accuracy: 0.5718 - val_loss: 1.0777 - val_accuracy: 0.5462\n",
            "\n",
            "Epoch 00741: val_loss did not improve from 1.04342\n",
            "Epoch 742/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0132 - accuracy: 0.5663 - val_loss: 1.0950 - val_accuracy: 0.5340\n",
            "\n",
            "Epoch 00742: val_loss did not improve from 1.04342\n",
            "Epoch 743/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0081 - accuracy: 0.5606 - val_loss: 1.0803 - val_accuracy: 0.5474\n",
            "\n",
            "Epoch 00743: val_loss did not improve from 1.04342\n",
            "Epoch 744/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.9966 - accuracy: 0.5648 - val_loss: 1.0719 - val_accuracy: 0.5538\n",
            "\n",
            "Epoch 00744: val_loss did not improve from 1.04342\n",
            "Epoch 745/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9973 - accuracy: 0.5785 - val_loss: 1.0727 - val_accuracy: 0.5506\n",
            "\n",
            "Epoch 00745: val_loss did not improve from 1.04342\n",
            "Epoch 746/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9790 - accuracy: 0.5756 - val_loss: 1.0762 - val_accuracy: 0.5538\n",
            "\n",
            "Epoch 00746: val_loss did not improve from 1.04342\n",
            "Epoch 747/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0000 - accuracy: 0.5710 - val_loss: 1.0867 - val_accuracy: 0.5468\n",
            "\n",
            "Epoch 00747: val_loss did not improve from 1.04342\n",
            "Epoch 748/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0257 - accuracy: 0.5628 - val_loss: 1.0728 - val_accuracy: 0.5519\n",
            "\n",
            "Epoch 00748: val_loss did not improve from 1.04342\n",
            "Epoch 749/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1.0066 - accuracy: 0.5680 - val_loss: 1.1210 - val_accuracy: 0.5141\n",
            "\n",
            "Epoch 00749: val_loss did not improve from 1.04342\n",
            "Epoch 750/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0207 - accuracy: 0.5484 - val_loss: 1.0780 - val_accuracy: 0.5359\n",
            "\n",
            "Epoch 00750: val_loss did not improve from 1.04342\n",
            "Epoch 751/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9894 - accuracy: 0.5759 - val_loss: 1.0748 - val_accuracy: 0.5481\n",
            "\n",
            "Epoch 00751: val_loss did not improve from 1.04342\n",
            "Epoch 752/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.9818 - accuracy: 0.5634 - val_loss: 1.0733 - val_accuracy: 0.5423\n",
            "\n",
            "Epoch 00752: val_loss did not improve from 1.04342\n",
            "Epoch 753/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 1.0081 - accuracy: 0.5568 - val_loss: 1.0848 - val_accuracy: 0.5551\n",
            "\n",
            "Epoch 00753: val_loss did not improve from 1.04342\n",
            "Epoch 754/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0040 - accuracy: 0.5720 - val_loss: 1.0735 - val_accuracy: 0.5436\n",
            "\n",
            "Epoch 00754: val_loss did not improve from 1.04342\n",
            "Epoch 755/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9865 - accuracy: 0.5891 - val_loss: 1.1072 - val_accuracy: 0.5333\n",
            "\n",
            "Epoch 00755: val_loss did not improve from 1.04342\n",
            "Epoch 756/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0180 - accuracy: 0.5487 - val_loss: 1.0809 - val_accuracy: 0.5462\n",
            "\n",
            "Epoch 00756: val_loss did not improve from 1.04342\n",
            "Epoch 757/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9936 - accuracy: 0.5645 - val_loss: 1.0862 - val_accuracy: 0.5263\n",
            "\n",
            "Epoch 00757: val_loss did not improve from 1.04342\n",
            "Epoch 758/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9812 - accuracy: 0.5871 - val_loss: 1.0892 - val_accuracy: 0.5449\n",
            "\n",
            "Epoch 00758: val_loss did not improve from 1.04342\n",
            "Epoch 759/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1.0042 - accuracy: 0.5679 - val_loss: 1.0816 - val_accuracy: 0.5468\n",
            "\n",
            "Epoch 00759: val_loss did not improve from 1.04342\n",
            "Epoch 760/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.9895 - accuracy: 0.5757 - val_loss: 1.0895 - val_accuracy: 0.5237\n",
            "\n",
            "Epoch 00760: val_loss did not improve from 1.04342\n",
            "Epoch 761/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0420 - accuracy: 0.5439 - val_loss: 1.1107 - val_accuracy: 0.5244\n",
            "\n",
            "Epoch 00761: val_loss did not improve from 1.04342\n",
            "Epoch 762/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9992 - accuracy: 0.5693 - val_loss: 1.0808 - val_accuracy: 0.5494\n",
            "\n",
            "Epoch 00762: val_loss did not improve from 1.04342\n",
            "Epoch 763/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9958 - accuracy: 0.5870 - val_loss: 1.0805 - val_accuracy: 0.5481\n",
            "\n",
            "Epoch 00763: val_loss did not improve from 1.04342\n",
            "Epoch 764/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9712 - accuracy: 0.5784 - val_loss: 1.0985 - val_accuracy: 0.5385\n",
            "\n",
            "Epoch 00764: val_loss did not improve from 1.04342\n",
            "Epoch 765/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.9872 - accuracy: 0.5765 - val_loss: 1.1212 - val_accuracy: 0.5269\n",
            "\n",
            "Epoch 00765: val_loss did not improve from 1.04342\n",
            "Epoch 766/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 0.9953 - accuracy: 0.5753 - val_loss: 1.0962 - val_accuracy: 0.5417\n",
            "\n",
            "Epoch 00766: val_loss did not improve from 1.04342\n",
            "Epoch 767/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1.0068 - accuracy: 0.5744 - val_loss: 1.0925 - val_accuracy: 0.5500\n",
            "\n",
            "Epoch 00767: val_loss did not improve from 1.04342\n",
            "Epoch 768/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9707 - accuracy: 0.5847 - val_loss: 1.0849 - val_accuracy: 0.5481\n",
            "\n",
            "Epoch 00768: val_loss did not improve from 1.04342\n",
            "Epoch 769/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9908 - accuracy: 0.5856 - val_loss: 1.0948 - val_accuracy: 0.5276\n",
            "\n",
            "Epoch 00769: val_loss did not improve from 1.04342\n",
            "Epoch 770/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0035 - accuracy: 0.5706 - val_loss: 1.0885 - val_accuracy: 0.5462\n",
            "\n",
            "Epoch 00770: val_loss did not improve from 1.04342\n",
            "Epoch 771/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1.0043 - accuracy: 0.5645 - val_loss: 1.0980 - val_accuracy: 0.5263\n",
            "\n",
            "Epoch 00771: val_loss did not improve from 1.04342\n",
            "Epoch 772/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1.0072 - accuracy: 0.5652 - val_loss: 1.0893 - val_accuracy: 0.5417\n",
            "\n",
            "Epoch 00772: val_loss did not improve from 1.04342\n",
            "Epoch 773/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9856 - accuracy: 0.5809 - val_loss: 1.1206 - val_accuracy: 0.5295\n",
            "\n",
            "Epoch 00773: val_loss did not improve from 1.04342\n",
            "Epoch 774/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0151 - accuracy: 0.5569 - val_loss: 1.0797 - val_accuracy: 0.5468\n",
            "\n",
            "Epoch 00774: val_loss did not improve from 1.04342\n",
            "Epoch 775/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0031 - accuracy: 0.5612 - val_loss: 1.0780 - val_accuracy: 0.5455\n",
            "\n",
            "Epoch 00775: val_loss did not improve from 1.04342\n",
            "Epoch 776/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0226 - accuracy: 0.5647 - val_loss: 1.0827 - val_accuracy: 0.5487\n",
            "\n",
            "Epoch 00776: val_loss did not improve from 1.04342\n",
            "Epoch 777/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9847 - accuracy: 0.5694 - val_loss: 1.0831 - val_accuracy: 0.5378\n",
            "\n",
            "Epoch 00777: val_loss did not improve from 1.04342\n",
            "Epoch 778/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0150 - accuracy: 0.5556 - val_loss: 1.0912 - val_accuracy: 0.5385\n",
            "\n",
            "Epoch 00778: val_loss did not improve from 1.04342\n",
            "Epoch 779/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9965 - accuracy: 0.5815 - val_loss: 1.0819 - val_accuracy: 0.5404\n",
            "\n",
            "Epoch 00779: val_loss did not improve from 1.04342\n",
            "Epoch 780/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9986 - accuracy: 0.5532 - val_loss: 1.0615 - val_accuracy: 0.5590\n",
            "\n",
            "Epoch 00780: val_loss did not improve from 1.04342\n",
            "Epoch 781/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9946 - accuracy: 0.5850 - val_loss: 1.0893 - val_accuracy: 0.5532\n",
            "\n",
            "Epoch 00781: val_loss did not improve from 1.04342\n",
            "Epoch 782/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9976 - accuracy: 0.5768 - val_loss: 1.0851 - val_accuracy: 0.5436\n",
            "\n",
            "Epoch 00782: val_loss did not improve from 1.04342\n",
            "Epoch 783/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9898 - accuracy: 0.5877 - val_loss: 1.1060 - val_accuracy: 0.5378\n",
            "\n",
            "Epoch 00783: val_loss did not improve from 1.04342\n",
            "Epoch 784/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0160 - accuracy: 0.5683 - val_loss: 1.1194 - val_accuracy: 0.5282\n",
            "\n",
            "Epoch 00784: val_loss did not improve from 1.04342\n",
            "Epoch 785/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9868 - accuracy: 0.5688 - val_loss: 1.0770 - val_accuracy: 0.5526\n",
            "\n",
            "Epoch 00785: val_loss did not improve from 1.04342\n",
            "Epoch 786/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1.0174 - accuracy: 0.5662 - val_loss: 1.0826 - val_accuracy: 0.5596\n",
            "\n",
            "Epoch 00786: val_loss did not improve from 1.04342\n",
            "Epoch 787/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0053 - accuracy: 0.5607 - val_loss: 1.1037 - val_accuracy: 0.5391\n",
            "\n",
            "Epoch 00787: val_loss did not improve from 1.04342\n",
            "Epoch 788/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9898 - accuracy: 0.5847 - val_loss: 1.0677 - val_accuracy: 0.5532\n",
            "\n",
            "Epoch 00788: val_loss did not improve from 1.04342\n",
            "Epoch 789/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.9894 - accuracy: 0.5738 - val_loss: 1.0705 - val_accuracy: 0.5500\n",
            "\n",
            "Epoch 00789: val_loss did not improve from 1.04342\n",
            "Epoch 790/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9915 - accuracy: 0.5635 - val_loss: 1.0759 - val_accuracy: 0.5551\n",
            "\n",
            "Epoch 00790: val_loss did not improve from 1.04342\n",
            "Epoch 791/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0035 - accuracy: 0.5653 - val_loss: 1.0942 - val_accuracy: 0.5372\n",
            "\n",
            "Epoch 00791: val_loss did not improve from 1.04342\n",
            "Epoch 792/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0126 - accuracy: 0.5667 - val_loss: 1.0682 - val_accuracy: 0.5538\n",
            "\n",
            "Epoch 00792: val_loss did not improve from 1.04342\n",
            "Epoch 793/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.9793 - accuracy: 0.5602 - val_loss: 1.1098 - val_accuracy: 0.5353\n",
            "\n",
            "Epoch 00793: val_loss did not improve from 1.04342\n",
            "Epoch 794/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9845 - accuracy: 0.5759 - val_loss: 1.0972 - val_accuracy: 0.5436\n",
            "\n",
            "Epoch 00794: val_loss did not improve from 1.04342\n",
            "Epoch 795/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9742 - accuracy: 0.5869 - val_loss: 1.0791 - val_accuracy: 0.5513\n",
            "\n",
            "Epoch 00795: val_loss did not improve from 1.04342\n",
            "Epoch 796/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.9990 - accuracy: 0.5593 - val_loss: 1.0836 - val_accuracy: 0.5429\n",
            "\n",
            "Epoch 00796: val_loss did not improve from 1.04342\n",
            "Epoch 797/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.9946 - accuracy: 0.5648 - val_loss: 1.0820 - val_accuracy: 0.5404\n",
            "\n",
            "Epoch 00797: val_loss did not improve from 1.04342\n",
            "Epoch 798/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0154 - accuracy: 0.5800 - val_loss: 1.0717 - val_accuracy: 0.5558\n",
            "\n",
            "Epoch 00798: val_loss did not improve from 1.04342\n",
            "Epoch 799/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0161 - accuracy: 0.5715 - val_loss: 1.0751 - val_accuracy: 0.5462\n",
            "\n",
            "Epoch 00799: val_loss did not improve from 1.04342\n",
            "Epoch 800/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.9679 - accuracy: 0.5835 - val_loss: 1.0976 - val_accuracy: 0.5410\n",
            "\n",
            "Epoch 00800: val_loss did not improve from 1.04342\n",
            "Epoch 801/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0202 - accuracy: 0.5556 - val_loss: 1.0846 - val_accuracy: 0.5269\n",
            "\n",
            "Epoch 00801: val_loss did not improve from 1.04342\n",
            "Epoch 802/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0120 - accuracy: 0.5629 - val_loss: 1.0932 - val_accuracy: 0.5455\n",
            "\n",
            "Epoch 00802: val_loss did not improve from 1.04342\n",
            "Epoch 803/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0000 - accuracy: 0.5667 - val_loss: 1.0909 - val_accuracy: 0.5449\n",
            "\n",
            "Epoch 00803: val_loss did not improve from 1.04342\n",
            "Epoch 804/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0025 - accuracy: 0.5712 - val_loss: 1.0922 - val_accuracy: 0.5314\n",
            "\n",
            "Epoch 00804: val_loss did not improve from 1.04342\n",
            "Epoch 805/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9881 - accuracy: 0.5820 - val_loss: 1.0784 - val_accuracy: 0.5526\n",
            "\n",
            "Epoch 00805: val_loss did not improve from 1.04342\n",
            "Epoch 806/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9666 - accuracy: 0.5760 - val_loss: 1.1428 - val_accuracy: 0.5346\n",
            "\n",
            "Epoch 00806: val_loss did not improve from 1.04342\n",
            "Epoch 807/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.9970 - accuracy: 0.5878 - val_loss: 1.0743 - val_accuracy: 0.5455\n",
            "\n",
            "Epoch 00807: val_loss did not improve from 1.04342\n",
            "Epoch 808/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1.0251 - accuracy: 0.5782 - val_loss: 1.0993 - val_accuracy: 0.5462\n",
            "\n",
            "Epoch 00808: val_loss did not improve from 1.04342\n",
            "Epoch 809/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.9829 - accuracy: 0.5668 - val_loss: 1.0801 - val_accuracy: 0.5494\n",
            "\n",
            "Epoch 00809: val_loss did not improve from 1.04342\n",
            "Epoch 810/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9905 - accuracy: 0.5804 - val_loss: 1.0968 - val_accuracy: 0.5558\n",
            "\n",
            "Epoch 00810: val_loss did not improve from 1.04342\n",
            "Epoch 811/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9753 - accuracy: 0.5787 - val_loss: 1.0846 - val_accuracy: 0.5449\n",
            "\n",
            "Epoch 00811: val_loss did not improve from 1.04342\n",
            "Epoch 812/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9716 - accuracy: 0.5869 - val_loss: 1.0801 - val_accuracy: 0.5603\n",
            "\n",
            "Epoch 00812: val_loss did not improve from 1.04342\n",
            "Epoch 813/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9997 - accuracy: 0.5702 - val_loss: 1.0927 - val_accuracy: 0.5423\n",
            "\n",
            "Epoch 00813: val_loss did not improve from 1.04342\n",
            "Epoch 814/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0020 - accuracy: 0.5694 - val_loss: 1.0740 - val_accuracy: 0.5455\n",
            "\n",
            "Epoch 00814: val_loss did not improve from 1.04342\n",
            "Epoch 815/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9586 - accuracy: 0.5970 - val_loss: 1.1007 - val_accuracy: 0.5321\n",
            "\n",
            "Epoch 00815: val_loss did not improve from 1.04342\n",
            "Epoch 816/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9880 - accuracy: 0.5604 - val_loss: 1.0913 - val_accuracy: 0.5404\n",
            "\n",
            "Epoch 00816: val_loss did not improve from 1.04342\n",
            "Epoch 817/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9935 - accuracy: 0.5834 - val_loss: 1.0894 - val_accuracy: 0.5474\n",
            "\n",
            "Epoch 00817: val_loss did not improve from 1.04342\n",
            "Epoch 818/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9817 - accuracy: 0.5788 - val_loss: 1.0827 - val_accuracy: 0.5404\n",
            "\n",
            "Epoch 00818: val_loss did not improve from 1.04342\n",
            "Epoch 819/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1.0046 - accuracy: 0.5777 - val_loss: 1.0938 - val_accuracy: 0.5385\n",
            "\n",
            "Epoch 00819: val_loss did not improve from 1.04342\n",
            "Epoch 820/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9898 - accuracy: 0.5746 - val_loss: 1.0989 - val_accuracy: 0.5340\n",
            "\n",
            "Epoch 00820: val_loss did not improve from 1.04342\n",
            "Epoch 821/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9857 - accuracy: 0.5770 - val_loss: 1.0902 - val_accuracy: 0.5410\n",
            "\n",
            "Epoch 00821: val_loss did not improve from 1.04342\n",
            "Epoch 822/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0076 - accuracy: 0.5613 - val_loss: 1.1000 - val_accuracy: 0.5429\n",
            "\n",
            "Epoch 00822: val_loss did not improve from 1.04342\n",
            "Epoch 823/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0005 - accuracy: 0.5726 - val_loss: 1.0936 - val_accuracy: 0.5551\n",
            "\n",
            "Epoch 00823: val_loss did not improve from 1.04342\n",
            "Epoch 824/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.9969 - accuracy: 0.5634 - val_loss: 1.0833 - val_accuracy: 0.5519\n",
            "\n",
            "Epoch 00824: val_loss did not improve from 1.04342\n",
            "Epoch 825/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9769 - accuracy: 0.5827 - val_loss: 1.0760 - val_accuracy: 0.5449\n",
            "\n",
            "Epoch 00825: val_loss did not improve from 1.04342\n",
            "Epoch 826/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.9898 - accuracy: 0.5710 - val_loss: 1.0943 - val_accuracy: 0.5449\n",
            "\n",
            "Epoch 00826: val_loss did not improve from 1.04342\n",
            "Epoch 827/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9952 - accuracy: 0.5626 - val_loss: 1.0924 - val_accuracy: 0.5494\n",
            "\n",
            "Epoch 00827: val_loss did not improve from 1.04342\n",
            "Epoch 828/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9869 - accuracy: 0.5644 - val_loss: 1.0799 - val_accuracy: 0.5583\n",
            "\n",
            "Epoch 00828: val_loss did not improve from 1.04342\n",
            "Epoch 829/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1.0150 - accuracy: 0.5784 - val_loss: 1.0826 - val_accuracy: 0.5481\n",
            "\n",
            "Epoch 00829: val_loss did not improve from 1.04342\n",
            "Epoch 830/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9906 - accuracy: 0.5786 - val_loss: 1.0993 - val_accuracy: 0.5282\n",
            "\n",
            "Epoch 00830: val_loss did not improve from 1.04342\n",
            "Epoch 831/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9850 - accuracy: 0.5716 - val_loss: 1.0947 - val_accuracy: 0.5378\n",
            "\n",
            "Epoch 00831: val_loss did not improve from 1.04342\n",
            "Epoch 832/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0105 - accuracy: 0.5733 - val_loss: 1.0756 - val_accuracy: 0.5506\n",
            "\n",
            "Epoch 00832: val_loss did not improve from 1.04342\n",
            "Epoch 833/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.9887 - accuracy: 0.5698 - val_loss: 1.0757 - val_accuracy: 0.5558\n",
            "\n",
            "Epoch 00833: val_loss did not improve from 1.04342\n",
            "Epoch 834/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.9761 - accuracy: 0.5743 - val_loss: 1.0805 - val_accuracy: 0.5462\n",
            "\n",
            "Epoch 00834: val_loss did not improve from 1.04342\n",
            "Epoch 835/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0063 - accuracy: 0.5742 - val_loss: 1.0893 - val_accuracy: 0.5429\n",
            "\n",
            "Epoch 00835: val_loss did not improve from 1.04342\n",
            "Epoch 836/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.9881 - accuracy: 0.5676 - val_loss: 1.0790 - val_accuracy: 0.5423\n",
            "\n",
            "Epoch 00836: val_loss did not improve from 1.04342\n",
            "Epoch 837/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0122 - accuracy: 0.5696 - val_loss: 1.0842 - val_accuracy: 0.5506\n",
            "\n",
            "Epoch 00837: val_loss did not improve from 1.04342\n",
            "Epoch 838/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1.0108 - accuracy: 0.5690 - val_loss: 1.1187 - val_accuracy: 0.5288\n",
            "\n",
            "Epoch 00838: val_loss did not improve from 1.04342\n",
            "Epoch 839/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1.0040 - accuracy: 0.5723 - val_loss: 1.0710 - val_accuracy: 0.5513\n",
            "\n",
            "Epoch 00839: val_loss did not improve from 1.04342\n",
            "Epoch 840/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1.0104 - accuracy: 0.5688 - val_loss: 1.0632 - val_accuracy: 0.5571\n",
            "\n",
            "Epoch 00840: val_loss did not improve from 1.04342\n",
            "Epoch 841/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9752 - accuracy: 0.5749 - val_loss: 1.0873 - val_accuracy: 0.5481\n",
            "\n",
            "Epoch 00841: val_loss did not improve from 1.04342\n",
            "Epoch 842/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.9720 - accuracy: 0.5992 - val_loss: 1.0829 - val_accuracy: 0.5410\n",
            "\n",
            "Epoch 00842: val_loss did not improve from 1.04342\n",
            "Epoch 843/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9868 - accuracy: 0.5860 - val_loss: 1.0916 - val_accuracy: 0.5538\n",
            "\n",
            "Epoch 00843: val_loss did not improve from 1.04342\n",
            "Epoch 844/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0038 - accuracy: 0.5644 - val_loss: 1.0842 - val_accuracy: 0.5481\n",
            "\n",
            "Epoch 00844: val_loss did not improve from 1.04342\n",
            "Epoch 845/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.9978 - accuracy: 0.5701 - val_loss: 1.0906 - val_accuracy: 0.5449\n",
            "\n",
            "Epoch 00845: val_loss did not improve from 1.04342\n",
            "Epoch 846/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.9874 - accuracy: 0.5681 - val_loss: 1.1012 - val_accuracy: 0.5410\n",
            "\n",
            "Epoch 00846: val_loss did not improve from 1.04342\n",
            "Epoch 847/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9963 - accuracy: 0.5632 - val_loss: 1.0866 - val_accuracy: 0.5468\n",
            "\n",
            "Epoch 00847: val_loss did not improve from 1.04342\n",
            "Epoch 848/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9889 - accuracy: 0.5703 - val_loss: 1.1334 - val_accuracy: 0.5365\n",
            "\n",
            "Epoch 00848: val_loss did not improve from 1.04342\n",
            "Epoch 849/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1.0027 - accuracy: 0.5735 - val_loss: 1.1043 - val_accuracy: 0.5429\n",
            "\n",
            "Epoch 00849: val_loss did not improve from 1.04342\n",
            "Epoch 850/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9885 - accuracy: 0.5743 - val_loss: 1.0833 - val_accuracy: 0.5429\n",
            "\n",
            "Epoch 00850: val_loss did not improve from 1.04342\n",
            "Epoch 851/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1.0114 - accuracy: 0.5660 - val_loss: 1.0736 - val_accuracy: 0.5494\n",
            "\n",
            "Epoch 00851: val_loss did not improve from 1.04342\n",
            "Epoch 852/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.9805 - accuracy: 0.5841 - val_loss: 1.0986 - val_accuracy: 0.5474\n",
            "\n",
            "Epoch 00852: val_loss did not improve from 1.04342\n",
            "Epoch 853/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0000 - accuracy: 0.5787 - val_loss: 1.0816 - val_accuracy: 0.5519\n",
            "\n",
            "Epoch 00853: val_loss did not improve from 1.04342\n",
            "Epoch 854/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9914 - accuracy: 0.5651 - val_loss: 1.0769 - val_accuracy: 0.5494\n",
            "\n",
            "Epoch 00854: val_loss did not improve from 1.04342\n",
            "Epoch 855/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1.0080 - accuracy: 0.5531 - val_loss: 1.0897 - val_accuracy: 0.5359\n",
            "\n",
            "Epoch 00855: val_loss did not improve from 1.04342\n",
            "Epoch 856/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9724 - accuracy: 0.5862 - val_loss: 1.0733 - val_accuracy: 0.5500\n",
            "\n",
            "Epoch 00856: val_loss did not improve from 1.04342\n",
            "Epoch 857/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9957 - accuracy: 0.5658 - val_loss: 1.0736 - val_accuracy: 0.5571\n",
            "\n",
            "Epoch 00857: val_loss did not improve from 1.04342\n",
            "Epoch 858/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9862 - accuracy: 0.5713 - val_loss: 1.0765 - val_accuracy: 0.5506\n",
            "\n",
            "Epoch 00858: val_loss did not improve from 1.04342\n",
            "Epoch 859/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9926 - accuracy: 0.5762 - val_loss: 1.0779 - val_accuracy: 0.5487\n",
            "\n",
            "Epoch 00859: val_loss did not improve from 1.04342\n",
            "Epoch 860/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9618 - accuracy: 0.5876 - val_loss: 1.0894 - val_accuracy: 0.5449\n",
            "\n",
            "Epoch 00860: val_loss did not improve from 1.04342\n",
            "Epoch 861/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9943 - accuracy: 0.5779 - val_loss: 1.0810 - val_accuracy: 0.5442\n",
            "\n",
            "Epoch 00861: val_loss did not improve from 1.04342\n",
            "Epoch 862/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9880 - accuracy: 0.5794 - val_loss: 1.0940 - val_accuracy: 0.5551\n",
            "\n",
            "Epoch 00862: val_loss did not improve from 1.04342\n",
            "Epoch 863/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9969 - accuracy: 0.5814 - val_loss: 1.0855 - val_accuracy: 0.5590\n",
            "\n",
            "Epoch 00863: val_loss did not improve from 1.04342\n",
            "Epoch 864/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9809 - accuracy: 0.5713 - val_loss: 1.0857 - val_accuracy: 0.5519\n",
            "\n",
            "Epoch 00864: val_loss did not improve from 1.04342\n",
            "Epoch 865/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9927 - accuracy: 0.5622 - val_loss: 1.0937 - val_accuracy: 0.5571\n",
            "\n",
            "Epoch 00865: val_loss did not improve from 1.04342\n",
            "Epoch 866/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9675 - accuracy: 0.5819 - val_loss: 1.0842 - val_accuracy: 0.5494\n",
            "\n",
            "Epoch 00866: val_loss did not improve from 1.04342\n",
            "Epoch 867/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9911 - accuracy: 0.5790 - val_loss: 1.0801 - val_accuracy: 0.5442\n",
            "\n",
            "Epoch 00867: val_loss did not improve from 1.04342\n",
            "Epoch 868/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.9999 - accuracy: 0.5691 - val_loss: 1.0970 - val_accuracy: 0.5462\n",
            "\n",
            "Epoch 00868: val_loss did not improve from 1.04342\n",
            "Epoch 869/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0019 - accuracy: 0.5669 - val_loss: 1.0866 - val_accuracy: 0.5494\n",
            "\n",
            "Epoch 00869: val_loss did not improve from 1.04342\n",
            "Epoch 870/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0185 - accuracy: 0.5665 - val_loss: 1.0943 - val_accuracy: 0.5314\n",
            "\n",
            "Epoch 00870: val_loss did not improve from 1.04342\n",
            "Epoch 871/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9957 - accuracy: 0.5646 - val_loss: 1.0921 - val_accuracy: 0.5571\n",
            "\n",
            "Epoch 00871: val_loss did not improve from 1.04342\n",
            "Epoch 872/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.9986 - accuracy: 0.5807 - val_loss: 1.0978 - val_accuracy: 0.5397\n",
            "\n",
            "Epoch 00872: val_loss did not improve from 1.04342\n",
            "Epoch 873/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0004 - accuracy: 0.5682 - val_loss: 1.0761 - val_accuracy: 0.5558\n",
            "\n",
            "Epoch 00873: val_loss did not improve from 1.04342\n",
            "Epoch 874/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9731 - accuracy: 0.5673 - val_loss: 1.0872 - val_accuracy: 0.5429\n",
            "\n",
            "Epoch 00874: val_loss did not improve from 1.04342\n",
            "Epoch 875/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9897 - accuracy: 0.5814 - val_loss: 1.0851 - val_accuracy: 0.5577\n",
            "\n",
            "Epoch 00875: val_loss did not improve from 1.04342\n",
            "Epoch 876/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9821 - accuracy: 0.5778 - val_loss: 1.0876 - val_accuracy: 0.5551\n",
            "\n",
            "Epoch 00876: val_loss did not improve from 1.04342\n",
            "Epoch 877/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9735 - accuracy: 0.5762 - val_loss: 1.0812 - val_accuracy: 0.5455\n",
            "\n",
            "Epoch 00877: val_loss did not improve from 1.04342\n",
            "Epoch 878/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0062 - accuracy: 0.5668 - val_loss: 1.0914 - val_accuracy: 0.5545\n",
            "\n",
            "Epoch 00878: val_loss did not improve from 1.04342\n",
            "Epoch 879/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9915 - accuracy: 0.5720 - val_loss: 1.0914 - val_accuracy: 0.5449\n",
            "\n",
            "Epoch 00879: val_loss did not improve from 1.04342\n",
            "Epoch 880/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.9888 - accuracy: 0.5752 - val_loss: 1.0828 - val_accuracy: 0.5506\n",
            "\n",
            "Epoch 00880: val_loss did not improve from 1.04342\n",
            "Epoch 881/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9879 - accuracy: 0.5786 - val_loss: 1.0903 - val_accuracy: 0.5519\n",
            "\n",
            "Epoch 00881: val_loss did not improve from 1.04342\n",
            "Epoch 882/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9766 - accuracy: 0.5767 - val_loss: 1.0796 - val_accuracy: 0.5551\n",
            "\n",
            "Epoch 00882: val_loss did not improve from 1.04342\n",
            "Epoch 883/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.9896 - accuracy: 0.5712 - val_loss: 1.0881 - val_accuracy: 0.5404\n",
            "\n",
            "Epoch 00883: val_loss did not improve from 1.04342\n",
            "Epoch 884/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9762 - accuracy: 0.5748 - val_loss: 1.0905 - val_accuracy: 0.5506\n",
            "\n",
            "Epoch 00884: val_loss did not improve from 1.04342\n",
            "Epoch 885/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9660 - accuracy: 0.5844 - val_loss: 1.0863 - val_accuracy: 0.5487\n",
            "\n",
            "Epoch 00885: val_loss did not improve from 1.04342\n",
            "Epoch 886/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9942 - accuracy: 0.5830 - val_loss: 1.0936 - val_accuracy: 0.5526\n",
            "\n",
            "Epoch 00886: val_loss did not improve from 1.04342\n",
            "Epoch 887/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9943 - accuracy: 0.5702 - val_loss: 1.0830 - val_accuracy: 0.5532\n",
            "\n",
            "Epoch 00887: val_loss did not improve from 1.04342\n",
            "Epoch 888/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9995 - accuracy: 0.5565 - val_loss: 1.0824 - val_accuracy: 0.5468\n",
            "\n",
            "Epoch 00888: val_loss did not improve from 1.04342\n",
            "Epoch 889/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9891 - accuracy: 0.5820 - val_loss: 1.0832 - val_accuracy: 0.5462\n",
            "\n",
            "Epoch 00889: val_loss did not improve from 1.04342\n",
            "Epoch 890/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1.0304 - accuracy: 0.5533 - val_loss: 1.0845 - val_accuracy: 0.5513\n",
            "\n",
            "Epoch 00890: val_loss did not improve from 1.04342\n",
            "Epoch 891/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9905 - accuracy: 0.5657 - val_loss: 1.0886 - val_accuracy: 0.5423\n",
            "\n",
            "Epoch 00891: val_loss did not improve from 1.04342\n",
            "Epoch 892/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9747 - accuracy: 0.5751 - val_loss: 1.0905 - val_accuracy: 0.5474\n",
            "\n",
            "Epoch 00892: val_loss did not improve from 1.04342\n",
            "Epoch 893/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9811 - accuracy: 0.5818 - val_loss: 1.0763 - val_accuracy: 0.5609\n",
            "\n",
            "Epoch 00893: val_loss did not improve from 1.04342\n",
            "Epoch 894/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9763 - accuracy: 0.5885 - val_loss: 1.0944 - val_accuracy: 0.5468\n",
            "\n",
            "Epoch 00894: val_loss did not improve from 1.04342\n",
            "Epoch 895/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9850 - accuracy: 0.5818 - val_loss: 1.1079 - val_accuracy: 0.5237\n",
            "\n",
            "Epoch 00895: val_loss did not improve from 1.04342\n",
            "Epoch 896/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9750 - accuracy: 0.5886 - val_loss: 1.0992 - val_accuracy: 0.5423\n",
            "\n",
            "Epoch 00896: val_loss did not improve from 1.04342\n",
            "Epoch 897/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0002 - accuracy: 0.5635 - val_loss: 1.0741 - val_accuracy: 0.5538\n",
            "\n",
            "Epoch 00897: val_loss did not improve from 1.04342\n",
            "Epoch 898/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9734 - accuracy: 0.5821 - val_loss: 1.0835 - val_accuracy: 0.5442\n",
            "\n",
            "Epoch 00898: val_loss did not improve from 1.04342\n",
            "Epoch 899/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.9696 - accuracy: 0.5826 - val_loss: 1.1003 - val_accuracy: 0.5481\n",
            "\n",
            "Epoch 00899: val_loss did not improve from 1.04342\n",
            "Epoch 900/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.9917 - accuracy: 0.5771 - val_loss: 1.0948 - val_accuracy: 0.5397\n",
            "\n",
            "Epoch 00900: val_loss did not improve from 1.04342\n",
            "Epoch 901/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.9865 - accuracy: 0.5761 - val_loss: 1.0899 - val_accuracy: 0.5378\n",
            "\n",
            "Epoch 00901: val_loss did not improve from 1.04342\n",
            "Epoch 902/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9813 - accuracy: 0.5925 - val_loss: 1.0754 - val_accuracy: 0.5558\n",
            "\n",
            "Epoch 00902: val_loss did not improve from 1.04342\n",
            "Epoch 903/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9893 - accuracy: 0.5748 - val_loss: 1.0870 - val_accuracy: 0.5417\n",
            "\n",
            "Epoch 00903: val_loss did not improve from 1.04342\n",
            "Epoch 904/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9968 - accuracy: 0.5749 - val_loss: 1.1101 - val_accuracy: 0.5237\n",
            "\n",
            "Epoch 00904: val_loss did not improve from 1.04342\n",
            "Epoch 905/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1.0293 - accuracy: 0.5587 - val_loss: 1.1251 - val_accuracy: 0.5423\n",
            "\n",
            "Epoch 00905: val_loss did not improve from 1.04342\n",
            "Epoch 906/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9929 - accuracy: 0.5767 - val_loss: 1.0869 - val_accuracy: 0.5558\n",
            "\n",
            "Epoch 00906: val_loss did not improve from 1.04342\n",
            "Epoch 907/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9880 - accuracy: 0.5686 - val_loss: 1.1325 - val_accuracy: 0.5167\n",
            "\n",
            "Epoch 00907: val_loss did not improve from 1.04342\n",
            "Epoch 908/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1.0045 - accuracy: 0.5661 - val_loss: 1.0726 - val_accuracy: 0.5564\n",
            "\n",
            "Epoch 00908: val_loss did not improve from 1.04342\n",
            "Epoch 909/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.9666 - accuracy: 0.5917 - val_loss: 1.0871 - val_accuracy: 0.5526\n",
            "\n",
            "Epoch 00909: val_loss did not improve from 1.04342\n",
            "Epoch 910/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.9895 - accuracy: 0.5813 - val_loss: 1.0887 - val_accuracy: 0.5474\n",
            "\n",
            "Epoch 00910: val_loss did not improve from 1.04342\n",
            "Epoch 911/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0077 - accuracy: 0.5677 - val_loss: 1.0804 - val_accuracy: 0.5513\n",
            "\n",
            "Epoch 00911: val_loss did not improve from 1.04342\n",
            "Epoch 912/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.9768 - accuracy: 0.5792 - val_loss: 1.0896 - val_accuracy: 0.5519\n",
            "\n",
            "Epoch 00912: val_loss did not improve from 1.04342\n",
            "Epoch 913/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.9826 - accuracy: 0.5865 - val_loss: 1.1078 - val_accuracy: 0.5333\n",
            "\n",
            "Epoch 00913: val_loss did not improve from 1.04342\n",
            "Epoch 914/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.9883 - accuracy: 0.5735 - val_loss: 1.0854 - val_accuracy: 0.5513\n",
            "\n",
            "Epoch 00914: val_loss did not improve from 1.04342\n",
            "Epoch 915/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.9700 - accuracy: 0.5757 - val_loss: 1.1031 - val_accuracy: 0.5474\n",
            "\n",
            "Epoch 00915: val_loss did not improve from 1.04342\n",
            "Epoch 916/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0124 - accuracy: 0.5585 - val_loss: 1.0902 - val_accuracy: 0.5468\n",
            "\n",
            "Epoch 00916: val_loss did not improve from 1.04342\n",
            "Epoch 917/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0019 - accuracy: 0.5694 - val_loss: 1.0860 - val_accuracy: 0.5410\n",
            "\n",
            "Epoch 00917: val_loss did not improve from 1.04342\n",
            "Epoch 918/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9784 - accuracy: 0.5897 - val_loss: 1.0967 - val_accuracy: 0.5442\n",
            "\n",
            "Epoch 00918: val_loss did not improve from 1.04342\n",
            "Epoch 919/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9788 - accuracy: 0.5824 - val_loss: 1.0885 - val_accuracy: 0.5481\n",
            "\n",
            "Epoch 00919: val_loss did not improve from 1.04342\n",
            "Epoch 920/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9830 - accuracy: 0.5801 - val_loss: 1.0933 - val_accuracy: 0.5500\n",
            "\n",
            "Epoch 00920: val_loss did not improve from 1.04342\n",
            "Epoch 921/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9973 - accuracy: 0.5760 - val_loss: 1.0865 - val_accuracy: 0.5487\n",
            "\n",
            "Epoch 00921: val_loss did not improve from 1.04342\n",
            "Epoch 922/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9934 - accuracy: 0.5821 - val_loss: 1.0956 - val_accuracy: 0.5545\n",
            "\n",
            "Epoch 00922: val_loss did not improve from 1.04342\n",
            "Epoch 923/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0088 - accuracy: 0.5545 - val_loss: 1.0901 - val_accuracy: 0.5513\n",
            "\n",
            "Epoch 00923: val_loss did not improve from 1.04342\n",
            "Epoch 924/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9773 - accuracy: 0.5775 - val_loss: 1.0927 - val_accuracy: 0.5397\n",
            "\n",
            "Epoch 00924: val_loss did not improve from 1.04342\n",
            "Epoch 925/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.9852 - accuracy: 0.5736 - val_loss: 1.0911 - val_accuracy: 0.5519\n",
            "\n",
            "Epoch 00925: val_loss did not improve from 1.04342\n",
            "Epoch 926/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9858 - accuracy: 0.5708 - val_loss: 1.0752 - val_accuracy: 0.5455\n",
            "\n",
            "Epoch 00926: val_loss did not improve from 1.04342\n",
            "Epoch 927/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1.0156 - accuracy: 0.5699 - val_loss: 1.0815 - val_accuracy: 0.5635\n",
            "\n",
            "Epoch 00927: val_loss did not improve from 1.04342\n",
            "Epoch 928/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.9722 - accuracy: 0.5791 - val_loss: 1.0940 - val_accuracy: 0.5378\n",
            "\n",
            "Epoch 00928: val_loss did not improve from 1.04342\n",
            "Epoch 929/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.9741 - accuracy: 0.5765 - val_loss: 1.1016 - val_accuracy: 0.5288\n",
            "\n",
            "Epoch 00929: val_loss did not improve from 1.04342\n",
            "Epoch 930/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1.0046 - accuracy: 0.5626 - val_loss: 1.0890 - val_accuracy: 0.5340\n",
            "\n",
            "Epoch 00930: val_loss did not improve from 1.04342\n",
            "Epoch 931/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1.0063 - accuracy: 0.5626 - val_loss: 1.0858 - val_accuracy: 0.5494\n",
            "\n",
            "Epoch 00931: val_loss did not improve from 1.04342\n",
            "Epoch 932/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9816 - accuracy: 0.5882 - val_loss: 1.0798 - val_accuracy: 0.5609\n",
            "\n",
            "Epoch 00932: val_loss did not improve from 1.04342\n",
            "Epoch 933/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.9841 - accuracy: 0.5728 - val_loss: 1.0972 - val_accuracy: 0.5410\n",
            "\n",
            "Epoch 00933: val_loss did not improve from 1.04342\n",
            "Epoch 934/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 0.9698 - accuracy: 0.5834 - val_loss: 1.1037 - val_accuracy: 0.5487\n",
            "\n",
            "Epoch 00934: val_loss did not improve from 1.04342\n",
            "Epoch 935/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9979 - accuracy: 0.5779 - val_loss: 1.0968 - val_accuracy: 0.5288\n",
            "\n",
            "Epoch 00935: val_loss did not improve from 1.04342\n",
            "Epoch 936/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9764 - accuracy: 0.5850 - val_loss: 1.0763 - val_accuracy: 0.5417\n",
            "\n",
            "Epoch 00936: val_loss did not improve from 1.04342\n",
            "Epoch 937/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0024 - accuracy: 0.5649 - val_loss: 1.0911 - val_accuracy: 0.5487\n",
            "\n",
            "Epoch 00937: val_loss did not improve from 1.04342\n",
            "Epoch 938/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0095 - accuracy: 0.5666 - val_loss: 1.0983 - val_accuracy: 0.5314\n",
            "\n",
            "Epoch 00938: val_loss did not improve from 1.04342\n",
            "Epoch 939/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.9757 - accuracy: 0.5922 - val_loss: 1.0924 - val_accuracy: 0.5513\n",
            "\n",
            "Epoch 00939: val_loss did not improve from 1.04342\n",
            "Epoch 940/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9909 - accuracy: 0.5624 - val_loss: 1.0820 - val_accuracy: 0.5551\n",
            "\n",
            "Epoch 00940: val_loss did not improve from 1.04342\n",
            "Epoch 941/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0020 - accuracy: 0.5695 - val_loss: 1.0895 - val_accuracy: 0.5481\n",
            "\n",
            "Epoch 00941: val_loss did not improve from 1.04342\n",
            "Epoch 942/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9628 - accuracy: 0.5945 - val_loss: 1.0852 - val_accuracy: 0.5474\n",
            "\n",
            "Epoch 00942: val_loss did not improve from 1.04342\n",
            "Epoch 943/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9917 - accuracy: 0.5693 - val_loss: 1.1011 - val_accuracy: 0.5506\n",
            "\n",
            "Epoch 00943: val_loss did not improve from 1.04342\n",
            "Epoch 944/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 0.9841 - accuracy: 0.5799 - val_loss: 1.0778 - val_accuracy: 0.5468\n",
            "\n",
            "Epoch 00944: val_loss did not improve from 1.04342\n",
            "Epoch 945/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.9928 - accuracy: 0.5765 - val_loss: 1.0914 - val_accuracy: 0.5455\n",
            "\n",
            "Epoch 00945: val_loss did not improve from 1.04342\n",
            "Epoch 946/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9863 - accuracy: 0.5792 - val_loss: 1.1184 - val_accuracy: 0.5474\n",
            "\n",
            "Epoch 00946: val_loss did not improve from 1.04342\n",
            "Epoch 947/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.9789 - accuracy: 0.5764 - val_loss: 1.0773 - val_accuracy: 0.5564\n",
            "\n",
            "Epoch 00947: val_loss did not improve from 1.04342\n",
            "Epoch 948/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9858 - accuracy: 0.5687 - val_loss: 1.0877 - val_accuracy: 0.5442\n",
            "\n",
            "Epoch 00948: val_loss did not improve from 1.04342\n",
            "Epoch 949/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9890 - accuracy: 0.5778 - val_loss: 1.1118 - val_accuracy: 0.5404\n",
            "\n",
            "Epoch 00949: val_loss did not improve from 1.04342\n",
            "Epoch 950/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1.0059 - accuracy: 0.5697 - val_loss: 1.0803 - val_accuracy: 0.5532\n",
            "\n",
            "Epoch 00950: val_loss did not improve from 1.04342\n",
            "Epoch 951/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.9721 - accuracy: 0.5801 - val_loss: 1.0922 - val_accuracy: 0.5494\n",
            "\n",
            "Epoch 00951: val_loss did not improve from 1.04342\n",
            "Epoch 952/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1.0100 - accuracy: 0.5734 - val_loss: 1.0922 - val_accuracy: 0.5417\n",
            "\n",
            "Epoch 00952: val_loss did not improve from 1.04342\n",
            "Epoch 953/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.9937 - accuracy: 0.5782 - val_loss: 1.0795 - val_accuracy: 0.5500\n",
            "\n",
            "Epoch 00953: val_loss did not improve from 1.04342\n",
            "Epoch 954/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9761 - accuracy: 0.5842 - val_loss: 1.0866 - val_accuracy: 0.5449\n",
            "\n",
            "Epoch 00954: val_loss did not improve from 1.04342\n",
            "Epoch 955/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.9894 - accuracy: 0.5715 - val_loss: 1.1089 - val_accuracy: 0.5500\n",
            "\n",
            "Epoch 00955: val_loss did not improve from 1.04342\n",
            "Epoch 956/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.9805 - accuracy: 0.5844 - val_loss: 1.0857 - val_accuracy: 0.5513\n",
            "\n",
            "Epoch 00956: val_loss did not improve from 1.04342\n",
            "Epoch 957/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.9911 - accuracy: 0.5788 - val_loss: 1.0781 - val_accuracy: 0.5474\n",
            "\n",
            "Epoch 00957: val_loss did not improve from 1.04342\n",
            "Epoch 958/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9688 - accuracy: 0.5884 - val_loss: 1.0764 - val_accuracy: 0.5513\n",
            "\n",
            "Epoch 00958: val_loss did not improve from 1.04342\n",
            "Epoch 959/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1.0064 - accuracy: 0.5820 - val_loss: 1.0874 - val_accuracy: 0.5455\n",
            "\n",
            "Epoch 00959: val_loss did not improve from 1.04342\n",
            "Epoch 960/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9777 - accuracy: 0.5810 - val_loss: 1.1201 - val_accuracy: 0.5212\n",
            "\n",
            "Epoch 00960: val_loss did not improve from 1.04342\n",
            "Epoch 961/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1.0125 - accuracy: 0.5623 - val_loss: 1.0926 - val_accuracy: 0.5474\n",
            "\n",
            "Epoch 00961: val_loss did not improve from 1.04342\n",
            "Epoch 962/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 0.9733 - accuracy: 0.5844 - val_loss: 1.0976 - val_accuracy: 0.5487\n",
            "\n",
            "Epoch 00962: val_loss did not improve from 1.04342\n",
            "Epoch 963/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9843 - accuracy: 0.5757 - val_loss: 1.1033 - val_accuracy: 0.5224\n",
            "\n",
            "Epoch 00963: val_loss did not improve from 1.04342\n",
            "Epoch 964/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9736 - accuracy: 0.5912 - val_loss: 1.0760 - val_accuracy: 0.5519\n",
            "\n",
            "Epoch 00964: val_loss did not improve from 1.04342\n",
            "Epoch 965/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9865 - accuracy: 0.5683 - val_loss: 1.1051 - val_accuracy: 0.5385\n",
            "\n",
            "Epoch 00965: val_loss did not improve from 1.04342\n",
            "Epoch 966/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9799 - accuracy: 0.5867 - val_loss: 1.0862 - val_accuracy: 0.5558\n",
            "\n",
            "Epoch 00966: val_loss did not improve from 1.04342\n",
            "Epoch 967/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.9680 - accuracy: 0.5917 - val_loss: 1.0895 - val_accuracy: 0.5481\n",
            "\n",
            "Epoch 00967: val_loss did not improve from 1.04342\n",
            "Epoch 968/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 0.9797 - accuracy: 0.5802 - val_loss: 1.1458 - val_accuracy: 0.5186\n",
            "\n",
            "Epoch 00968: val_loss did not improve from 1.04342\n",
            "Epoch 969/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1.0102 - accuracy: 0.5734 - val_loss: 1.0759 - val_accuracy: 0.5385\n",
            "\n",
            "Epoch 00969: val_loss did not improve from 1.04342\n",
            "Epoch 970/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 1.0049 - accuracy: 0.5715 - val_loss: 1.0963 - val_accuracy: 0.5513\n",
            "\n",
            "Epoch 00970: val_loss did not improve from 1.04342\n",
            "Epoch 971/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9766 - accuracy: 0.5792 - val_loss: 1.0700 - val_accuracy: 0.5526\n",
            "\n",
            "Epoch 00971: val_loss did not improve from 1.04342\n",
            "Epoch 972/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9726 - accuracy: 0.5954 - val_loss: 1.0877 - val_accuracy: 0.5436\n",
            "\n",
            "Epoch 00972: val_loss did not improve from 1.04342\n",
            "Epoch 973/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1.0146 - accuracy: 0.5705 - val_loss: 1.0875 - val_accuracy: 0.5551\n",
            "\n",
            "Epoch 00973: val_loss did not improve from 1.04342\n",
            "Epoch 974/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.9829 - accuracy: 0.5686 - val_loss: 1.0948 - val_accuracy: 0.5532\n",
            "\n",
            "Epoch 00974: val_loss did not improve from 1.04342\n",
            "Epoch 975/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9735 - accuracy: 0.5743 - val_loss: 1.0984 - val_accuracy: 0.5526\n",
            "\n",
            "Epoch 00975: val_loss did not improve from 1.04342\n",
            "Epoch 976/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9930 - accuracy: 0.5734 - val_loss: 1.0770 - val_accuracy: 0.5538\n",
            "\n",
            "Epoch 00976: val_loss did not improve from 1.04342\n",
            "Epoch 977/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9638 - accuracy: 0.5896 - val_loss: 1.1055 - val_accuracy: 0.5449\n",
            "\n",
            "Epoch 00977: val_loss did not improve from 1.04342\n",
            "Epoch 978/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.9926 - accuracy: 0.5826 - val_loss: 1.0837 - val_accuracy: 0.5474\n",
            "\n",
            "Epoch 00978: val_loss did not improve from 1.04342\n",
            "Epoch 979/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.9609 - accuracy: 0.5858 - val_loss: 1.0809 - val_accuracy: 0.5449\n",
            "\n",
            "Epoch 00979: val_loss did not improve from 1.04342\n",
            "Epoch 980/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9822 - accuracy: 0.5853 - val_loss: 1.1125 - val_accuracy: 0.5385\n",
            "\n",
            "Epoch 00980: val_loss did not improve from 1.04342\n",
            "Epoch 981/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9597 - accuracy: 0.6007 - val_loss: 1.0840 - val_accuracy: 0.5558\n",
            "\n",
            "Epoch 00981: val_loss did not improve from 1.04342\n",
            "Epoch 982/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.9688 - accuracy: 0.5841 - val_loss: 1.0938 - val_accuracy: 0.5385\n",
            "\n",
            "Epoch 00982: val_loss did not improve from 1.04342\n",
            "Epoch 983/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9826 - accuracy: 0.5767 - val_loss: 1.1024 - val_accuracy: 0.5474\n",
            "\n",
            "Epoch 00983: val_loss did not improve from 1.04342\n",
            "Epoch 984/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9737 - accuracy: 0.5900 - val_loss: 1.0945 - val_accuracy: 0.5519\n",
            "\n",
            "Epoch 00984: val_loss did not improve from 1.04342\n",
            "Epoch 985/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.9768 - accuracy: 0.5865 - val_loss: 1.1399 - val_accuracy: 0.5064\n",
            "\n",
            "Epoch 00985: val_loss did not improve from 1.04342\n",
            "Epoch 986/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1.0102 - accuracy: 0.5621 - val_loss: 1.0819 - val_accuracy: 0.5474\n",
            "\n",
            "Epoch 00986: val_loss did not improve from 1.04342\n",
            "Epoch 987/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.9569 - accuracy: 0.5857 - val_loss: 1.0982 - val_accuracy: 0.5462\n",
            "\n",
            "Epoch 00987: val_loss did not improve from 1.04342\n",
            "Epoch 988/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9788 - accuracy: 0.5795 - val_loss: 1.1094 - val_accuracy: 0.5327\n",
            "\n",
            "Epoch 00988: val_loss did not improve from 1.04342\n",
            "Epoch 989/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9909 - accuracy: 0.5821 - val_loss: 1.1140 - val_accuracy: 0.5321\n",
            "\n",
            "Epoch 00989: val_loss did not improve from 1.04342\n",
            "Epoch 990/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9678 - accuracy: 0.5836 - val_loss: 1.1198 - val_accuracy: 0.5212\n",
            "\n",
            "Epoch 00990: val_loss did not improve from 1.04342\n",
            "Epoch 991/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.9966 - accuracy: 0.5688 - val_loss: 1.0833 - val_accuracy: 0.5590\n",
            "\n",
            "Epoch 00991: val_loss did not improve from 1.04342\n",
            "Epoch 992/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9862 - accuracy: 0.5950 - val_loss: 1.0677 - val_accuracy: 0.5519\n",
            "\n",
            "Epoch 00992: val_loss did not improve from 1.04342\n",
            "Epoch 993/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9707 - accuracy: 0.5736 - val_loss: 1.1100 - val_accuracy: 0.5340\n",
            "\n",
            "Epoch 00993: val_loss did not improve from 1.04342\n",
            "Epoch 994/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.0013 - accuracy: 0.5534 - val_loss: 1.0945 - val_accuracy: 0.5545\n",
            "\n",
            "Epoch 00994: val_loss did not improve from 1.04342\n",
            "Epoch 995/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9908 - accuracy: 0.5741 - val_loss: 1.0769 - val_accuracy: 0.5532\n",
            "\n",
            "Epoch 00995: val_loss did not improve from 1.04342\n",
            "Epoch 996/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9956 - accuracy: 0.5799 - val_loss: 1.0868 - val_accuracy: 0.5513\n",
            "\n",
            "Epoch 00996: val_loss did not improve from 1.04342\n",
            "Epoch 997/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1.0120 - accuracy: 0.5621 - val_loss: 1.0735 - val_accuracy: 0.5545\n",
            "\n",
            "Epoch 00997: val_loss did not improve from 1.04342\n",
            "Epoch 998/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.9579 - accuracy: 0.5895 - val_loss: 1.0901 - val_accuracy: 0.5468\n",
            "\n",
            "Epoch 00998: val_loss did not improve from 1.04342\n",
            "Epoch 999/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9976 - accuracy: 0.5770 - val_loss: 1.0973 - val_accuracy: 0.5391\n",
            "\n",
            "Epoch 00999: val_loss did not improve from 1.04342\n",
            "Epoch 1000/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9833 - accuracy: 0.5844 - val_loss: 1.0869 - val_accuracy: 0.5449\n",
            "\n",
            "Epoch 01000: val_loss did not improve from 1.04342\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRz8TkjcpJ4x"
      },
      "source": [
        "## 결과 출력"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkUdiqxQLrBS"
      },
      "source": [
        "from keras.models import load_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5DPNFROL8Ev"
      },
      "source": [
        "####와인 종류"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBxvnUguoXw-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0b3c1ba-3620-4c0a-e49a-d47cf1eeed84"
      },
      "source": [
        "print(\"\\n Test Accuracy: %.4f\\n\" % (model.evaluate(x_test, y_test)[1])) # 와인 종류에 대한 검사\n",
        "print(\"\\n Accuracy: %.4f\" % (model.evaluate(x_train,y_train)[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "41/41 [==============================] - 0s 1ms/step - loss: 0.0389 - accuracy: 0.9869\n",
            "\n",
            " Test Accuracy: 0.9869\n",
            "\n",
            "163/163 [==============================] - 0s 1ms/step - loss: 0.0315 - accuracy: 0.9906\n",
            "\n",
            " Accuracy: 0.9906\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgnFRz5qL7iN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80004a47-4f05-47e8-f8c2-c6610c59f337"
      },
      "source": [
        "bestm=load_model('/content/model/와인종류.0.0306-0.9904-957.hdf5') #현재 학습에서 고른 모델\n",
        "#bestm=load_model('/content/model/0.0319-0.9891-788.hdf5') # 9851 9877\n",
        "print(\"\\n Test Accuracy: %.4f\\n\" % (bestm.evaluate(x_test, y_test)[1])) # 와인 종류에 대한 검사\n",
        "print(\"\\n Accuracy: %.4f\" % (bestm.evaluate(x_train,y_train)[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "41/41 [==============================] - 0s 967us/step - loss: 0.0438 - accuracy: 0.9877\n",
            "\n",
            " Test Accuracy: 0.9877\n",
            "\n",
            "163/163 [==============================] - 0s 969us/step - loss: 0.0327 - accuracy: 0.9906\n",
            "\n",
            " Accuracy: 0.9906\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vb0X-sYX7kkx",
        "outputId": "adae2165-f346-489e-ffd8-4bfcff8fa608"
      },
      "source": [
        "b_bestm=load_model('/content/와인분류0.0539-0.9846-220.hdf5') #이전 학습에서 고른 모델 -> before_best_model\n",
        "#bestm=load_model('/content/model/0.0725-453.hdf5') # 9851 9877\n",
        "print(\"\\n Test Accuracy: %.4f\\n\" % (b_bestm.evaluate(x_test, y_test)[1])) # 와인 종류에 대한 검사\n",
        "print(\"\\n Accuracy: %.4f\" % (b_bestm.evaluate(x_train,y_train)[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "41/41 [==============================] - 0s 1ms/step - loss: 0.0706 - accuracy: 0.9800\n",
            "\n",
            " Test Accuracy: 0.9800\n",
            "\n",
            "163/163 [==============================] - 0s 961us/step - loss: 0.0530 - accuracy: 0.9863\n",
            "\n",
            " Accuracy: 0.9863\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtgEMwMmMB0i"
      },
      "source": [
        "####와인 품질"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3woOjuAoIOmI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9069f426-7d6d-4f4b-ab23-5d300b12ac8c"
      },
      "source": [
        "print(\"\\n Test Accuracy: %.4f\\n\" % (model0.evaluate(x0_test, y0_test)[1])) #와인 \n",
        "print(\"\\n Accuracy: %.4f\" % (model0.evaluate(x0_train, y0_train)[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "41/41 [==============================] - 0s 963us/step - loss: 1.0737 - accuracy: 0.5462\n",
            "\n",
            " Test Accuracy: 0.5462\n",
            "\n",
            "163/163 [==============================] - 0s 1ms/step - loss: 1.0092 - accuracy: 0.5696\n",
            "\n",
            " Accuracy: 0.5696\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgtO8IGsM1cX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f3c082a-881a-4b8a-9427-f6ffa54cfbef"
      },
      "source": [
        "bestm0=load_model('/content/model0/와인질.1.0504-0.5423-215.hdf5')  \n",
        "print(\"\\n Test Accuracy: %.4f\\n\" % (bestm0.evaluate(x0_test, y0_test)[1])) #와인 \n",
        "print(\"\\n Accuracy: %.4f\" % (bestm0.evaluate(x0_train, y0_train)[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "41/41 [==============================] - 0s 929us/step - loss: 1.0462 - accuracy: 0.5562\n",
            "\n",
            " Test Accuracy: 0.5562\n",
            "\n",
            "163/163 [==============================] - 0s 998us/step - loss: 1.0548 - accuracy: 0.5434\n",
            "\n",
            " Accuracy: 0.5434\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFE4O8-R7vNw",
        "outputId": "e40e749b-9520-4874-9249-721b9f7419d9"
      },
      "source": [
        "b_bestm0=load_model('/content/와인질1.0693-0.5297-397.hdf5') #이전 학습에서 높은 정확도 보인 모델, 테스트 셋에서 점수가 더 잘 나옴\n",
        "print(\"\\n Test Accuracy: %.4f\\n\" % (b_bestm0.evaluate(x0_test, y0_test)[1])) #와인 \n",
        "print(\"\\n Accuracy: %.4f\" % (b_bestm0.evaluate(x0_train, y0_train)[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "41/41 [==============================] - 0s 1ms/step - loss: 1.0049 - accuracy: 0.5708\n",
            "\n",
            " Test Accuracy: 0.5708\n",
            "\n",
            "163/163 [==============================] - 0s 1ms/step - loss: 1.0395 - accuracy: 0.5597\n",
            "\n",
            " Accuracy: 0.5597\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34WLFSppHv1v"
      },
      "source": [
        "모델 불러오기 부분"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zczs83HbHuwP"
      },
      "source": [
        "from keras.models import load_model\n",
        "model123=model0\n",
        "model123.evaluate(x_a_test,y_a_test_r)\n",
        "wine12=load_model('/content/model_trash/94-1.1253.hdf5')\n",
        "#wine12.evaluate(x_a_test,y_a_test_r)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elaew1sbbmeA"
      },
      "source": [
        "###시각화"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyzjtLKz-XbS"
      },
      "source": [
        "val_loss가 train_loss와 차이가 날 때(높아질 떄) 과적합이 시작됐다 판단"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfR8O1f9boXy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "cf4fd13b-2991-4b93-d699-4d50f3d742d5"
      },
      "source": [
        "fig, loss_ax = plt.subplots()\n",
        "acc_ax = loss_ax.twinx()\n",
        "\n",
        "loss_ax.plot(wineseries.history['loss'], 'y', label='train loss')\n",
        "loss_ax.plot(wineseries.history['val_loss'], 'r', label='val loss')\n",
        "loss_ax.set_xlabel('epoch')\n",
        "loss_ax.set_ylabel('loss')\n",
        "loss_ax.legend(loc='upper left')\n",
        "\n",
        "acc_ax.plot(wineseries.history['accuracy'], 'b', label='train acc')\n",
        "acc_ax.plot(wineseries.history['val_accuracy'], 'g', label='val acc')\n",
        "acc_ax.set_ylabel('accuracy')\n",
        "acc_ax.legend(loc='upper left')\n",
        "\n",
        "plt.figure(figsize=(20,15))\n",
        "plt.show()\n",
        "\n",
        "#쭉 같이 내려가는 모습 -> 과적합 판단 모르겠음"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbMAAAEHCAYAAAAktqjkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydeXxU5fWHnzPZN0jYwr7vKKhsdQURBBUB665VUXGra7W2blWLWqu1tm6t8qv7hmitRYviiooCEmUTlB2RhECAbGTPzPn9ce8kk2SSTEKGEDjP5zPOve9y75kJ3u+c9z3veUVVMQzDMIyWjKe5DTAMwzCMfcXEzDAMw2jxmJgZhmEYLR4TM8MwDKPFY2JmGIZhtHhMzAzDMIwWT2RzG9BUeDwejYuLa24zDMMwWhSFhYWqqrU6NiLyHDAZ2KmqhwWpF+Ax4FSgEJiuqt+5dZcAd7lN71fVF5va/go7DpZ1ZgkJCVpQUNDcZhiGYbQoRKRQVRPqqD8B2Au8VIuYnQpcjyNmo4HHVHW0iLQB0oARgALfAsNVNTsMH8OGGQ3DMIzaUdUvgD11NJmKI3SqqouBZBHpBEwEPlLVPa6AfQRMCpedJmaGYRjGvtAF+DngfJtbVlt5WDho5swMwzCMRhEpImkB57NUdVazWdNIDmoxKyoqYtOmTXi93uY2pcUhIkRERBAXF0fXrl2JiopqbpMMwwgP5ao6Yh/6pwPdAs67umXpwNhq5Qv24T51clCL2aZNm2jXrh3t27fH47ER1VBRVXbv3k1+fj5JSUls27aNXr16NbdZhmEcmMwFrhOR2TgBILmqul1E5gN/EpEUt93JwO3hMuKgFjOv12tC1ghEhLZt25KVlUXPnj3JyspqbpMMw2gmROR1HA+rnYhsA+4BogBU9WlgHk4k4wac0PxL3bo9InIfsNS91ExVrSuQZJ84qMUMMCFrJM7Skcp3wzAOTVT1/HrqFbi2lrrngOfCYVd1Dvknvari85WiavNqhmE0LXPmwLZtTXvNg2RpcJNzyIsZKKplqPqa/Mq7du3ioYcealTfMWPGsGvXrpDbZ2RkkJmZ2ah7GeEhKwuWL29uK6ryxBPw5z8Hr/P54OGHISMDSkuhqMgp37sXysurtlWFBx+EzZuhrKz2+6lCXp5zzfvvh9xcWLkStm51jj/7DM46CzZuhPPOc+p27nRsqc7PP8OXX8KHH8L48fDss/DUU07dV19B376werVznpvr3LugoPK4OiUlsGsXpKfDW2/Bli3OZ1q9Gu691ykvKHC+i0WLnL8nQH4++GPK/J8PIC0Nrr8ejj4arrkGRODcc6FbN+ezn3GGc921ayEzEz74ACZOhE8/dc7X/ODj1bT/0m9IPoMHO59pyxZ45hlYtgwWLIBx48DjgY4d4YYbfZx5z2xOPc3LBRfU/jc4ZFDVg+IVHx+v1VmxYkWNsur4fD4tL9+rXm9pvW0byo8//qh9+/YNWlda2rT3S09P1+3btzfpNdesWVPlfX8zZ47qCy9Unvt8qq+/rlpQ4JyvX6/q9VbWZ2aq5uTUfj2vt7K9z6e6dm3V+nvuUZ0+3Tnetk21sFB1507V7Ozg1wu8/86dqitXqm7frvrmm6rPPqvqPOpUd+1S3b3babd8uepTT6necovT94cfVI87TvX77536VatUL79cNS1N9eqrVfv0UU1OVr3sMtXFi1VnzlQ9+WTVI49U3btX9YknVP/3v8rPdNppzuf48UfV8nLV//xH9a9/dT7Lc89V2rRundN+4ULV4cOdsosuqqz3v044wXm//HLVf/9b9Re/UB00qGqbfuO+0vOv/1Gj70hVOi/V3/5W9fPPVY86qub1GvL6+WfVc88NKPvlhcrE39Rod/bZ7nGnb7Vd762amqpKfJa2P+prt41P6f+u9h1YpNOnq44Y4XyW3r1ruXdSutJ5acV5Uusype885czztd35v1NQvfJK1QULVMdfskS5qYcy7AVFvMplxyiHvVZ5rR6fK7F7nOPkzUqnNOdakUVKdJ5y1RHKsBeVm7orY/6o3IvzGvEPp4+nTBnwjiLl2m7ISuUXjyoD31YSMivbTrtETz21rv+T6gYo0APgGb6vr4M6ndXKlSsZOnRonf1UFZ+vEJFoPJ6mDT+fPHkyH3/8MT179mTs2LFMmTKFu+++m9atW7Nx40a2bNnChAkTyMjIoKSkhGuuuYZbbrkFgC5dupCWlkZeXh6nnHIKo0aNIi0tjY4dOzJ//nwSEqpmn3nhhRd4/PHHUVWSk5OZOXMmbdq0oby8nEcffZTvvvsOr9fLFVdcwcknn8ySJUt48sknKSsrIyEhgWeffRYRYcCAAURERADwww8/MGjQoIr3xvLdd1AUt5EuqbH0bFO5ZnLHDsjJcX4djxwJ0dHw+OPOL+8OpzzD8x8vgndewOeDvL1l9HvgRLLmzGTasHH8+tdw8snOddatg5QUaN/eOZ8zx7l2585w5pnQurVz3aeegm++8X9fMH26c3zGRTvYOPo0Vv7hDcjuw0uL5nHxpSWwdiqoh27dIOWwNDZ9049xx7YmMxO+/Ra8yWtJnXEVJ6aew+ybfw2D3oahr8Ab/wZqzjUmJTm/6v1MnAgrdy1l+8rBUJbA9OmOXaSugMgSSB/lNIzPgoSdkDWk1u942hnKO0U3QfJPMPsd6LqI313dnYcfy3H6dV0EGSMgdRXs7gelSXDuGZDfBRb+HhKyoKADRJRAcTIkbYedbuaiDqtg8tXw1e9h7RSnrMs34I2GU66HHgsrDdndD16eD3F7QBRUYOLN8Pq7UNKqqtEdl0N2L6e8yzeQMdJp3+ML6JwGPT93zlM2Qer3lf1WnQ//fg3a/QCJmTDuD7DyVzD5GqfeFwEe13V6/b9wzlkQUQb5HWHptTD8GXj/CTj6r1Vt/9sWp98NfR3bX/gMtoyFk+6A4x+savvuvuCLgvY/VJZtGge9P3WOv74Z+v8P2q2FsrjK7zSQBffA2D/W+jdNXXcHO3b44PhaXOkAJmV9yPtPTqi3XTDqS2fVUjhkxOy66/JYuTJ4vIv/O2hosMPQoeU8+WSrWuvXrl3L5MmTWb9+PQDz5s3jzDPPZNmyZQwcOBCAnTt30qFDBwoKCjjiiCNYuHAhqampVcRsyJAhfPnllwwbMYyzpp7F6aefzqVXXEqZt4yYyBiiI6JZs2YNKSkpJLZJ5NGHH2XXzl088cQT/PrXv6a4pJinZz3NmlUb6Nq1AwWlBRw3+jjmfjiXyPhIWktr2nVqR05WLGVlQlKSEBtfzsaNP9Cl0+HMnv0zp5/eja+XlPDIT+cyY8wpjOk5hoi9PejdLY6MDGe46Oq/zKfv2c8zatvL/NT1ET6el8CA+GNY+308XOs8iL8+I5OPN3/IW+teY+VfHnEeMnldiLj2KLwJ2+C5L5yH+B9inS/x5flw4t2w4mI47VrI6Q4vfuo8HFr/DG3XwdCX4e1XIGUz+CKhNBFic6CgvfMAyRjuPKzPmwrLL4UVF8HEWyB9pHN+RyJEF8A3v4bFN8EN/Z17bxkDO4fA+lPhwslO2dz/c663ewDcGfD//1/T4eauzkPwlXmwYyjkd4Zf/gp+nAbeGBj9OHzyJ9jbETovhfG3QdsNsHYyZB4J3ReC+JyHOMCGk2Hb0ZUPvH+sdOzeNcB5wKePgt6fQNpVEFEK0y5z2n1xJ5zwQKVtm8dCrwWwbRR0/QY2ToBP74crRtf9D/zbKyC3G4y7u2p5SRLE5AfvUwfxq6+hsOPH0HY9rDvNedgbVRgefR7DD2vFrO8atmZ5WPsRLP/10vobBsHE7ACjpYjZH//4R5YsWQI48xC33vpb5s17F/UoGdsyePudtxk/bjzdunYjLS2NnNwcJk2cxEfffUReSR6vPvUqUWVRnHPTOQDEeOI4LHUw8z+dz/0zHyBz53bKSsvo32cA7879gFGjhnPvP/5A997doaQVEZ4yPvtsPh//91NmPnWv+wV4nIdoYTvI6+wITJv17NqWySkfngIf/A2yBsFFQdKqrbwQdg10vIehr0D8Hsjp4XgI+5MNE6Hv/Ib3+/lo6LbIOc7vCOVxjig2lEBvwE91UTFaBL1TelNcXkxGfkaTX/uMgWdw1fCruH7ejazPXluj/r3z32NS30l0eKQDe4pqRrFLXg+0Vc3/t0Z3Gc3iGYsbZdPBImYHfWi+n9pEJ5zDjH68Pi8FZQVkl2YTHx9PRobiiSnivx+8w2cLvubZec8SGxfLVWddxebszfy0Jx1FWLcBcqPXExkXSV6JM8vsi/BRVFRSce0SXxHf/pDFnX+4kwuuvIAxJ4/h26+/Zdajs/h+z3eUUVxpSEwe/setTwJm9MWdbY/f5byqM+k3tX+4oa/WLNvfQgaNEzKoFDKApMoAmq78gm004OFQXcigbiHLGgjtfwxaNTR+IisLa/88S69Yyokvnsje0r20jmlNbkkuAAPaDGRCu8v5v2fLKTm+cm3qgLYDWLu75oMzGG3j2rK7aHeNco948LlBUpO6ncMH/xgH6aO46ok3eGa1E+T0+KTH2ZyzmTVZa5i/cT7xUfEUlhUSFxnHHcffweT+kznj1XPZsnddlWt/Pv1zcopzWPTzIv78VeWQ2jGpExjYqSf3j/sjnZI6cdend/HAlw9w8bCLeWnFS0HtP3vw2Tw68VG6/c1JSHHf2Ac4K/UOdsR+zmdbPmN30R76telLel46tx57K6XeUtrEteH1Va+Tnp/OzUffTHxUPAD/+u5fXPHuFQCc2fMKVu/9kh93Bf+b+Tmi4xEsz6wZ9fPC1Bc4fcDpJEYnEh0Rzdrrf2DGf66jV9IA/vD1jRXteib3JMITQddWXR0x23QSKTFtye4yh5GFd/PXM+7hrMWd2Fmwk8+nf85DXz3EvPXzKCwrrNOuQ4FDRszqp2k8VK/PS0Z+Bh0TO1IcVUxBQQHLMpcBsLd8L+UR5WT4VkBJOXtLt5PULoLYuFi2bNjC99858wK7S3aAx0dZymoIsqtNiRRVLUjeyt68vXTo2AGA9958r6Jq1AmjePOFN7llpjMXl5eTx+HDD+ehOx4ifWs6Xbp3ITc7l9YprUP7gO8+A6df1cBvBQa0GcTaPe78whM/QtweOl91NRnelbX2uW7EDXyfvpldu+D7sndrNlg2nR//eR8Db5sOvT+hT3J/7hj4CpOO6UJybDK/e3QFOT91Zeq1iznnrXMquv3hhD9Qsm4MD2eOryh7/8L3ue3j21ixYwUA/7niCYalDmNb3jaiI6LJKsyiW6tutPtLOwCGdxrOt9u/rWLO5P6TeW/de9TGBxd+wMuz2vLqo4c7w473Vh0JyP59NmXeMtontOennJ/IKszika8f4eJhF7Nqxypu++Q2RnYeyYjOI1h46UL+tvhv/H3S3xn5fyPZsGcDD5x0P2cOPpMnzgf5oyNm47Z9xMd3n4RnphO4vPXGbTzy5RMM69qf47sfT5u4NmQVZtE5qTOtYpwffJl7M7nw7Qv5dPOnFbZtv2U7HRKcf19ZWdDhcqf88SlHcOu4K+jTpk9F2+LyYmbMncFdJ9xFfFQ8HRI6EBvpDBvHxnqczUSAi4ddzIvTKre3mjJgCjcffTMXv3MxH2z4gF8Oncgtx9xSUX9yn5N54MsHGNV5FJ9s+oT0/HQ+ufgTTnrpJADOP+x8Hp7wMF1bda3oc9eYOwAYyBjG9BxT69/m0iMvrVE246gZnNL3FEq8JfRO6Q1AQWkBeSV5dH60c432XZK68OWlX5L0YBIA31z8I5sLV/Deuvc477DziImMqWgrIjz7SycU0y9mG2/YWHGfSI/zaJ73+z8wa8UTvLMObrloMMcf5mHdiHWUektpn9Ce47ofxzXvXRPU/kMNE7MmRFXZUbCj4kUsDB09lHPHncsxJx7DcScd5zT0OF7R0WOP5t8v/5uzx5xNjz49OOyoGlsFhczVN/yG22fcQ3JKa34xehwZOEMkl1/0Jx6+//ece8IlREQIM269mHGnjuOOh+/gdzN+h/qUlHYpPDX7KWfyvu16PEQyuP1ANudu5rdH/5ZHFj1SeaN1p1W57ytnvMLs5f/lvc1vgs8DHufX+7NTnuWyIy9DLh0DPb/g/pNmMr73eN783y6u3N2X3r1h/Z3LuPDtC7lq+FWc+OKJVa57ZOIpPHHaYxXnq3asIj4qnuiIaH415wq+yJgPuwYxoFNXLpiaymur4PCOg7ls4siKPk/+/mj3qBs6RJkxdwbPLnuWrq26MmpqWx5+xqn9y4S/MKnvJE7qdRLR90cDkBidSFREFL1SnDReXVpVTfa96PJFFW07J3UmIz+DqQOm1hCza0dey5tr3mRnwU4GtBvA8w/05PcXQfW4pChPFMmxyRXnPZJ70CO5B7PPmg1AdIRzrzKfEwc/rOMwXpj2QsX9N+zZUKW/n0vP6VBl+LxbchceO71qQEHb+LZVzjsmdiQusupGt+3i21Uct28Pr7zihIlHR0sVIQOIjYzllV++UsOW6nik5sqg9gnteXbKs8yYO6PGA/qEHiew/KrlDE0dylc/f8Xr37/O4R0O5+nTnmZ30W7uOP6Oeu/ZUKr/3ROiE0iIrhyRO6HHCfyQ9QNZhVmkJqaSGJ1YUTey1wBGMoBzhpxDXfzn3P/w/vr3K4QMKsUsOSmaRyY+RLGvgFP7nQpA69jKH54e8fDM6c80/gMeRJiYNYLsomxiImMo95WDQnxUPJtzNuNTH/mlVSfG73/q/irnw48ZXjG/Eh0TzeOvPA6ZQ6FjVQ9l7pK5ACS3SeaNT9+oKL/o6osAiPQlUb7b/QValsBvrhzBb668uqLddxnL8VFOx9RWPPnEK+zaBR27FZLpXQPAseOO5dhxxzqN96ZCXiR4nWHWyAgPsVHOL+nDOlQK7KwJb3DlfZUPNXA+e2ys49XePeoJPts5my+3fskpfU8B4KgjovguBxKiEkiOTaZPivPAFXH+R3z9zNeDfsedOlX1Wg5PPbziOLVVW8jA+R6BpGjnl3DggyQY/rlRVa3StkfrHgBERVQOMydEBZ9CePWXrzJn9Zwqbf0PnmD3f/LUJ5k2cBr3LriXLkldiIqAww+v2mb99etrvZ+ftnGO4JR5a1/UFUwcjh7euKmQwe0H87/1/2P+r+bTMbFjjWtfeGGjLstRnY6qGKob2HZg0Dadkzoz78J5QeuGdRwGOD+Wbjn6FtontOeqEQ0fKdhXbj3mViI9kfzppD+xYc8G+j3Rj2Gpjm0/3dSwYfZpA6cxbeC0KmVHdjySb9K/oXVsa/q06cP7F77fZLYfrIRVzERkEs522hHAv1Q1aIypiJwJvAWMVNU0t+x24HLAC9ygqo2cFGlaVJWN2RtD75DbHVAoS3DClRN2OmHRKhCXjeBBfdGwpw+0CX7dAW0HsHZNNDFxXuJa7yVHtxIlMbRulUBiIrRrF7QbAIKHnj2he3co9XrIDJJm8bDu3fj+e+jUpYztSpVf5RP7TqRNTBs+uuQjjup0FL/Kh/iHK/vGR8VXRKF37RjFa8e/RnpeOp2SOgHQoV0U5IC6w7hx7qXri7WRIKHtfqLcf7XXXeeImV9E/KJWGz2Tezo2JXSo0jbQc4kgCi9lVX59B3LB4RdwweFVV6hGiGOHf66lOuN7j2d87/FVypKSIP+LOznt8uX0bdO3TrsBUuKcXK392/avUTdz7EzOfvNsjup0VI06v02T+0/m8A6H16ivjfvH3c+E3hOY0Kdx4d61MWvyLK446gqKy4uZ0Lvx146LimN45+G11n9/zfe1/g2bgocnVP5P0LdNXz69+FN+0fUXAHRv3X2fr//3SX/n7MFnM7j94H2+1qFC2MRMRCKAp4AJOJuyLRWRuaq6plq7JOBGYElA2WDgPGAI0Bn4WET6azPnnMoryWPd7nX1NwTIGkznbiXk5aWw150jSOlQQLYPxBfNgI7dKdF8kuJiKIgDnySy2T+HWy04ICkmiSOHOlkRyjWCnF3QrU17WsXVvK0fEQWFxETnF7XHAx5f8IQvsbEwYgRAFInF/ao8BDomdmTh1IUM6uSsM4uLczyZn3KdX59xUXEVHk90RDRdW3WtMmcR5QbV+D2KuFpsrj7fVGdkqVvVv09Vz6w2MfFz23G3MbDdQKYNnFZlwrx1TOWwzdOn/4Pr37++Yv4oFCI8jh1+Dy0UVq+GjRvvZ+zY0Nr3TO7Ju+e/y/Hdj69RN6bnGHbeujNoP//f8t3zg8w51kF0RHSTC5nfnrE9xzb5daszpEPta/LCwYm9Tqy/UQOIjYzlpN4nNek1D3bCmc5qFLBBVTepaikwG2d77ercBzwEgWF3TAVmq2qJqm7GycY8KhxG1vXQLCorIi0jjZziHNZkrQkuZOWxQfsOHRxN5zYpJAaMPEXHOlrcto2HxERom5REdGQ0KSmQ3KryT9GvZ2Un/8R5RARERUFcdAwjOo+gVVxovzrbJFdeN5SlB61jW9f7UD6hxwkVx5GeyAqvyz+vE8jVI5yhT7/XEBv86+Lh8Q9XOb9qeP1DR34R8X9HdXlz4Awjnj3kbESkivAFek0zjppB0Z1FDRImf9tgw3y10a0bIQuZn8n9J1eZL6mLLknOXE99Am8YBwvhHGYMtmV2lVWaInIU0E1V/ycit1bru7ha37Btt10bq7OcRG8b9mwI3iCnJ0TthcjiGlWRkc6DrXNniIlxhpWyy5yHbVx0zSUAgULTujX0ie5DbGQscVF1uF8hEHjdYA/bNr6GZ/YIvE6ggAQTgFP7nYreUxkp6iYXqTHMGNg3sH1d+If3/Otx/KIWCv7v5arhV+3zzgD+4IiG3D/cLLxsIV9t/apBomwYLZlm+5cuIh7gUWD6PlzjSuBKgOjoml5BWNh+pLOOKm4PsTHQvm0bfi6suTbL/5D3eCrTLHWI7oCitE9oX6N9daHxz5E0lghPBF6vF0+A8x1MzKJouFhOHTCVF1c4IdWBD8tQRCHGjU7u1q1qeWMeun7PbGQXJ4Kxvqix6oQqmvXx7JRnefuHtxnTo/bQ7/1Nz+SeFXOEhnEoEE4xq20rbT9JwGHAAvch2BGYKyJTQugLgKrOAmaBkwGkKY0PGjWW1xU0wkmZBMTFK6nJrSCyGyVlXnYWVWYMCPZgj/BE0Dmp5voUP91adas3iCFU+rftT3ZRdsUDP9AmKY9HI505o7ZtGu6VnDHoDNZfv54Xl7/I8M7DKzOo1DPMB04gyksvwSmnVC0PjA4MFb9nduagM9l7+96wTvjXRafETtx23G3Ncm/DMBzCOWe2FOgnIr1EJBonoGOuv1JVc1W1nar2VNWeOMOKU9xoxrnAeSISIyK9gH7AN2G0tQbp+dW0syyOob07Oh5FfmcoaE+8tAEgNTGV1rGhBwzURmpiKu2Sg4cmfvfddw26VmxkLJ2SOtUQ1SM6HsHgDgOJwbE3Pr5xQ2x92/TlvnH3VR1yDHG47qKLakZg7otnJiLNJmQQfK7QMIz9S9jETFXLgeuA+cAPwBxVXS0iM13vq66+q4E5wBrgA+Da/R3JWO6rtoFTVBFRUZCaCh3aRUJuDzxS6fVE+L/JsriK9SYHIpGeSOJiPQzp1LfJ7NQmyJ7SGDFrSMBFOPAvYm2MV2kYRtMS1jkzVZ0HzKtWdnctbcdWO38A2E9ZWmt6FDnFOTVbuc38QQyewGep/xLqqXi4XXvttXTr1o3bbnOGoG655RYSExO5+eabmTRpErm5uZSXl3PvvfdyQT276918883k5+dTXFzMRRddxOmnnw7AmjVrePDBBykvLychIYF//etfFBYW8thjj7FixQrKysq4+uqrmTBhAu3atSM1NdWxXTx4IppGDBoyzFgbDRGzfblPU/Lm2W+yPX97FVF9cdqLfJvxLbcdd5uJnGHsRw6ZUKeb3ryc5VmrQm6fH1nTEUwqd1RMEco0kpGbB/LY2c8CAQ/j8sqAigsvvJAbb7yxQszeeecdPvzwQ+Lj45k3bx4pKSls376d0aNHc9555+Hx1C4u99xzDyeeeCIZGRmMHTuWGTNmUFpayvXXX8/nn39O69at2bNnD4MHD+Z3v/sdbdu2ZfHixaSnp9O+fXtSUlIor75dcBPh98z2JSqwJUbdxUfF10jldPGwi7l42MXNZJFhHLq0vCfIfqDEU3PYLN4bEEiBEi1lVfyD2MhY2DWAaKmcuznmmGPYvXs3W7ZsITMzk9atW9OnTx9KSkq46aabWLRoER6Ph507d5Kenk636iF+AcyePZubbrqJsrIyMjMz2bBhA1lZWYwePZrU1FQiIiLIysoiIyODjz76iDlz5hATE0NJSQn5+fl4PB5atdr3eb1wERWmHQsMwzg0OGTE7O+uBxUMr7cQkQg8HiduPC0jrWoDFY7qfGS9czRHDkmqsX5qypQpvPrqq2zfvp0zzzwTgFmzZrFr1y5WrVpFTEwMXbp0obCw9i0cFixYwJIlS1i0aBG7d+/mvPPOo7i46tq2pKQkBgwYQG5uLqWlpezZs4d+/foxePBg8vLyyMrKIjs7m549e9b5GRrDjaNvZO7auRXpfBpDS/TMDMM4cGjeGfSWwvbhIQUbRERUm0cDLrroIt566y3ee+89fvWrXwGQm5tL+/btiYmJ4b333iMjo+5NAHNzc2nVqpW7F1oGaWlpqCrDhw9nyZIl7Ny5s8IDa9++PePGjWPWrFmUlVUuL+jSpQvVNy9tKsb1Gofeo3RM7NjoazR3MIdhGC0be4KEQOfal4bVy/DhwykoKCA1NZUePZzs7JdffjnLly+nf//+vPDCC/Tq1avOa0yaNAmv18ugQYN48MEHOeqoo9iyZQvZ2dk8/vjjnHvuuQwfPpzJkyezZs0apk+fTklJCcOGDWPw4MG8+OKLbNq0ia5du9Z5n+bEP9920+ibmtkSwzBaIja2Uw1/ZJ4fEaFzp3275rp1VXM6durUieXLa+5GCwQdboyJieGrr74K2n7IkCGcc07NzBevvFL/flIHGk2VkcMwjEMPE7NqeN3lbJLfjYQE6JF64AZNGIZhGA4mZtXw+hwxU28ESdKOOAuyMwzDOOA56OfMfD5fg9r7t6X372J8qBK4K7NhGMaBzkEtZv61V+W22CMAACAASURBVA0RNP+W7vgiOVSf46rK7t27iY2NrXg/EDGhNQzDz0E9zNi7d282bdrEjh076mznT/soEsGuAnc7l71RFOVGsmdPs25u3WyICBFu3q4DLQpyX/cfMwzj4OOgFrO4uDiGDKl/+/RvvhlEQsJQhgx5g2F/dJPvPraRDUt706dP3X0NwzCM5uegFrPQ8QBVhyJz0zvSat82eTYMwzD2Ewf1nFmoiHhQdcTMU9aKHttvoFVcfDNbZdRG27i2AM26h5lhHEqIyCQRWSsiG0Skxk60ItJDRD4RkZUiskBEugbUeUVkufuaW71vU2GeWXExKR/l4TsiDx2i+CLzSYm3tWUHMn866U/0bdOXaQOnNbcphnHQIyIRwFPABGAbsFRE5qrqmoBmjwAvqeqLIjIOeBC4yK0rUtUjwm2neWb5+fS9cysJX+1ge+4uEKV9Upvmtsqog/ioeK4bdZ3lczSM/cMoYIOqblLVUmA2MLVam8HAp+7xZ0Hqw05YnwYhuKZXi8gq1/1cKCKD3fKeIlIU4Jo+HTYj3Yg98fp4Z+lSAIZ3PTxstzMMw2hhdAF+Djjf5pYFsgL4pXt8BpAkIm3d81gRSRORxSIStuGUsA0zhuiavqaqT7vtpwCPApPcuo37wzUl0v0KvF5eWfkyFLbhjJGN38rEMAyjhREpIoH7Xs1S1VkNvMZvgSdFZDrwBZAO+Nc19VDVdBHpDXwqIqtUdeM+W12NcM6ZVbimACLid00rxExV8wLaJwD7fxWs65lR7mPd3jTYMpYh/RL3uxmGYRjNRLmqjqijPh0I3Dm4q1tWgapm4HpmIpIInKmqOW5duvu+SUQWAEcCTS5m4RxmDMU1RUSuFZGNwMPADQFVvURkmYh8LiLHh81Kv5j5vGTrFuIKB5BgQXKGYRh+lgL9RKSXiEQD5wFVohJFpJ1IxST27cBzbnmKiMT42wDHEuDQNCXNPoOuqk+pah/g98BdbvF2oLuqHgncDLwmIjVCDEXkSncsNq28vLxxBrjDjPleLz4pJyW2bT0dDMMwDh1UtRy4DpgP/ADMUdXVIjLTnR4CGAusFZF1QCrwgFs+CEgTkRU4gSF/rjbV1GSEc5ixXte0GrOBfwKoaglQ4h5/63pu/YHAcV3ccd1ZAAkJCY0bonQ9sxycBMOpSSZmhmEYgajqPGBetbK7A47fAt4K0u9rYL9E1IXTMwvFNe0XcHoasN4tb+8GkOBOGvYDNoXFShFUYLfXWTTdOcXC8g3DMFoaYfPMVLVcRPyuaQTwnN81BdJUdS5wnYiMB8qAbOASt/sJwEwRKcPJM3W1qu4Jm60RQtrezsB2Rh/WIVy3MQzDMMKEHCzbaCQkJGhBQUGj+vpiIxhzSX8Wdv6RLyfv4rjhNtRoGMahgYgUqmqLD3tr9gCQAwGNEFYlZwAwpLcJmWEYRkvDxAwgQijx+PCsvoDk5OY2xjAMw2goJmaAeoRyj5ckTwds30fDMIyWh4kZzjCjN6KUVnG2gZlhGEZLxMQMKIsCjfDSOsHEzDAMoyViYgbsdbOAtE82MTMMw2iJmJgBG6M6AdCpne0ubRiG0RIxMQNeGVQCQLxpmWEYRovExAz49+CdAOz17W5mSwzDMIzGYGIGTF7nDDOe3uG6ZrbEMAzDaAwmZoD/a0iMTmpmOwzDMIzGYGIG+DzO1+Dx2IppwzCMloiJGeBz035ERpiYGYZhtERMzDAxMwzDaOmYmAFe92uIMDEzDMNokZiYUemZRUQ0syGGYRhGowirmInIJBFZKyIbROS2IPVXi8gqEVkuIgtFZHBA3e1uv7UiMjGcdqoI+Dx4TNoNwzBaJGF7fItIBPAUcAowGDg/UKxcXlPVw1X1COBh4FG372DgPGAIMAn4h3u9sFAuAoh5ZoZhGC2UcPoio4ANqrpJVUuB2cDUwAaqmhdwmgCoezwVmK2qJaq6GdjgXi8sKAJqYmYYhtFSiQzjtbsAPwecbwNGV28kItcCNwPRwLiAvour9e0SHjP9c2Ziw4yGYRgtlGZ/fKvqU6raB/g9cFdD+orIlSKSJiJp5eXljbbBh8c8M8MwjBZMOMUsHegWcN7VLauN2cC0hvRV1VmqOkJVR0RGNt7JVAGbMzMMw2i5hFPMlgL9RKSXiETjBHTMDWwgIv0CTk8D1rvHc4HzRCRGRHoB/YBvwmWoVxzPzIYZDcMwWiZhmzNT1XIRuQ6YD0QAz6nqahGZCaSp6lzgOhEZD5QB2cAlbt/VIjIHWAOUA9eqqjdctvrUohkNwzBaMuEMAEFV5wHzqpXdHXB8Yx19HwAeCJ91AfcSi2Y0DMNoydjAGhbNaBiG0dKxxzfgs3VmhmEYLRoTMyqjGT0era+pYRiGcQBiYobfM/Pg8fia2xTDMAyjEZiY4c6ZqZiYGYZhBCGEpPE9ROQTEVkpIgtEpGtA3SUist59XRIuG03MAEfCTMwMwzCqE2LS+EeAl1R1KDATeNDt2wa4ByeV4SjgHhFJCYedJmZUBoCYmBmGYdSg3qTxOCL3qXv8WUD9ROAjVd2jqtnARzg7oTQ5Jma468wQIiJMzAzDMKoRLGl89cTvK4BfusdnAEki0jbEvk2CiRmVnpmIiZlhGIcckf6E7e7rykZc47fAGBFZBozByaUbtqxNwQhrBpCWgmKemWEYhyzlqjqijvp6E7+ragauZyYiicCZqpojIunA2Gp9FzSBzTUwzwzwCe6c2X79IWEYhtESCCVpfDsR8evJ7cBz7vF84GQRSXEDP052y5ocEzMqPTMbZjQMw6iKqpYD/qTxPwBz/EnjRWSK22wssFZE1gGpuHl1VXUPcB+OIC4FZrplQRGRt0XktABhDBlRPTiyXiQkJGhBQUGj+g6/+Di+67CR/HtXkJjYoYktMwzDOHARkUJVTWhuOwDcXVQuBX4BvAk8r6prQ+lrnhngyLngX3FmGIZh7H9U9WNVvRA4CtgCfCwiX4vIpSISVVdfEzPc3IwWzWgYhtHsuCH904EZwDLgMRxx+6iufhbNiOuZqcfEzDAMoxkRkf8AA4CXgdNVdbtb9YaIpNXVN6yeWQj5vG4WkTVuPq9PRKRHQJ1XRJa7r7nV+zYlKooFgBiGYTQ7j6vqYFV9MEDIAKhn+UD4xCzEfF7LgBFuPq+3gIcD6opU9Qj3NYUwou6i6f28xs8wDMOoymARSfafuCH9vw6lYzg9s3rzeanqZ6pa6J4uxllQt9/xe2YWAGIYhtGsXKGqOf4TN5/jFaF0DKeYNTQn1+XA+wHnsW5qlcUiMi0cBvpx5swEVRMzwzCMZiRCRMR/4o7wRYfS8YAIABGRXwEjcHJ6+emhquki0hv4VERWqerGav2uBK4EiI4O6fMGxZ9o2DwzwzCMZuUDnGCPZ9zzq9yyegmnmNWbzwsqFsndCYxR1RJ/uaqmu++bRGQBcCRQRcxUdRYwC5xF0401VFHzzAzDMJqf3+MI2DXu+UfAv0LpGE4xq8jnhSNi5wEXBDYQkSOBZ4BJqrozoDwFKFTVEhFpBxxL1eCQpkX8/zExMwzDaC7U8Sj+6b4aRNjETFXLRcSfzysCeM6fzwtIU9W5wF+AROBNd5h0qxu5OAh4RpxYeQ/wZ1VdEzZb3f+YZ2YYhtF8iEg/nF2qBwOx/nJV7V1f35DETERuBJ4H8nFcviOB21T1w7r6qeo8YF61srsDjsfX0u9r4PBQbGsK3FVmqFpovmEYRjPyPHAP8DfgRJw8jSEFKoYazXiZqubhpO9PAS4C/txwOw9M/OmsbJjRMAyjWYlT1U9wkuD/pKr3AqeF0jHUYUZ/qOSpwMvucKHU1aEl4U80bMOMhmEYzUqJu/3LeneaKh1nKqpeQvXMvhWRD3HEbL6IJHEwuTHmmRmGYRwI3AjEAzcAw4FfAZeE0jFUz+xy4Ahgk6oWikgbnLHMgwKfWGi+YRhGc+IukD5XVX8L7KWBGhOqZ3Y0sFZVc9wFzncBuQ2y9ABHLDTfMAyj2VAnAu+4xvYP1TP7JzBMRIYBt+BENL5E1YwdLRZLZ2UYhnFAsMzdJeVNoMBfqKpv19cxVDErV1UVkanAk6r6rIhc3jhbDzycRMNgWfMNwzCalVhgNzAuoEyBJhOzfBG5HSck/3g32qTOLaxbHOaZGYZhNCuq2uhYjFDF7FycVFSXqWqmiHTHyd5xUOBfNG1zZoZhGM2HiDyPf7VUAKp6WX19QxIzV8BeBUaKyGTgG1V9qcGWHqD4F02bZ2YYhtGsvBdwHAucAWSE0jHUdFbn4HhiC3BWZT0hIreq6lsNs/PApPJngImZYRhGc6Gq/w48F5HXgYWh9A11mPFOYKQ/s72ItAc+Bg4KMUMUfOaZGYZhHGD0AzqE0jBUMfMEbtGCE20Szl2q9ys2Z2YYhtH8iEg+VefMMnH2OKuXUMXsAxGZD7zunp9LtWz4LZnKLWAsNN8wDKO5UNWkxvYNybtS1VtxdnQe6r5mqWpIatkyUFCPDTMahmE0IyJyhoi0DjhPFpFpofQNeXNOd2Lu3/U2bIGoqLMtgHlmhmEYzck9qvof/4mbQvEe4J36OtbpmYlIvojkBXnli0hefRcXkUkislZENojIbUHqbxaRNSKyUkQ+EZEeAXWXiMh69xVS1uTGUpHOylseztsYhmEYdRNMk0JyuupstC/jl24G5KeACcA2YKmIzFXVNQHNlgEj3Ez81wAPA+e6WfnvAUbgaM23bt/sxtpTFypOAIi3vF59NgzDMMJHmog8iqMdANcC34bSMZwRiaOADaq6SVVLgdnA1MAGqvqZqha6p4uBru7xROAjVd3jCthHwKSwWSoCCmWlu8J2C8MwDKNergdKgTdwNKMYR9DqJeQ5s0bQBfg54HwbMLqO9pcD79fRt0uTWlcDobxgZ/3NDMMwjLCgqgVAjSmpUDgg1oq5e6SNoIH5HkXkShFJE5G08vLGz3dpZASigqzf1OhrGIZhHKyEEP/QXUQ+E5FlbgzEqW55TxEpEpHl7uvpeu7zkYgkB5ynuMvC6iWcnlk60C3gvKtbVgURGY+TYWSMqpYE9B1bre+C6n1VdRbOkgESEhJqJKcMFY2MAMqJ2BxSCjDDMIxDhhDjH+4C5qjqP0VkMM465J5u3UZVPSLE27VT1Rz/iapmi0hIGUDC6ZktBfqJSC8RiQbOA+YGNhCRI4FngCnVMozMB052VTkFONktCw9uomHf3px6mxqGYRxi1Bv/gBOo18o9bk2IyYGD4HN3ZQEcz44gWfSDETbPTFXLReQ6HBGKAJ5T1dUiMhNIU9W5OMOKicCbIgKwVVWnqOoeEbkPRxABZqrqnrDZKo6eUZAfrlsYhmG0VEKJf7gX+FBErgcSgPEBdb1EZBmQB9ylql/Wca87gYUi8jnOY/l44MpQjAznMCOqOo9qaa9U9e6A4/E1OlXWPQc8Fz7rAu4FjqKZmBmGcegRKSJpAeez3CmchnA+8IKq/lVEjgZeFpHDgO1Ad1XdLSLDgXdEZIiqBl0HpaofiMgIHAFbhrNYuiikD9FAgw9O3HVmFBajqrheomEYxqFAuaqOqKM+lPiHy3GXT6nqIhGJxZn/2gmUuOXfishGoD+QRhBEZAZwo3uP5cAvgEXAuPo+xAERzdjcKAoqeIp9+Hwl9XcwDMM4dKg3/gHYCpwEICKDcDbWzBKR9m4ACSLSG2dLl7rCxm8ERgI/qeqJwJFASMEM5pkBig9BiCgCrzePiIjY5jbJMAzjgCDE+IdbgP8Tkd/gzNxMV1UVkROAmSJShrPH1tX1xD8Uq2qxiCAiMar6o4gMCMVOEzPA+e49RBSD15tPiHvBGYZhHBKEEP+wBjg2SL+GJqjf5q4zewf4SESygZ9C6WhihjPM6PfMyi0/o2EYRrOgqme4h/eKyGc4Yf4fhNLXxAx3zgwhcq8zzGgYhmE0L6r6eUPaWwAI4B9mjCyA8nILzzcMw2hpmJjhDjOKEFFgnplhGEZLxMQMwJ0zczwzEzPDMIyWhokZ7pyZOMOM5pkZhmG0PEzMAMcz8+ApA19hWDazNgzDMMKIiRmVnhmAd3dmM1tjGIZhNBQTMwAq8zH6sk3MDMMwWhomZvjXmUU4xzlZzWuMYRiG0WBMzHBzM7rDjJqzu5mtMQzDMBqKiRngDDO6YpZn0YyGYRgtjbCKmYhMEpG1IrJBRG4LUn+CiHwnIuUicla1Oq+ILHdf1bcbaFKcABBnzsyTXxDOWxmGYRhhIGy5Gd09bJ4CJuBss71UROa62ZX9bAWmA78NcokiVT0iXPZVRXG33EHyS1D1VpwbhmEYBz7h9MxGARtUdZOqlgKzgamBDVR1i6quxNnnphmp9MwiCy0LiGEYRksjnGLWBfg54HybWxYqsSKSJiKLRWRa05pWFXUXTfviooncC+XlueG8nWEYhtHEHMhbwPRQ1XR3q+1PRWSVqm4MbCAiVwJXAkRHR+/DrZwtYLRdMlE5Oykp+Zm4uJ77cD3DMAxjfxJOzywd6BZw3tUtCwlVTXffNwELgCODtJmlqiNUdURkZON12Z81X1I7E50NBQWrG30twzAMY/8TTjFbCvQTkV4iEg2cB4QUlSgiKSIS4x63w9mOe03dvfYFJ2u+dOxC9B4oLc0I360MwzCMJidsYqaq5cB1wHzgB2COqq4WkZkiMgVAREaKyDbgbOAZEfG7RIOANBFZAXwG/LlaFGTT2irOMKP07EVsJpSX7QnXrQzDMIwwENY5M1WdB8yrVnZ3wPFSnOHH6v2+Bg4Pp23V7oggMGgQkYWg29Kh//67u2EYhrFvWAYQwL8FDF2cYEvJ2tHM9hiGYRgNwcQMNzcjAq1aAeDLyWlmiwzDMIyGYGIG+EPzad0aAMkzMTMMw2hJmJjhXzRd6ZmRl9+8BhmGYRgNwsQMqEhnVSFmBezZ8zGqzZxlyzAMwwgJEzMAcT2z5GTUI0RnKytXTiA9/YnmtswwDMMIARMzAoYZo6Px9e5KwmanvKhoc/MaZhiGYYSEiRlQsc4MkEGH0X4hHDsVPJ6oZrbLMAzDCAUTMwA3NyOAp0cfAKLyQPRAzsNsGIZh+DExozLRMADdKnMje8qkmSwyDMMwGoKJGRA4zEj79hWlEdllzWSPUSe7dsG110JpaXNbYhjGAYKJGVRGMwIkJ1cUdz71qWYyyKiTW2+Ff/wD5sxpbksM45BARCaJyFoR2SAitwWp7y4in4nIMhFZKSKnBtTd7vZbKyITw2WjTQpRudM0ACkpFeURuUXNZJFRJ16v8+6zdYCGEW5EJAJ4CpgAbAOWisjcajuZ3IWzM8o/RWQwToL5nu7xecAQoDPwsYj0V1VvU9tpnhkAvso5s4SE5jXFMAzjwGIUsEFVN6lqKTAbmFqtjQJu1glaA/5NIacCs1W1RFU3Axvc6zU5JmZUCwDp0aN5jTEMwziw6AL8HHC+zS0L5F7gV+7+lPOA6xvQt0kwMYOqc2YdOsDzz1dUldlGnYZhHNxEikhawOvKRlzjfOAFVe0KnAq8LCL7VV/CerMQJg1PEJHvRKRcRM6qVneJiKx3X5eE087AdWZA5ZwMUFDwfchX2bTpdn7++W9NadihxfbtUFwcenvV8NliGIcO5ao6IuA1q1p9OtAt4LyrWxbI5cAcAFVdBMQC7ULs2ySETcwCJg1PAQYD57uTgYFsBaYDr1Xr2wa4BxiNM756j4ikEDYCPDOoImZlZbtCvsrWrX9m48abm9KwQ4vOneHMM+tvJ7b+zzD2I0uBfiLSS0SicQI65lZrsxU4CUBEBuGIWZbb7jwRiRGRXkA/4JtwGBlOz6zeSUNV3aKqK4HqYWkTgY9UdY+qZgMfAZPCZajW4ZmtXn0mubmLw3Vrozrz5jW3BYZhBKCq5cB1wHzgB5yoxdUiMlNEprjNbgGuEJEVwOvAdHVYjeOxrQE+AK4NRyQjhDc0P9jE3+h96BuWSUPAmTMLFLMJE6pUL1t2NGPH2pBWWLEhQ8M4YFHVeTiBHYFldwccrwGOraXvA8ADYTWQFh4AIiJX+icty8vL9+FK1YYZ+/aFsWMBiCjYJxONUPGG5ceaYRiHCOEUs32Z+Aupr6rO8k9aRkbui5NZzTMD2LgRgO6vBWluND2NWQBt3pxhGC7hFLNQJg1rYz5wsoikuIEfJ7tl4UGqeWYACxcC0OM1GPhnLOigLnJy4KGH9i0jR0M8M/tbGIZRjbCJWSiThiIy0l1kdzbwjIisdvvuAe7DEcSlwEy3LDy2oniqPyC7d4eRIwHo6JdR8wSCc8MNcNtt8OGHjb+GpaYyDGMfCGtuxhAmDZfiDCEG6/sc8Fw47Qu4W2VuxkBat65y6i3OJyKuFV5vMdu3z6JLl2txViCAHspCl5vrvJeUNP4aNmdmGMY+0KIDQJoM8dWcMwPHOwsgN+MDALZu/RMbNtxIZubLFXWqtl3MPmFiZhjGPmBiBgQNAAH4+9+rnMbe8hegciG117u3os7ns7219omWGABSWgo7djSvDYZhACZmDsECQACSkuCsyixb8f9NIzv7UwoKnJ0PAlOPaVYGY0+E1A/Cbu0+k5HxLxYsEIqKNjW3KZW0xACQiy+Gjh2bX1QNwzAxcwgSAOLntNOqnK5YcRK5uZ+7ZwFitn4dAF3+Gw77mpbNm+8CYMmSPmRl/aeZrXFpiQEgb7zhvAcK8fr18PnnwdsbhhE2TMygZgaQQKZNC+kSPt2H4If9jD9oBSA/Pyxp0hpOS54zC1yw37+/s+A+Px8KbMW9YewvTMyg9mFGgOTkKvMiRw/dWHG8c+erFBf/TFHRFnw+Z1dqTymwe3c4rd1nRD14mlJ7GzjMVlKynRrp2VqymAWzvVUr6BK+DGyGYVTFxMylVs8MnD3OHnoIgJi2fejR426id0Nu7kKWfNWdtE97UVTsiFziJqBdu1ovtWTJQNLTn67foPHj4fHHG/IRQqb7rHxOmASeBuy20lSUle1m0aLObNz4u6oVLTEAxE9tQuxfsmAYRtg55MXMvz6sTjEDOOaYisNe3x7OMWdB65VOdpDjJ0PO3HtDuJeXoqK1rF9/TfAGTz4Jy5c7x598AjfeGMpHaDAd/psPQERRE6+PCyEww7/Z6a5d1SYXW2IAiJ99ygtqGEZTYGKG8zD31DbM6GfEiMrjS5y9Qlv9AKkfO0V96nC2ysp24/UW4S3aQ+d3gNqe29dfD0ceGZrh9VFaClu21CjO/ce1ROU6XtCo6Y28tiosWwaFhY3o7P+eq4loSwwA8ZOVBX/+84HjKRrGIYiJWaieWWwsPOcmJHEf4tHatvbressoLt7Gjh2v8dVX7fjyy3i8f72P/o9Bp2BbdjXgQVhUtLF+j2rGDOjVq0YQQutr/1FxHJUX8i2r8uSTcNRRkJDg7A7dKKrZ35g5swNFPK64Am6/HT77rLktMYxDFhMzQhQzgAsugJ49K067PbMb9QT/CtO+OpzFi7uRmfl8RVnpjrVALSJSVplBJGvnv2s1ITv7M5Ys6cuOHa/Wbet77znvxQETY8G8n7JGiMiyZZXHW7c2qKuTsjMIzSFmL70Ea9bs2zXASbQMUFS079dqKnbvhi++qDyfNAl+//vms8cwwoyJmftA9EgIX0VMDCyuuuu01DI81vrttRw7FXJ2OuOQkfmQu91JxCvVnttlZbvR4soHYVZmgJh99x0A5eV5lJRsZ+9eZ04tPz+tblvdz+UrDfDMymqm3IpdnlH3dRpCCEOFlWm/6hhmFIE336z/dmWuUC9bBr17Q0YDP8sll8CQIQ3rEwz/D6EGCHJp6S727l257/eujfHjYcyYyu91/nx4+OHw3c8wmplDXsx86vzPXmtofnVSU52hOzejfm30f8zxwCKdWAuOmwJd33aOxQsLFgg//ngpxcU/89VX7UjfXJk6a++eRZUXGj4cgIULW7N8+QkVno1/rZjXW0BxceCm3O7n8jmisXVDwAavQcSsy/mN2LDt+eeDlwd7mJeVVcmm7xezGsOk1fu+/DK14femMzP+5RS89hps3gxPhxAlGvSC++jh+cWsAYEg3347nLS0Yft237rwBxIdqsEpubm2zu8Q45AXs4oAkIZEyMXHwzffwAkn1Nu0Y9LZNcr8nllm5gvk5TnCtXX9vRX1JXu3VGnv9ToeSFHRBjZt+h0JmyFiTzEbNtzC4sW9WLy4akJkAFyRLtsbIHRBxKwKZWWOpzIvYFIvNxdGj4YffwSoSOVV+WECvrdgYvaHP8DEifDVV45ZtSVkru7V1SEwfkHfm7fCKejc2XnPq2cScPdu+PWvnaHXwOvvy9Y1gTRAOEpKtpKwCfj006a5d22UNjJnaH6+8+MgXPOS4Raa5GRnx3jjkMHELNQAkGC89x5s21ZlHq06fTrcybHH7qpSlrgB2iyGYTdD9sPnAuAJeMYffmfVa+TkLKg4jsyHkZdB+xvfZNu2RykrywIgI+P/2LbtCYqLfyYnZ2HFQ0jKKrN91CVmPl8pZGY6c0hXXllZ8f77jnAPGkTpyi9YurTasFzgw87rdbaBeeaZSnFaudL/Idz71DLMWF0I6xIzNxxUtP62VbjrLvjnP+HVV6sKT2Mf+H4a4ZkBjLwcOOkkystDXI/2xRfBReCddxwbsrJq1jX2s11/PVxzTdV5t6Zi2TJITIT/hDmVWmZmeK/vZ88e5/t/8cX9cz8jKCZmDQkAqU5SkpPl4aOP4Jxzgrc54giiXv9flaK2S2Do7ZCyDAb81SmTAJ1JrjaVUlj4AxF7IXoPxG9xymK/ryqQ69ZdyYYNN7B4cXeWLz++wjOLXL0J74fvkZ//LVvW3xPUxN27P+CLL2JYsWK8UxAoDvHxFYdRw0+soUGBD/DS4izHE7v6aucBC5UBKLGx7qVrebg2YL5JfW5bvzPnF+n6/ob+B7tq1Yd8ZMC2frt2wbvvhmxLlfs2ckhv9epz62+0daszB3bVVTXrHWY/RwAAGINJREFUHnvMef/++5p19XnjtbFtm/O+r0IfjKVLnfcPWkBW7lDY5CbsDlOSAyM0wipmIjJJRNaKyAYRuS1IfYyIvOHWLxGRnm55TxEpEpHl7quRkyH14/M1YpixOn37Oklnd+0KXu+uS6uNwxOeov/7/Wut37jxZkZfDMecCTHuj2/1aE1hCcCfLqrnHWuImHg63347gsytwb/GVatOAaAob52/c2VlXFzFoZT7qoguAGVlFQuhyx66zfHioEKcCnPcB2yEfxPT4J6ZVo8ErNMzc+cN/WIW6qag/muKVH3IR1R6r4VjesOUKejevTSYYHaE4NkUFKyo/9p+r+uHH2rW+SNqgwXgBBOjgoKqUa7B8PeLiqrftobw3/8GF+SWTOC/K6PZCJuYiROh8BRwCjAYOF9EBldrdjmQrap9gb8BDwXUbVTVI9zX1eGy07cvw4zVadvWeUjOmVMj6rHObmc/TMrsdbXW9/kHRGc7x0Puc96j8mDsOMdbC4qvpqcjtTgOcekQs7NyqNPrLSQ9/Wny8pbUEBVP9WdjWRm5ec58WMLaosqM8YmJAJQXZlW0g6rDjOXluRXnOmlCTcOys53gDqB0+zp8xQVuz2rDjP4HczXPaNu2J9izZ35lQW1iFrC8In6NE7GTublyPV59lJW7uTiDheaPGRPCMGgI//b8C9QDflxU4Lc/iHfrKwkyLJmY6KxBrAv/9/Pll3DTTfXbFyq33155fLA8/MMhZp984ux0X988sFFBOD2zUcAGVd2kztjSbGBqtTZT+f/2zjtMquru458fIAioNNEgqMArsb9iiQGVR41dSYwtokiMGo29JrHGbNSXV6NvULHhgyQaC7HFIAYbroXQQaQIuLsiuCwsfRtsmZnv+8e5szOzO9uGXZaZPZ/nOc/cU+4p98y933vKPQeiHc1vAqdYs6hK44m2zJot2Q4d4KKL3GzHBx90S1LF38DJWLmyXu9965mlvltht+Co4fwnE7Oyofvw48tg6MUxoQpXFZGTcx3z5w8hvDXxZmqXpGWWjFUr3HtJdZxbi6GykvINi+hUCKqKMG1ad5YsuSAIl/ggrqra7PYLGzkScnLouM+BFJ8zgLKyJbFv1Wq2zGq0jHJzb2bhwjPdGM2oUQndkZsK4yZ9JGnRbC54r5YbAHl58Fbid4DVY151fWc2dy6ce2499dyI2zBFMSv47okEe/Us0uh40l//6h7CNVtq0ZbZ/fe7bsw4QZYiLFt2FcXFcxrOd33Udc9Nm+b8FrbgpwvNxerV7vtTSF3MJk1y45Px3H+/E7J0uAY7CS0pZn2B+Dnj+YFb0jByT6giILqsxgAz+9LMPjOzYS2VyXC0m7GxU/MbS7t2bsLB44/D6NGu1ZCTA1de2azJHH7Yuwwe/AXDfrSBH+x9BVYFP1p6DxZpnxgwDO2SDEt1nhP7NisqVB03wwFPueMV3yQuCFxTzEL5uW5WXg1K1n9GScmC6vChsjVUDjucfgffw9ARsO9Yl27J8ndr7egNUFw0A638DoC8L68HoPsn65kz57DqHQqiLbOyje4j7srS1ax+72ro3h2tzq+OK3LJhfDyy5TMDj40N+ObxZfFEos+uOPEUFtLYmUpWUBFRbDSyRFHuA1bX4190lAtrnWJ2bHHugdW//6EQsWEw4mtpUa9SEXf0JOJWbSbNMmYXa873kwQ64KCuBbnuHFujBNq75hd8yUlTuyqqjawdu0E5s8/tsk7rKsxZX07+Ibl44/rDlNcHPNfsSJ592tdvP8+jBjR+PDJuPdeJzh33OFecCB1MTv33NqflUTjGjbMzS4eP37nWfFmJ2VnnQCyBthP0pHA7cCrZrZHzUBmdo2ZzTWzuaEUB9+bvWVWF+3bu7G1P//ZzRa85ho30WA712K04mK6dzqa9rv14sDX+nHi6dD1+tG1WjqHD5zIMVfXPr9d3GU77L7Ycb+33CcElcUrEsPXeHZ1+M0tdE4yaWyfSZCTc311+LylN9FxdqwrtVfQC3toFnDbbbXO71AKkYgTl5KCxIdaOBK0UiJQXDyL4vVuGanNhf+m3VPjoaiI8OQ3AbeYclnEqe0uwUIdoXBJYiv1pz/l29fPonxVbOyqsngl33xzA+HwNubNO5I5cw5zHtHZhCNHxs4PxHDbpoZXE5n5Xjfad9iNH8TNfajYlh/s/J1HOFxWe3scIJLvWnWVnZOMy0XFLMk4WOeFGxKEac2a8THPa6+Nnbt5c2LLrqaYxa3DGa0XgIqK/Fphw+EyNm1KLkTRFxHAfe6RrDs+ei/W9/C+9FI47TS0do37YP6QmiMY0SjCbN2am+h41llujLsRk47C4TJycm6uPeN09GjX8xLdoBWIEEISkUdGU/ng7Q3GLYWJRELxDskDnnOOWzKtuT4hyVBaUsxWA/vG2fsFbknDmFkHoBuwUVKFpI0AkuYBeUCtGRKSnpd0jKRjOsTPSGsC4eaYANIUevVyb8TjxsHw4W6Fj0gExoyBp5+GiRObNstr5EjXAgTswQfrTnbXhr+Ji47LRelQkih2AIc8XuudIik95kNx8YxYa6/m2F5wuXet0SCI0u1raL8kB4AfPhZz36UIiovdA9DCsG7dxOpJKfGtxrKFblX+YWfD7jlBWsHw3aZXbq7+mD1Kz4feZ+XiO6rtnRdvoqDgGRY+04WuuRAKbaKk5EuSYeUu4bJFk5IXJj6dYOGWg+JGh6P5njXrAL74Yjfmzh2c+FH50KG0u/13AGyocsJdWPgqFRWudRvGienmginuvJqTVxLEJrHFHiHwO/LIWGtl4sTq7wqriWt1hsOx+G3KR9CxI8VfTKh2W7LkQhYuPI3KinVuFuvZZ1ePpSYI9aefwtChcPHFTlhqzkrNz4fjj3ct2xpEFrqVcQpyn6jlFy8KK1bcz+zZg9i27bva4eLKFIlUsqlwCorvcv78c0qzfsmmmWP57rus2ufXoKR0PoWFL9PurnvpeP8Ywh9Nrjf83LmDmTatW8yhgYlM4eLgJjrxRDeTGlxZb7wxNkO0LSOpRQzQAfgWGAB0BL4CDq0R5gbgueB4BPB6cNwbaB8cD8SJXs/60uvSpYtSIX/jJpGFhj80JqXzW4zVq6XDDpPc31W68073e+utMbemmOzsJp8TOf54hU8cllp6oFl/Q6E9OkqggrMS/Sp7d9asv6Gqrk2Lc95TaPVwd7zqIrR06VVaN8zZNwxJTOfz9+qOZ9veifYth6B5Tye6ZU+NHedeg7Kzk8dVvmdq16c6n++6uLM/QUvuQYUnof+8gYqLv3T/hbiwq89BeXn3KDsbzXgZhSrLVHzKvhJo2W2ooOAFbThl98RzXjiv+jj/uj4JfhU9auSnRnpRE166WOHSLZKkoo3T9emHLs8VV7i4l9+GwuEqSXJlyUZl6+bXirvyh32SX4dTTpEIyvzb39b2D4WktWul/faTJk6sds/552mJeZekyspqt+nT93V5mfycIn/4g1at+r9qv9CaldWnFKx41qV/2/BYPHHpL53yE6m8XHrrLen555OWYcuhaNmyqxPdZ86UfvMbqaqq1i0evU7VYX/3Oykcdp4nnFAr/kVZKD//mZhbWZm0cKE77tYt5UcNUCa1jA7sSNOykcPZwDe4ltW9gdsDwM+C412BN4BcYDYwMHC/AFgCLADmAz9tKK1UxWzV+o0iC/3sf55I6fwWZ9s2d3NKUiTifj/5xFXdtdcmfzA0ZAYMSO28ncDk3BATrM2Ho+yP3W+ysIUnNi3urfvUf/78MS1TpkV/QmX7opzrYm4VPdDSpVdo7eqXEsKuOZ1qIRNo5ZVdVXiSO869Bn19V9PSruqcaK/rBWDVr3tIoAV/aaeKowdKuHyUXn6yBFp+i7NvHH+tZr7sjtfMeSQhjpKSr1Tav/78ZGej0KXn166bgq9U/saztdw3nr9fzB7lsccS4osXjOxP4q775KMUDleqvLxABTOzJFCoW6dYPCnU5XfvjEjuN3durVu7lpiB1r30a1VUrJOG1X6JXJSFpk/vF3OLD9OjR8qPGC9mO5lJVcxWFK4XWejc0U+mdH6rs3mz9OWX0pQpUmGhsx91lKvaulpjubl13ox1mgMPrN+/Y8emx9kMpuSAdop06bTD0w3v0vxxlvdNLEf2VFRwZmKYtT9BOdejvKubJ82aLeOvHkkebsOQII894/KXjfJ/HrNv/YH7rdwd/edNtPHoxDiys2lQzGqWN2qmT0TLb22gPAMGqCIrsefi67tR4ckxe9GBseM5z6GK/btrwaPo+7dGubzvuWvs3mrGut3y9I0Kh7ZVR53//TNaeyr69leJ4ZbdEbTukojZ4iw0Y8bA5Gn07p3yI8SL2U5mUhWzvDXrRBY673/HpnT+Ts/69dKWLVJ+vpSVJc2e7dwffVR64QXpgQekZ5+Vli+XCgqkd95xf4sPPpD+/vfYzVJRIZ13njR4sOvyibrvtZeUk+PivP76Jt3gzWr696/XP7Lnns2WVvkhe6nk1dGtV9adxEyfiEIdGx/+63u245pvZ1dufab4h+i7O/aRcN3PS98aoor992iRtHJzfq9tvxquVb+oO0zeB7+o8/rNnn1Y8vP69En5EeHFbCczqYrZN6sLRRa64OGnUjo/41m+XBoTjCeGw7G+/3/9y4lfPKGQ68efNElatkyaOlXatMmN/40b51qNX3whHXqoNH68NGGC6zKNRKR77pHeflu6+Wbp2GOlsWOl++6Tdt9dOuAA6fzzpVdfdX/ZG290N2/8zbxkiRNokA4/3MW1//7OPn2666qtrJQuvDD5w+CllyQzadAgqW/fOh80Aun11115x493Yzggde2aGKZ79/rj2BGmoXJ4U202HeV+t/Zp2XRqjVE2wZTujz77aJekflV9fTdjq2eguUzK3YwFW8T5I3Xdox+mdL5nB7NkiRPV0lJp0SInhNGxREn6979dN6rkhLesrHYc5eVuLDIUkg4+WHrttZhfOCytWCG9914s3tNPd7fKnDnStGmJ6UlOJDdvdq1gSSoqcmFee80JeXxLduXKmCj36CF9+qn00UfSPq5loM6dpSFDpFGu20t7BC2Eo45yrWKQRo6UHnxQWrVKeugh55aV5X579pQ6dXICHgpJZ50Vi2vYMBW//rA2f/GMO2/KFPfiEM1br17ud+zYmNuJJyY+OGfNSvow9WbHmPhu3XhTNrCTUqUxYgacCSwP5jfclcR/TDDHYUEwT2JLnF84zm9SQ2mlalok0tYwqYrZhg3uKjyZpkNmnh1AZaVUUrJ9cZSVOZGsi61b3Wy9eNascaIbJRKJzXZrTubMkR5+ONEtFIodDwzGaR591Nm3bXMt85UrpXXrXCu8pCTxATtihPTGG9Itt7i4Ro2SnnjCXctQSPr8c9dyv+466d13XdmjwgzO78knpTPOkI47LtbqjpoJE+ruWu7QQaHLErvqIqeeKp18smtNx7vHt6gvvVThc4dryxmxSSWR9u1V9P5YRfbrp0i7dk0SnqhZMQoVD2r6efk391f5Qb0bFTZywnEpV39DYob7niMvmFkenZl+SD3hbwImxNlL64u/uUyri1BzmVTFbN06dxXGZuiQmcezw9ke4d+2zYlkMp58UnrxxURBnzbN3cAvvCD16yf98Y8xv/nzXTd5XeTlufQiESee5eUxv/fec/FOnhxzi7bIIxEnvjfd5MI89pibrv/ii06ws7OlR4KZnG+/7c4pLXWi0w5t3Pih9Oab0siRCo9+MCZKXbpUH4ceuNf1LJSWqure2xWaN1O64AJFBh2QXNBOPbUpVzmBRojZUOCDOPvdwN31hJ8OnBZn3yFiZkFiaU/Xrl1VlsKGf0VF7uP6K6+EM89sgYx5PJ7MJT8f+vVL7rd0KRx0UOKKJlLCwtaA+2D844/h4IPdh+S9e7tVSuqjqAhmzIDvv3frjgZbLKWCmW2V1LUe/wuBMyX9OrCPAn4s6cYkYfcHZgL9FHwhb2YhXBdjCHhY0jspZ7Ye2ryYeTweT1vGzCqBRXFOz0t6Ps6/KWJ2J07Ibopz6ytptZkNBD4BTpGU19zlSG0NKI/H4/FkCiFJx9Tj35ilCaOMwK3sVI2k1cHvt2b2KXAkbgyuWdlZFxr2eDwez87BHGCQmQ0ws444waq1EKmZHQT0AGbEufUws07B8Z7A8UDDK3KngG+ZeTwej6dOJIXM7EbgA9zMxgmSlpjZA8BcSVFhGwFMVOLY1cHAODOL4BpPD0tqETHzY2Yej8fThmloAki64LsZPR6Px5P2eDHzeDweT9rjxczj8Xg8aY8XM4/H4/GkPRkzASSYLbOtwYB10wH3hXpbwpc582lr5QVf5qbSWVLaN2wyRsy2FzOb28CHgxmHL3Pm09bKC77MbZW0V2OPx+PxeLyYeTwejyft8WIW4/mGg2QcvsyZT1srL/gyt0n8mJnH4/F40h7fMvN4PB5P2tPmxczMzjSz5WaWa2Z3tXZ+mgsz29fMss3sazNbYma3BO49zewjM8sJfnsE7mZmTwbXYaGZHdW6JUgdM2tvZl+a2eTAPsDMZgVl+0ew8jdm1imw5wb+/Vsz36liZt3N7E0zW2ZmS81saKbXs5ndFvyvF5vZa2a2a6bVs5lNMLN1ZrY4zq3J9Wpmlwfhc8zs8tYoy46gTYuZmbUHngbOAg4BLjGzQ1o3V81GCLhD0iHAEOCGoGx3AVMlDQKmBnZw12BQYK4Bnt3xWW42bgGWxtkfAcZIOgDYDFwVuF8FbA7cxwTh0pEngPclHQQcgSt7xtazmfUFbgaOkXQYbiX3EWRePf8NOLOGW5Pq1cx6An8EfgwcC/wxKoAZh6Q2a4ChwAdx9ruBu1s7Xy1U1n8BpwHLgT6BWx9geXA8DrgkLnx1uHQyuI0DpwI/ASYDBmwAOtSsc9yWFkOD4w5BOGvtMjSxvN2AFTXzncn1DPQFvgd6BvU2GTgjE+sZ6A8sTrVegUuAcXHuCeEyybTplhmxmyJKfuCWUQTdKkcCs4C9Ja0JvNYCewfHmXItHgd+D0QCey9gi6To6gjx5aouc+BfFIRPJwYA64G/Bl2r482sKxlcz3I7Fz8GrALW4OptHpldz1GaWq9pX9+Npa2LWcZjZrsBbwG3SiqO95N7VcuY6axmNhxYJ2lea+dlB9IBOAp4VtKRQBmxricgI+u5B3AuTsj3AbpSuzsu48m0et1e2rqYrQb2jbP3C9wyAjPbBSdkr0h6O3AuNLM+gX8fYF3gngnX4njgZ2b2HTAR19X4BNDdzKK7qseXq7rMgX83YOOOzHAzkA/kS5oV2N/EiVsm1/OpwApJ6yVVAW/j6j6T6zlKU+s1E+q7UbR1MZsDDApmQXXEDSJPauCctMDMDHgBWCrpL3Fek4DojKbLcWNpUfdfBrOihgBFcd0ZaYGkuyX1k9QfV5efSBoJZAMXBsFqljl6LS4MwqfVm66ktcD3ZnZg4HQK8DUZXM+47sUhZtYl+J9Hy5yx9RxHU+v1A+B0M+sRtGhPD9wyj9YetGttA5wNfAPkAfe2dn6asVwn4LogFgILAnM2bqxgKpADfAz0DMIbbmZnHrAIN1Os1cuxHeU/CZgcHA8EZgO5wBtAp8B918CeG/gPbO18p1jWwcDcoK7fAXpkej0DfwKWAYuBvwOdMq2egddwY4JVuBb4VanUK3BlUPZc4IrWLldLGb8CiMfj8XjSnrbezejxeDyeDMCLmcfj8XjSHi9mHo/H40l7vJh5PB6PJ+3xYubxeDyetMeLmcezE2BmJ0VX+fd4PE3Hi5nH4/F40h4vZh5PEzCzy8xstpktMLNxwd5ppWY2Jthfa6qZ9Q7CDjazmcH+Uv+M23vqADP72My+MrP5ZvZfQfS7xe1L9kqwuoXH42kEXsw8nkZiZgcDFwPHSxoMhIGRuIVu50o6FPgMt38UwEvAnZL+G7cqQ9T9FeBpSUcAx+FWeQC3s8GtuL31BuLWG/R4PI2gQ8NBPB5PwCnA0cCcoNHUGbfQawT4RxDmZeBtM+sGdJf0WeD+IvCGme0O9JX0TwBJ5QBBfLMl5Qf2Bbi9rKa1fLE8nvTHi5nH03gMeFHS3QmOZn+oES7VNeIq4o7D+PvT42k0vpvR42k8U4ELzWwvcFvSm9n+uPsoulr7pcA0SUXAZjMbFriPAj6TVALkm9nPgzg6mVmXHVoKjycD8W9+Hk8jkfS1md0HfGhm7XCrmd+A2xDz2MBvHW5cDdwWHc8FYvUtcEXgPgoYZ2YPBHFctAOL4fFkJH7VfI9nOzGzUkm7tXY+PJ62jO9m9Hg8Hk/a41tmHo/H40l7fMvM4/F4PGmPFzOPx+PxpD1ezDwej8eT9ngx83g8Hk/a48XM4/F4PGmPFzOPx+PxpD3/D0XGljf8VsrtAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x1080 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Imh6JovThTQw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "002da64c-78b1-4d08-b78b-d31156a0a596"
      },
      "source": [
        "fig, loss_ax = plt.subplots()\n",
        "acc_ax = loss_ax.twinx()\n",
        "\n",
        "loss_ax.plot(wineclass.history['loss'], 'y', label='train loss')\n",
        "loss_ax.plot(wineclass.history['val_loss'], 'r', label='val loss')\n",
        "loss_ax.set_xlabel('epoch')\n",
        "loss_ax.set_ylabel('loss')\n",
        "loss_ax.legend(loc='upper left')\n",
        "\n",
        "acc_ax.plot(wineclass.history['accuracy'], 'b', label='train acc')\n",
        "acc_ax.plot(wineclass.history['val_accuracy'], 'g', label='val acc')\n",
        "acc_ax.set_ylabel('accuracy')\n",
        "acc_ax.legend(loc='upper left')\n",
        "\n",
        "plt.figure(figsize=(20,15))\n",
        "plt.show()\n",
        "\n",
        "#200 근처에서 선택, -> train acc & val acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x1080 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYVR3h31lzsS"
      },
      "source": [
        "파일 삭제(하고 위에서 다시 생성할 것)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giJd_Oaed1TH"
      },
      "source": [
        "import shutil\n",
        "\n",
        "shutil.rmtree('/content/model')\n",
        "shutil.rmtree('/content/model0')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmWk3cUjLYxM"
      },
      "source": [
        "##############################################모델 병합###################################################  일단은 X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vIK76ZmLayw"
      },
      "source": [
        "https://jaehyeongan.github.io/2019/03/26/KERAS-FUNCTIONAL-API-MULTI-INPUT-%EB%AA%A8%EB%8D%B8-%EA%B5%AC%EC%B6%95%ED%95%98%EA%B8%B0/"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}